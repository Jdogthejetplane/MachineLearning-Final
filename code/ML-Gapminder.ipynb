{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gapminder-scaled.csv\")\n",
    "\n",
    "X = df.drop(columns=['country', 'lex','cm'])\n",
    "y = df['lex']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.63312329\n",
      "Validation score: -15.269522\n",
      "Iteration 2, loss = 0.63134885\n",
      "Validation score: -15.220844\n",
      "Iteration 3, loss = 0.62957609\n",
      "Validation score: -15.172094\n",
      "Iteration 4, loss = 0.62780355\n",
      "Validation score: -15.123346\n",
      "Iteration 5, loss = 0.62603252\n",
      "Validation score: -15.074739\n",
      "Iteration 6, loss = 0.62426182\n",
      "Validation score: -15.026136\n",
      "Iteration 7, loss = 0.62249098\n",
      "Validation score: -14.977413\n",
      "Iteration 8, loss = 0.62072069\n",
      "Validation score: -14.928671\n",
      "Iteration 9, loss = 0.61895282\n",
      "Validation score: -14.879988\n",
      "Iteration 10, loss = 0.61718707\n",
      "Validation score: -14.831324\n",
      "Iteration 11, loss = 0.61542351\n",
      "Validation score: -14.782666\n",
      "Iteration 12, loss = 0.61366056\n",
      "Validation score: -14.734066\n",
      "Iteration 13, loss = 0.61189892\n",
      "Validation score: -14.685594\n",
      "Iteration 14, loss = 0.61013764\n",
      "Validation score: -14.637216\n",
      "Iteration 15, loss = 0.60837661\n",
      "Validation score: -14.588917\n",
      "Iteration 16, loss = 0.60661602\n",
      "Validation score: -14.540389\n",
      "Iteration 17, loss = 0.60485592\n",
      "Validation score: -14.491932\n",
      "Iteration 18, loss = 0.60309529\n",
      "Validation score: -14.443512\n",
      "Iteration 19, loss = 0.60133319\n",
      "Validation score: -14.394807\n",
      "Iteration 20, loss = 0.59956860\n",
      "Validation score: -14.345994\n",
      "Iteration 21, loss = 0.59780397\n",
      "Validation score: -14.297285\n",
      "Iteration 22, loss = 0.59604122\n",
      "Validation score: -14.248882\n",
      "Iteration 23, loss = 0.59428202\n",
      "Validation score: -14.200634\n",
      "Iteration 24, loss = 0.59252432\n",
      "Validation score: -14.152424\n",
      "Iteration 25, loss = 0.59077019\n",
      "Validation score: -14.104190\n",
      "Iteration 26, loss = 0.58901674\n",
      "Validation score: -14.055863\n",
      "Iteration 27, loss = 0.58726478\n",
      "Validation score: -14.007468\n",
      "Iteration 28, loss = 0.58551429\n",
      "Validation score: -13.959183\n",
      "Iteration 29, loss = 0.58376556\n",
      "Validation score: -13.911155\n",
      "Iteration 30, loss = 0.58201821\n",
      "Validation score: -13.863012\n",
      "Iteration 31, loss = 0.58026907\n",
      "Validation score: -13.814662\n",
      "Iteration 32, loss = 0.57851970\n",
      "Validation score: -13.766183\n",
      "Iteration 33, loss = 0.57677154\n",
      "Validation score: -13.717540\n",
      "Iteration 34, loss = 0.57502475\n",
      "Validation score: -13.668834\n",
      "Iteration 35, loss = 0.57327582\n",
      "Validation score: -13.620219\n",
      "Iteration 36, loss = 0.57152813\n",
      "Validation score: -13.571706\n",
      "Iteration 37, loss = 0.56978234\n",
      "Validation score: -13.523439\n",
      "Iteration 38, loss = 0.56803856\n",
      "Validation score: -13.475125\n",
      "Iteration 39, loss = 0.56629454\n",
      "Validation score: -13.426887\n",
      "Iteration 40, loss = 0.56455372\n",
      "Validation score: -13.378756\n",
      "Iteration 41, loss = 0.56281272\n",
      "Validation score: -13.330655\n",
      "Iteration 42, loss = 0.56107150\n",
      "Validation score: -13.282606\n",
      "Iteration 43, loss = 0.55933176\n",
      "Validation score: -13.234461\n",
      "Iteration 44, loss = 0.55759456\n",
      "Validation score: -13.186397\n",
      "Iteration 45, loss = 0.55585732\n",
      "Validation score: -13.138417\n",
      "Iteration 46, loss = 0.55412331\n",
      "Validation score: -13.090546\n",
      "Iteration 47, loss = 0.55239157\n",
      "Validation score: -13.042700\n",
      "Iteration 48, loss = 0.55066169\n",
      "Validation score: -12.994954\n",
      "Iteration 49, loss = 0.54893452\n",
      "Validation score: -12.947295\n",
      "Iteration 50, loss = 0.54721148\n",
      "Validation score: -12.899774\n",
      "Iteration 51, loss = 0.54549084\n",
      "Validation score: -12.852374\n",
      "Iteration 52, loss = 0.54377107\n",
      "Validation score: -12.805042\n",
      "Iteration 53, loss = 0.54205259\n",
      "Validation score: -12.757590\n",
      "Iteration 54, loss = 0.54033697\n",
      "Validation score: -12.710093\n",
      "Iteration 55, loss = 0.53862296\n",
      "Validation score: -12.662766\n",
      "Iteration 56, loss = 0.53690956\n",
      "Validation score: -12.615848\n",
      "Iteration 57, loss = 0.53519727\n",
      "Validation score: -12.569061\n",
      "Iteration 58, loss = 0.53348647\n",
      "Validation score: -12.522373\n",
      "Iteration 59, loss = 0.53177664\n",
      "Validation score: -12.475800\n",
      "Iteration 60, loss = 0.53006977\n",
      "Validation score: -12.429333\n",
      "Iteration 61, loss = 0.52836455\n",
      "Validation score: -12.382968\n",
      "Iteration 62, loss = 0.52666104\n",
      "Validation score: -12.336703\n",
      "Iteration 63, loss = 0.52496064\n",
      "Validation score: -12.290538\n",
      "Iteration 64, loss = 0.52326193\n",
      "Validation score: -12.244465\n",
      "Iteration 65, loss = 0.52156659\n",
      "Validation score: -12.198528\n",
      "Iteration 66, loss = 0.51987398\n",
      "Validation score: -12.152702\n",
      "Iteration 67, loss = 0.51818203\n",
      "Validation score: -12.106970\n",
      "Iteration 68, loss = 0.51649087\n",
      "Validation score: -12.061335\n",
      "Iteration 69, loss = 0.51480169\n",
      "Validation score: -12.015797\n",
      "Iteration 70, loss = 0.51311506\n",
      "Validation score: -11.970290\n",
      "Iteration 71, loss = 0.51143189\n",
      "Validation score: -11.924896\n",
      "Iteration 72, loss = 0.50974812\n",
      "Validation score: -11.879599\n",
      "Iteration 73, loss = 0.50806614\n",
      "Validation score: -11.834415\n",
      "Iteration 74, loss = 0.50638711\n",
      "Validation score: -11.789393\n",
      "Iteration 75, loss = 0.50471088\n",
      "Validation score: -11.744481\n",
      "Iteration 76, loss = 0.50303699\n",
      "Validation score: -11.699782\n",
      "Iteration 77, loss = 0.50136716\n",
      "Validation score: -11.655279\n",
      "Iteration 78, loss = 0.49970084\n",
      "Validation score: -11.610925\n",
      "Iteration 79, loss = 0.49803761\n",
      "Validation score: -11.566708\n",
      "Iteration 80, loss = 0.49637736\n",
      "Validation score: -11.522551\n",
      "Iteration 81, loss = 0.49472133\n",
      "Validation score: -11.478525\n",
      "Iteration 82, loss = 0.49306644\n",
      "Validation score: -11.434614\n",
      "Iteration 83, loss = 0.49141388\n",
      "Validation score: -11.390815\n",
      "Iteration 84, loss = 0.48976224\n",
      "Validation score: -11.347240\n",
      "Iteration 85, loss = 0.48811077\n",
      "Validation score: -11.303653\n",
      "Iteration 86, loss = 0.48646025\n",
      "Validation score: -11.260084\n",
      "Iteration 87, loss = 0.48481146\n",
      "Validation score: -11.216448\n",
      "Iteration 88, loss = 0.48316741\n",
      "Validation score: -11.172847\n",
      "Iteration 89, loss = 0.48152704\n",
      "Validation score: -11.129361\n",
      "Iteration 90, loss = 0.47989014\n",
      "Validation score: -11.085972\n",
      "Iteration 91, loss = 0.47825566\n",
      "Validation score: -11.042679\n",
      "Iteration 92, loss = 0.47662381\n",
      "Validation score: -10.999572\n",
      "Iteration 93, loss = 0.47499495\n",
      "Validation score: -10.956674\n",
      "Iteration 94, loss = 0.47336746\n",
      "Validation score: -10.913828\n",
      "Iteration 95, loss = 0.47174187\n",
      "Validation score: -10.871081\n",
      "Iteration 96, loss = 0.47011927\n",
      "Validation score: -10.828470\n",
      "Iteration 97, loss = 0.46849922\n",
      "Validation score: -10.786025\n",
      "Iteration 98, loss = 0.46688075\n",
      "Validation score: -10.743696\n",
      "Iteration 99, loss = 0.46526488\n",
      "Validation score: -10.701373\n",
      "Iteration 100, loss = 0.46365149\n",
      "Validation score: -10.659101\n",
      "Iteration 101, loss = 0.46204084\n",
      "Validation score: -10.616884\n",
      "Iteration 102, loss = 0.46042967\n",
      "Validation score: -10.574763\n",
      "Iteration 103, loss = 0.45882113\n",
      "Validation score: -10.532584\n",
      "Iteration 104, loss = 0.45721535\n",
      "Validation score: -10.490298\n",
      "Iteration 105, loss = 0.45561191\n",
      "Validation score: -10.448059\n",
      "Iteration 106, loss = 0.45401170\n",
      "Validation score: -10.405892\n",
      "Iteration 107, loss = 0.45241149\n",
      "Validation score: -10.363766\n",
      "Iteration 108, loss = 0.45081230\n",
      "Validation score: -10.321660\n",
      "Iteration 109, loss = 0.44921696\n",
      "Validation score: -10.279669\n",
      "Iteration 110, loss = 0.44762411\n",
      "Validation score: -10.237630\n",
      "Iteration 111, loss = 0.44603271\n",
      "Validation score: -10.195460\n",
      "Iteration 112, loss = 0.44444281\n",
      "Validation score: -10.153393\n",
      "Iteration 113, loss = 0.44285630\n",
      "Validation score: -10.111468\n",
      "Iteration 114, loss = 0.44127384\n",
      "Validation score: -10.069647\n",
      "Iteration 115, loss = 0.43969567\n",
      "Validation score: -10.027911\n",
      "Iteration 116, loss = 0.43811858\n",
      "Validation score: -9.986215\n",
      "Iteration 117, loss = 0.43654415\n",
      "Validation score: -9.944691\n",
      "Iteration 118, loss = 0.43497278\n",
      "Validation score: -9.903252\n",
      "Iteration 119, loss = 0.43340502\n",
      "Validation score: -9.861891\n",
      "Iteration 120, loss = 0.43183833\n",
      "Validation score: -9.820639\n",
      "Iteration 121, loss = 0.43027233\n",
      "Validation score: -9.779466\n",
      "Iteration 122, loss = 0.42870942\n",
      "Validation score: -9.738336\n",
      "Iteration 123, loss = 0.42714942\n",
      "Validation score: -9.697275\n",
      "Iteration 124, loss = 0.42559403\n",
      "Validation score: -9.656337\n",
      "Iteration 125, loss = 0.42403897\n",
      "Validation score: -9.615493\n",
      "Iteration 126, loss = 0.42248569\n",
      "Validation score: -9.574744\n",
      "Iteration 127, loss = 0.42093577\n",
      "Validation score: -9.534099\n",
      "Iteration 128, loss = 0.41939048\n",
      "Validation score: -9.493529\n",
      "Iteration 129, loss = 0.41785080\n",
      "Validation score: -9.453031\n",
      "Iteration 130, loss = 0.41631240\n",
      "Validation score: -9.412661\n",
      "Iteration 131, loss = 0.41477633\n",
      "Validation score: -9.372417\n",
      "Iteration 132, loss = 0.41324182\n",
      "Validation score: -9.332323\n",
      "Iteration 133, loss = 0.41170901\n",
      "Validation score: -9.291969\n",
      "Iteration 134, loss = 0.41017632\n",
      "Validation score: -9.251695\n",
      "Iteration 135, loss = 0.40864394\n",
      "Validation score: -9.211492\n",
      "Iteration 136, loss = 0.40711323\n",
      "Validation score: -9.171617\n",
      "Iteration 137, loss = 0.40558550\n",
      "Validation score: -9.131859\n",
      "Iteration 138, loss = 0.40406266\n",
      "Validation score: -9.092205\n",
      "Iteration 139, loss = 0.40254349\n",
      "Validation score: -9.052622\n",
      "Iteration 140, loss = 0.40102545\n",
      "Validation score: -9.013101\n",
      "Iteration 141, loss = 0.39951004\n",
      "Validation score: -8.973686\n",
      "Iteration 142, loss = 0.39799765\n",
      "Validation score: -8.934281\n",
      "Iteration 143, loss = 0.39648747\n",
      "Validation score: -8.894979\n",
      "Iteration 144, loss = 0.39498045\n",
      "Validation score: -8.855791\n",
      "Iteration 145, loss = 0.39347635\n",
      "Validation score: -8.816420\n",
      "Iteration 146, loss = 0.39197539\n",
      "Validation score: -8.776896\n",
      "Iteration 147, loss = 0.39047814\n",
      "Validation score: -8.737479\n",
      "Iteration 148, loss = 0.38898394\n",
      "Validation score: -8.698146\n",
      "Iteration 149, loss = 0.38749082\n",
      "Validation score: -8.658912\n",
      "Iteration 150, loss = 0.38599941\n",
      "Validation score: -8.619782\n",
      "Iteration 151, loss = 0.38451080\n",
      "Validation score: -8.580766\n",
      "Iteration 152, loss = 0.38302508\n",
      "Validation score: -8.541865\n",
      "Iteration 153, loss = 0.38153968\n",
      "Validation score: -8.503067\n",
      "Iteration 154, loss = 0.38005600\n",
      "Validation score: -8.464378\n",
      "Iteration 155, loss = 0.37857279\n",
      "Validation score: -8.425780\n",
      "Iteration 156, loss = 0.37709227\n",
      "Validation score: -8.387267\n",
      "Iteration 157, loss = 0.37561520\n",
      "Validation score: -8.348877\n",
      "Iteration 158, loss = 0.37414109\n",
      "Validation score: -8.310380\n",
      "Iteration 159, loss = 0.37267054\n",
      "Validation score: -8.271894\n",
      "Iteration 160, loss = 0.37120326\n",
      "Validation score: -8.233490\n",
      "Iteration 161, loss = 0.36973799\n",
      "Validation score: -8.195157\n",
      "Iteration 162, loss = 0.36827393\n",
      "Validation score: -8.156669\n",
      "Iteration 163, loss = 0.36681349\n",
      "Validation score: -8.118375\n",
      "Iteration 164, loss = 0.36535831\n",
      "Validation score: -8.080243\n",
      "Iteration 165, loss = 0.36390758\n",
      "Validation score: -8.042228\n",
      "Iteration 166, loss = 0.36246039\n",
      "Validation score: -8.004308\n",
      "Iteration 167, loss = 0.36101825\n",
      "Validation score: -7.966468\n",
      "Iteration 168, loss = 0.35957895\n",
      "Validation score: -7.928736\n",
      "Iteration 169, loss = 0.35814270\n",
      "Validation score: -7.891059\n",
      "Iteration 170, loss = 0.35670882\n",
      "Validation score: -7.853473\n",
      "Iteration 171, loss = 0.35527787\n",
      "Validation score: -7.815778\n",
      "Iteration 172, loss = 0.35384910\n",
      "Validation score: -7.778163\n",
      "Iteration 173, loss = 0.35242516\n",
      "Validation score: -7.740652\n",
      "Iteration 174, loss = 0.35100873\n",
      "Validation score: -7.703475\n",
      "Iteration 175, loss = 0.34959794\n",
      "Validation score: -7.666425\n",
      "Iteration 176, loss = 0.34818861\n",
      "Validation score: -7.629482\n",
      "Iteration 177, loss = 0.34678190\n",
      "Validation score: -7.592649\n",
      "Iteration 178, loss = 0.34537678\n",
      "Validation score: -7.555904\n",
      "Iteration 179, loss = 0.34397418\n",
      "Validation score: -7.519179\n",
      "Iteration 180, loss = 0.34257384\n",
      "Validation score: -7.482429\n",
      "Iteration 181, loss = 0.34117497\n",
      "Validation score: -7.445563\n",
      "Iteration 182, loss = 0.33977676\n",
      "Validation score: -7.408797\n",
      "Iteration 183, loss = 0.33837746\n",
      "Validation score: -7.372128\n",
      "Iteration 184, loss = 0.33697959\n",
      "Validation score: -7.335543\n",
      "Iteration 185, loss = 0.33558449\n",
      "Validation score: -7.299001\n",
      "Iteration 186, loss = 0.33419035\n",
      "Validation score: -7.262394\n",
      "Iteration 187, loss = 0.33279941\n",
      "Validation score: -7.225845\n",
      "Iteration 188, loss = 0.33141100\n",
      "Validation score: -7.189368\n",
      "Iteration 189, loss = 0.33002566\n",
      "Validation score: -7.152943\n",
      "Iteration 190, loss = 0.32864214\n",
      "Validation score: -7.116579\n",
      "Iteration 191, loss = 0.32726060\n",
      "Validation score: -7.080319\n",
      "Iteration 192, loss = 0.32588267\n",
      "Validation score: -7.044166\n",
      "Iteration 193, loss = 0.32450781\n",
      "Validation score: -7.008084\n",
      "Iteration 194, loss = 0.32313702\n",
      "Validation score: -6.972087\n",
      "Iteration 195, loss = 0.32177047\n",
      "Validation score: -6.936200\n",
      "Iteration 196, loss = 0.32040726\n",
      "Validation score: -6.900472\n",
      "Iteration 197, loss = 0.31904636\n",
      "Validation score: -6.864873\n",
      "Iteration 198, loss = 0.31768721\n",
      "Validation score: -6.829396\n",
      "Iteration 199, loss = 0.31632936\n",
      "Validation score: -6.793998\n",
      "Iteration 200, loss = 0.31497185\n",
      "Validation score: -6.758687\n",
      "Iteration 201, loss = 0.31361675\n",
      "Validation score: -6.723448\n",
      "Iteration 202, loss = 0.31226518\n",
      "Validation score: -6.688291\n",
      "Iteration 203, loss = 0.31091770\n",
      "Validation score: -6.653251\n",
      "Iteration 204, loss = 0.30957410\n",
      "Validation score: -6.618039\n",
      "Iteration 205, loss = 0.30823407\n",
      "Validation score: -6.582681\n",
      "Iteration 206, loss = 0.30689816\n",
      "Validation score: -6.547431\n",
      "Iteration 207, loss = 0.30556633\n",
      "Validation score: -6.512278\n",
      "Iteration 208, loss = 0.30423790\n",
      "Validation score: -6.477192\n",
      "Iteration 209, loss = 0.30291320\n",
      "Validation score: -6.442170\n",
      "Iteration 210, loss = 0.30159314\n",
      "Validation score: -6.407262\n",
      "Iteration 211, loss = 0.30027772\n",
      "Validation score: -6.372462\n",
      "Iteration 212, loss = 0.29896681\n",
      "Validation score: -6.337810\n",
      "Iteration 213, loss = 0.29765947\n",
      "Validation score: -6.303281\n",
      "Iteration 214, loss = 0.29635513\n",
      "Validation score: -6.268880\n",
      "Iteration 215, loss = 0.29505431\n",
      "Validation score: -6.234372\n",
      "Iteration 216, loss = 0.29375762\n",
      "Validation score: -6.199890\n",
      "Iteration 217, loss = 0.29246411\n",
      "Validation score: -6.165510\n",
      "Iteration 218, loss = 0.29117282\n",
      "Validation score: -6.131191\n",
      "Iteration 219, loss = 0.28988635\n",
      "Validation score: -6.096927\n",
      "Iteration 220, loss = 0.28860251\n",
      "Validation score: -6.062723\n",
      "Iteration 221, loss = 0.28732186\n",
      "Validation score: -6.028599\n",
      "Iteration 222, loss = 0.28604507\n",
      "Validation score: -5.994598\n",
      "Iteration 223, loss = 0.28477090\n",
      "Validation score: -5.960685\n",
      "Iteration 224, loss = 0.28349929\n",
      "Validation score: -5.926847\n",
      "Iteration 225, loss = 0.28223211\n",
      "Validation score: -5.892985\n",
      "Iteration 226, loss = 0.28096935\n",
      "Validation score: -5.859153\n",
      "Iteration 227, loss = 0.27970984\n",
      "Validation score: -5.825433\n",
      "Iteration 228, loss = 0.27845212\n",
      "Validation score: -5.791809\n",
      "Iteration 229, loss = 0.27719681\n",
      "Validation score: -5.758316\n",
      "Iteration 230, loss = 0.27594474\n",
      "Validation score: -5.724946\n",
      "Iteration 231, loss = 0.27469559\n",
      "Validation score: -5.691694\n",
      "Iteration 232, loss = 0.27344975\n",
      "Validation score: -5.658567\n",
      "Iteration 233, loss = 0.27220676\n",
      "Validation score: -5.625534\n",
      "Iteration 234, loss = 0.27096777\n",
      "Validation score: -5.592655\n",
      "Iteration 235, loss = 0.26973348\n",
      "Validation score: -5.559906\n",
      "Iteration 236, loss = 0.26850134\n",
      "Validation score: -5.527309\n",
      "Iteration 237, loss = 0.26727201\n",
      "Validation score: -5.494881\n",
      "Iteration 238, loss = 0.26604599\n",
      "Validation score: -5.462539\n",
      "Iteration 239, loss = 0.26482371\n",
      "Validation score: -5.430319\n",
      "Iteration 240, loss = 0.26360535\n",
      "Validation score: -5.398216\n",
      "Iteration 241, loss = 0.26239032\n",
      "Validation score: -5.366111\n",
      "Iteration 242, loss = 0.26117846\n",
      "Validation score: -5.334126\n",
      "Iteration 243, loss = 0.25997056\n",
      "Validation score: -5.302225\n",
      "Iteration 244, loss = 0.25876553\n",
      "Validation score: -5.270411\n",
      "Iteration 245, loss = 0.25756430\n",
      "Validation score: -5.238600\n",
      "Iteration 246, loss = 0.25636635\n",
      "Validation score: -5.206870\n",
      "Iteration 247, loss = 0.25517126\n",
      "Validation score: -5.175246\n",
      "Iteration 248, loss = 0.25397888\n",
      "Validation score: -5.143721\n",
      "Iteration 249, loss = 0.25278952\n",
      "Validation score: -5.112308\n",
      "Iteration 250, loss = 0.25160325\n",
      "Validation score: -5.080939\n",
      "Iteration 251, loss = 0.25041980\n",
      "Validation score: -5.049594\n",
      "Iteration 252, loss = 0.24923900\n",
      "Validation score: -5.018525\n",
      "Iteration 253, loss = 0.24806139\n",
      "Validation score: -4.987566\n",
      "Iteration 254, loss = 0.24688801\n",
      "Validation score: -4.956717\n",
      "Iteration 255, loss = 0.24571838\n",
      "Validation score: -4.925973\n",
      "Iteration 256, loss = 0.24455163\n",
      "Validation score: -4.895343\n",
      "Iteration 257, loss = 0.24338734\n",
      "Validation score: -4.864765\n",
      "Iteration 258, loss = 0.24222668\n",
      "Validation score: -4.834272\n",
      "Iteration 259, loss = 0.24107012\n",
      "Validation score: -4.803895\n",
      "Iteration 260, loss = 0.23991612\n",
      "Validation score: -4.773611\n",
      "Iteration 261, loss = 0.23876499\n",
      "Validation score: -4.743446\n",
      "Iteration 262, loss = 0.23761729\n",
      "Validation score: -4.713397\n",
      "Iteration 263, loss = 0.23647425\n",
      "Validation score: -4.683450\n",
      "Iteration 264, loss = 0.23533504\n",
      "Validation score: -4.653569\n",
      "Iteration 265, loss = 0.23420086\n",
      "Validation score: -4.623779\n",
      "Iteration 266, loss = 0.23307136\n",
      "Validation score: -4.594121\n",
      "Iteration 267, loss = 0.23194552\n",
      "Validation score: -4.564595\n",
      "Iteration 268, loss = 0.23082272\n",
      "Validation score: -4.535166\n",
      "Iteration 269, loss = 0.22970250\n",
      "Validation score: -4.505845\n",
      "Iteration 270, loss = 0.22858514\n",
      "Validation score: -4.476597\n",
      "Iteration 271, loss = 0.22747132\n",
      "Validation score: -4.447456\n",
      "Iteration 272, loss = 0.22636194\n",
      "Validation score: -4.418415\n",
      "Iteration 273, loss = 0.22525661\n",
      "Validation score: -4.389445\n",
      "Iteration 274, loss = 0.22415374\n",
      "Validation score: -4.360593\n",
      "Iteration 275, loss = 0.22305362\n",
      "Validation score: -4.331878\n",
      "Iteration 276, loss = 0.22195729\n",
      "Validation score: -4.303298\n",
      "Iteration 277, loss = 0.22086383\n",
      "Validation score: -4.274824\n",
      "Iteration 278, loss = 0.21977297\n",
      "Validation score: -4.246424\n",
      "Iteration 279, loss = 0.21868487\n",
      "Validation score: -4.218089\n",
      "Iteration 280, loss = 0.21760065\n",
      "Validation score: -4.189865\n",
      "Iteration 281, loss = 0.21651979\n",
      "Validation score: -4.161732\n",
      "Iteration 282, loss = 0.21544294\n",
      "Validation score: -4.133709\n",
      "Iteration 283, loss = 0.21436962\n",
      "Validation score: -4.105773\n",
      "Iteration 284, loss = 0.21329918\n",
      "Validation score: -4.077908\n",
      "Iteration 285, loss = 0.21223124\n",
      "Validation score: -4.050151\n",
      "Iteration 286, loss = 0.21116634\n",
      "Validation score: -4.022498\n",
      "Iteration 287, loss = 0.21010527\n",
      "Validation score: -3.994957\n",
      "Iteration 288, loss = 0.20904749\n",
      "Validation score: -3.967522\n",
      "Iteration 289, loss = 0.20799264\n",
      "Validation score: -3.940240\n",
      "Iteration 290, loss = 0.20694174\n",
      "Validation score: -3.913182\n",
      "Iteration 291, loss = 0.20589404\n",
      "Validation score: -3.886185\n",
      "Iteration 292, loss = 0.20484922\n",
      "Validation score: -3.859303\n",
      "Iteration 293, loss = 0.20380726\n",
      "Validation score: -3.832489\n",
      "Iteration 294, loss = 0.20276778\n",
      "Validation score: -3.805750\n",
      "Iteration 295, loss = 0.20173037\n",
      "Validation score: -3.779091\n",
      "Iteration 296, loss = 0.20069582\n",
      "Validation score: -3.752558\n",
      "Iteration 297, loss = 0.19966422\n",
      "Validation score: -3.726052\n",
      "Iteration 298, loss = 0.19863555\n",
      "Validation score: -3.699571\n",
      "Iteration 299, loss = 0.19760946\n",
      "Validation score: -3.673140\n",
      "Iteration 300, loss = 0.19658651\n",
      "Validation score: -3.646775\n",
      "Iteration 301, loss = 0.19556690\n",
      "Validation score: -3.620498\n",
      "Iteration 302, loss = 0.19454974\n",
      "Validation score: -3.594305\n",
      "Iteration 303, loss = 0.19353486\n",
      "Validation score: -3.568087\n",
      "Iteration 304, loss = 0.19252347\n",
      "Validation score: -3.541961\n",
      "Iteration 305, loss = 0.19151483\n",
      "Validation score: -3.515906\n",
      "Iteration 306, loss = 0.19050920\n",
      "Validation score: -3.489868\n",
      "Iteration 307, loss = 0.18950629\n",
      "Validation score: -3.463925\n",
      "Iteration 308, loss = 0.18850857\n",
      "Validation score: -3.438092\n",
      "Iteration 309, loss = 0.18751461\n",
      "Validation score: -3.412365\n",
      "Iteration 310, loss = 0.18652421\n",
      "Validation score: -3.386756\n",
      "Iteration 311, loss = 0.18553719\n",
      "Validation score: -3.361259\n",
      "Iteration 312, loss = 0.18455384\n",
      "Validation score: -3.335896\n",
      "Iteration 313, loss = 0.18357388\n",
      "Validation score: -3.310672\n",
      "Iteration 314, loss = 0.18259893\n",
      "Validation score: -3.285472\n",
      "Iteration 315, loss = 0.18162938\n",
      "Validation score: -3.260306\n",
      "Iteration 316, loss = 0.18066256\n",
      "Validation score: -3.235233\n",
      "Iteration 317, loss = 0.17969935\n",
      "Validation score: -3.210258\n",
      "Iteration 318, loss = 0.17873930\n",
      "Validation score: -3.185408\n",
      "Iteration 319, loss = 0.17778207\n",
      "Validation score: -3.160628\n",
      "Iteration 320, loss = 0.17682766\n",
      "Validation score: -3.135964\n",
      "Iteration 321, loss = 0.17587592\n",
      "Validation score: -3.111418\n",
      "Iteration 322, loss = 0.17492607\n",
      "Validation score: -3.086894\n",
      "Iteration 323, loss = 0.17398048\n",
      "Validation score: -3.062452\n",
      "Iteration 324, loss = 0.17303783\n",
      "Validation score: -3.038116\n",
      "Iteration 325, loss = 0.17209795\n",
      "Validation score: -3.013897\n",
      "Iteration 326, loss = 0.17116148\n",
      "Validation score: -2.989765\n",
      "Iteration 327, loss = 0.17022861\n",
      "Validation score: -2.965752\n",
      "Iteration 328, loss = 0.16929804\n",
      "Validation score: -2.941863\n",
      "Iteration 329, loss = 0.16836971\n",
      "Validation score: -2.918059\n",
      "Iteration 330, loss = 0.16744498\n",
      "Validation score: -2.894281\n",
      "Iteration 331, loss = 0.16652322\n",
      "Validation score: -2.870618\n",
      "Iteration 332, loss = 0.16560443\n",
      "Validation score: -2.847070\n",
      "Iteration 333, loss = 0.16468887\n",
      "Validation score: -2.823642\n",
      "Iteration 334, loss = 0.16377688\n",
      "Validation score: -2.800326\n",
      "Iteration 335, loss = 0.16286770\n",
      "Validation score: -2.777093\n",
      "Iteration 336, loss = 0.16196033\n",
      "Validation score: -2.753937\n",
      "Iteration 337, loss = 0.16105598\n",
      "Validation score: -2.730894\n",
      "Iteration 338, loss = 0.16015449\n",
      "Validation score: -2.707930\n",
      "Iteration 339, loss = 0.15925643\n",
      "Validation score: -2.685042\n",
      "Iteration 340, loss = 0.15836165\n",
      "Validation score: -2.662264\n",
      "Iteration 341, loss = 0.15746952\n",
      "Validation score: -2.639602\n",
      "Iteration 342, loss = 0.15658245\n",
      "Validation score: -2.617077\n",
      "Iteration 343, loss = 0.15569804\n",
      "Validation score: -2.594689\n",
      "Iteration 344, loss = 0.15481814\n",
      "Validation score: -2.572457\n",
      "Iteration 345, loss = 0.15394191\n",
      "Validation score: -2.550332\n",
      "Iteration 346, loss = 0.15306923\n",
      "Validation score: -2.528382\n",
      "Iteration 347, loss = 0.15219992\n",
      "Validation score: -2.506547\n",
      "Iteration 348, loss = 0.15133398\n",
      "Validation score: -2.484828\n",
      "Iteration 349, loss = 0.15047228\n",
      "Validation score: -2.463229\n",
      "Iteration 350, loss = 0.14961440\n",
      "Validation score: -2.441725\n",
      "Iteration 351, loss = 0.14875935\n",
      "Validation score: -2.420337\n",
      "Iteration 352, loss = 0.14790615\n",
      "Validation score: -2.399064\n",
      "Iteration 353, loss = 0.14705593\n",
      "Validation score: -2.377901\n",
      "Iteration 354, loss = 0.14620801\n",
      "Validation score: -2.356829\n",
      "Iteration 355, loss = 0.14536340\n",
      "Validation score: -2.335867\n",
      "Iteration 356, loss = 0.14452148\n",
      "Validation score: -2.315015\n",
      "Iteration 357, loss = 0.14368266\n",
      "Validation score: -2.294286\n",
      "Iteration 358, loss = 0.14284651\n",
      "Validation score: -2.273659\n",
      "Iteration 359, loss = 0.14201235\n",
      "Validation score: -2.253148\n",
      "Iteration 360, loss = 0.14117962\n",
      "Validation score: -2.232735\n",
      "Iteration 361, loss = 0.14034852\n",
      "Validation score: -2.212397\n",
      "Iteration 362, loss = 0.13952005\n",
      "Validation score: -2.192090\n",
      "Iteration 363, loss = 0.13869460\n",
      "Validation score: -2.171884\n",
      "Iteration 364, loss = 0.13787205\n",
      "Validation score: -2.151771\n",
      "Iteration 365, loss = 0.13705310\n",
      "Validation score: -2.131744\n",
      "Iteration 366, loss = 0.13623738\n",
      "Validation score: -2.111824\n",
      "Iteration 367, loss = 0.13542478\n",
      "Validation score: -2.092002\n",
      "Iteration 368, loss = 0.13461530\n",
      "Validation score: -2.072284\n",
      "Iteration 369, loss = 0.13380959\n",
      "Validation score: -2.052619\n",
      "Iteration 370, loss = 0.13300736\n",
      "Validation score: -2.033031\n",
      "Iteration 371, loss = 0.13220818\n",
      "Validation score: -2.013516\n",
      "Iteration 372, loss = 0.13141279\n",
      "Validation score: -1.994073\n",
      "Iteration 373, loss = 0.13062098\n",
      "Validation score: -1.974733\n",
      "Iteration 374, loss = 0.12983226\n",
      "Validation score: -1.955503\n",
      "Iteration 375, loss = 0.12904631\n",
      "Validation score: -1.936365\n",
      "Iteration 376, loss = 0.12826304\n",
      "Validation score: -1.917319\n",
      "Iteration 377, loss = 0.12748301\n",
      "Validation score: -1.898358\n",
      "Iteration 378, loss = 0.12670622\n",
      "Validation score: -1.879497\n",
      "Iteration 379, loss = 0.12593361\n",
      "Validation score: -1.860762\n",
      "Iteration 380, loss = 0.12516406\n",
      "Validation score: -1.842135\n",
      "Iteration 381, loss = 0.12439757\n",
      "Validation score: -1.823616\n",
      "Iteration 382, loss = 0.12363448\n",
      "Validation score: -1.805244\n",
      "Iteration 383, loss = 0.12287500\n",
      "Validation score: -1.786964\n",
      "Iteration 384, loss = 0.12211858\n",
      "Validation score: -1.768770\n",
      "Iteration 385, loss = 0.12136565\n",
      "Validation score: -1.750675\n",
      "Iteration 386, loss = 0.12061638\n",
      "Validation score: -1.732677\n",
      "Iteration 387, loss = 0.11987077\n",
      "Validation score: -1.714787\n",
      "Iteration 388, loss = 0.11912857\n",
      "Validation score: -1.697008\n",
      "Iteration 389, loss = 0.11839004\n",
      "Validation score: -1.679359\n",
      "Iteration 390, loss = 0.11765516\n",
      "Validation score: -1.661830\n",
      "Iteration 391, loss = 0.11692415\n",
      "Validation score: -1.644413\n",
      "Iteration 392, loss = 0.11619698\n",
      "Validation score: -1.627133\n",
      "Iteration 393, loss = 0.11547220\n",
      "Validation score: -1.609942\n",
      "Iteration 394, loss = 0.11475000\n",
      "Validation score: -1.592814\n",
      "Iteration 395, loss = 0.11403124\n",
      "Validation score: -1.575776\n",
      "Iteration 396, loss = 0.11331592\n",
      "Validation score: -1.558842\n",
      "Iteration 397, loss = 0.11260362\n",
      "Validation score: -1.542153\n",
      "Iteration 398, loss = 0.11189430\n",
      "Validation score: -1.525627\n",
      "Iteration 399, loss = 0.11118803\n",
      "Validation score: -1.509191\n",
      "Iteration 400, loss = 0.11048487\n",
      "Validation score: -1.492854\n",
      "Iteration 401, loss = 0.10978544\n",
      "Validation score: -1.476616\n",
      "Iteration 402, loss = 0.10908967\n",
      "Validation score: -1.460481\n",
      "Iteration 403, loss = 0.10839635\n",
      "Validation score: -1.444453\n",
      "Iteration 404, loss = 0.10770569\n",
      "Validation score: -1.428521\n",
      "Iteration 405, loss = 0.10701824\n",
      "Validation score: -1.412680\n",
      "Iteration 406, loss = 0.10633398\n",
      "Validation score: -1.396931\n",
      "Iteration 407, loss = 0.10565298\n",
      "Validation score: -1.381210\n",
      "Iteration 408, loss = 0.10497543\n",
      "Validation score: -1.365586\n",
      "Iteration 409, loss = 0.10430152\n",
      "Validation score: -1.350038\n",
      "Iteration 410, loss = 0.10363077\n",
      "Validation score: -1.334572\n",
      "Iteration 411, loss = 0.10296329\n",
      "Validation score: -1.319176\n",
      "Iteration 412, loss = 0.10229892\n",
      "Validation score: -1.303824\n",
      "Iteration 413, loss = 0.10163735\n",
      "Validation score: -1.288545\n",
      "Iteration 414, loss = 0.10097894\n",
      "Validation score: -1.273438\n",
      "Iteration 415, loss = 0.10032326\n",
      "Validation score: -1.258443\n",
      "Iteration 416, loss = 0.09967037\n",
      "Validation score: -1.243537\n",
      "Iteration 417, loss = 0.09902061\n",
      "Validation score: -1.228723\n",
      "Iteration 418, loss = 0.09837405\n",
      "Validation score: -1.214002\n",
      "Iteration 419, loss = 0.09773001\n",
      "Validation score: -1.199365\n",
      "Iteration 420, loss = 0.09708886\n",
      "Validation score: -1.184817\n",
      "Iteration 421, loss = 0.09645076\n",
      "Validation score: -1.170366\n",
      "Iteration 422, loss = 0.09581591\n",
      "Validation score: -1.156010\n",
      "Iteration 423, loss = 0.09518411\n",
      "Validation score: -1.141748\n",
      "Iteration 424, loss = 0.09455509\n",
      "Validation score: -1.127538\n",
      "Iteration 425, loss = 0.09392949\n",
      "Validation score: -1.113382\n",
      "Iteration 426, loss = 0.09330726\n",
      "Validation score: -1.099279\n",
      "Iteration 427, loss = 0.09268822\n",
      "Validation score: -1.085265\n",
      "Iteration 428, loss = 0.09207232\n",
      "Validation score: -1.071334\n",
      "Iteration 429, loss = 0.09145989\n",
      "Validation score: -1.057500\n",
      "Iteration 430, loss = 0.09085046\n",
      "Validation score: -1.043765\n",
      "Iteration 431, loss = 0.09024409\n",
      "Validation score: -1.030120\n",
      "Iteration 432, loss = 0.08964084\n",
      "Validation score: -1.016567\n",
      "Iteration 433, loss = 0.08904060\n",
      "Validation score: -1.003106\n",
      "Iteration 434, loss = 0.08844314\n",
      "Validation score: -0.989746\n",
      "Iteration 435, loss = 0.08784904\n",
      "Validation score: -0.976497\n",
      "Iteration 436, loss = 0.08725825\n",
      "Validation score: -0.963340\n",
      "Iteration 437, loss = 0.08667059\n",
      "Validation score: -0.950275\n",
      "Iteration 438, loss = 0.08608604\n",
      "Validation score: -0.937308\n",
      "Iteration 439, loss = 0.08550464\n",
      "Validation score: -0.924438\n",
      "Iteration 440, loss = 0.08492604\n",
      "Validation score: -0.911634\n",
      "Iteration 441, loss = 0.08435031\n",
      "Validation score: -0.898906\n",
      "Iteration 442, loss = 0.08377763\n",
      "Validation score: -0.886268\n",
      "Iteration 443, loss = 0.08320826\n",
      "Validation score: -0.873725\n",
      "Iteration 444, loss = 0.08264247\n",
      "Validation score: -0.861270\n",
      "Iteration 445, loss = 0.08207967\n",
      "Validation score: -0.848910\n",
      "Iteration 446, loss = 0.08151993\n",
      "Validation score: -0.836646\n",
      "Iteration 447, loss = 0.08096244\n",
      "Validation score: -0.824467\n",
      "Iteration 448, loss = 0.08040735\n",
      "Validation score: -0.812359\n",
      "Iteration 449, loss = 0.07985484\n",
      "Validation score: -0.800324\n",
      "Iteration 450, loss = 0.07930553\n",
      "Validation score: -0.788353\n",
      "Iteration 451, loss = 0.07875904\n",
      "Validation score: -0.776472\n",
      "Iteration 452, loss = 0.07821547\n",
      "Validation score: -0.764710\n",
      "Iteration 453, loss = 0.07767517\n",
      "Validation score: -0.753050\n",
      "Iteration 454, loss = 0.07713818\n",
      "Validation score: -0.741481\n",
      "Iteration 455, loss = 0.07660448\n",
      "Validation score: -0.730004\n",
      "Iteration 456, loss = 0.07607368\n",
      "Validation score: -0.718622\n",
      "Iteration 457, loss = 0.07554577\n",
      "Validation score: -0.707335\n",
      "Iteration 458, loss = 0.07502082\n",
      "Validation score: -0.696102\n",
      "Iteration 459, loss = 0.07449924\n",
      "Validation score: -0.684912\n",
      "Iteration 460, loss = 0.07398096\n",
      "Validation score: -0.673834\n",
      "Iteration 461, loss = 0.07346596\n",
      "Validation score: -0.662873\n",
      "Iteration 462, loss = 0.07295392\n",
      "Validation score: -0.651995\n",
      "Iteration 463, loss = 0.07244503\n",
      "Validation score: -0.641188\n",
      "Iteration 464, loss = 0.07193952\n",
      "Validation score: -0.630460\n",
      "Iteration 465, loss = 0.07143672\n",
      "Validation score: -0.619820\n",
      "Iteration 466, loss = 0.07093672\n",
      "Validation score: -0.609289\n",
      "Iteration 467, loss = 0.07043967\n",
      "Validation score: -0.598860\n",
      "Iteration 468, loss = 0.06994530\n",
      "Validation score: -0.588516\n",
      "Iteration 469, loss = 0.06945394\n",
      "Validation score: -0.578269\n",
      "Iteration 470, loss = 0.06896565\n",
      "Validation score: -0.568102\n",
      "Iteration 471, loss = 0.06847977\n",
      "Validation score: -0.558018\n",
      "Iteration 472, loss = 0.06799701\n",
      "Validation score: -0.548014\n",
      "Iteration 473, loss = 0.06751726\n",
      "Validation score: -0.538093\n",
      "Iteration 474, loss = 0.06704092\n",
      "Validation score: -0.528254\n",
      "Iteration 475, loss = 0.06656739\n",
      "Validation score: -0.518495\n",
      "Iteration 476, loss = 0.06609680\n",
      "Validation score: -0.508812\n",
      "Iteration 477, loss = 0.06562873\n",
      "Validation score: -0.499208\n",
      "Iteration 478, loss = 0.06516368\n",
      "Validation score: -0.489674\n",
      "Iteration 479, loss = 0.06470158\n",
      "Validation score: -0.480214\n",
      "Iteration 480, loss = 0.06424209\n",
      "Validation score: -0.470834\n",
      "Iteration 481, loss = 0.06378580\n",
      "Validation score: -0.461477\n",
      "Iteration 482, loss = 0.06333200\n",
      "Validation score: -0.452155\n",
      "Iteration 483, loss = 0.06288110\n",
      "Validation score: -0.442912\n",
      "Iteration 484, loss = 0.06243318\n",
      "Validation score: -0.433746\n",
      "Iteration 485, loss = 0.06198765\n",
      "Validation score: -0.424647\n",
      "Iteration 486, loss = 0.06154501\n",
      "Validation score: -0.415622\n",
      "Iteration 487, loss = 0.06110536\n",
      "Validation score: -0.406661\n",
      "Iteration 488, loss = 0.06066837\n",
      "Validation score: -0.397774\n",
      "Iteration 489, loss = 0.06023418\n",
      "Validation score: -0.388964\n",
      "Iteration 490, loss = 0.05980263\n",
      "Validation score: -0.380230\n",
      "Iteration 491, loss = 0.05937377\n",
      "Validation score: -0.371571\n",
      "Iteration 492, loss = 0.05894757\n",
      "Validation score: -0.362995\n",
      "Iteration 493, loss = 0.05852405\n",
      "Validation score: -0.354493\n",
      "Iteration 494, loss = 0.05810357\n",
      "Validation score: -0.346119\n",
      "Iteration 495, loss = 0.05768585\n",
      "Validation score: -0.337845\n",
      "Iteration 496, loss = 0.05727065\n",
      "Validation score: -0.329646\n",
      "Iteration 497, loss = 0.05685801\n",
      "Validation score: -0.321488\n",
      "Iteration 498, loss = 0.05644810\n",
      "Validation score: -0.313392\n",
      "Iteration 499, loss = 0.05604067\n",
      "Validation score: -0.305366\n",
      "Iteration 500, loss = 0.05563587\n",
      "Validation score: -0.297411\n",
      "Iteration 501, loss = 0.05523347\n",
      "Validation score: -0.289527\n",
      "Iteration 502, loss = 0.05483348\n",
      "Validation score: -0.281695\n",
      "Iteration 503, loss = 0.05443591\n",
      "Validation score: -0.273912\n",
      "Iteration 504, loss = 0.05404084\n",
      "Validation score: -0.266183\n",
      "Iteration 505, loss = 0.05364773\n",
      "Validation score: -0.258465\n",
      "Iteration 506, loss = 0.05325698\n",
      "Validation score: -0.250820\n",
      "Iteration 507, loss = 0.05286866\n",
      "Validation score: -0.243252\n",
      "Iteration 508, loss = 0.05248291\n",
      "Validation score: -0.235757\n",
      "Iteration 509, loss = 0.05209994\n",
      "Validation score: -0.228337\n",
      "Iteration 510, loss = 0.05171969\n",
      "Validation score: -0.220978\n",
      "Iteration 511, loss = 0.05134094\n",
      "Validation score: -0.213671\n",
      "Iteration 512, loss = 0.05096433\n",
      "Validation score: -0.206430\n",
      "Iteration 513, loss = 0.05058973\n",
      "Validation score: -0.199255\n",
      "Iteration 514, loss = 0.05021720\n",
      "Validation score: -0.192145\n",
      "Iteration 515, loss = 0.04984722\n",
      "Validation score: -0.185101\n",
      "Iteration 516, loss = 0.04947938\n",
      "Validation score: -0.178111\n",
      "Iteration 517, loss = 0.04911395\n",
      "Validation score: -0.171133\n",
      "Iteration 518, loss = 0.04875085\n",
      "Validation score: -0.164222\n",
      "Iteration 519, loss = 0.04839034\n",
      "Validation score: -0.157374\n",
      "Iteration 520, loss = 0.04803199\n",
      "Validation score: -0.150576\n",
      "Iteration 521, loss = 0.04767603\n",
      "Validation score: -0.143842\n",
      "Iteration 522, loss = 0.04732255\n",
      "Validation score: -0.137185\n",
      "Iteration 523, loss = 0.04697134\n",
      "Validation score: -0.130600\n",
      "Iteration 524, loss = 0.04662240\n",
      "Validation score: -0.124084\n",
      "Iteration 525, loss = 0.04627581\n",
      "Validation score: -0.117632\n",
      "Iteration 526, loss = 0.04593147\n",
      "Validation score: -0.111244\n",
      "Iteration 527, loss = 0.04558908\n",
      "Validation score: -0.104916\n",
      "Iteration 528, loss = 0.04524876\n",
      "Validation score: -0.098649\n",
      "Iteration 529, loss = 0.04491075\n",
      "Validation score: -0.092360\n",
      "Iteration 530, loss = 0.04457532\n",
      "Validation score: -0.086119\n",
      "Iteration 531, loss = 0.04424257\n",
      "Validation score: -0.079942\n",
      "Iteration 532, loss = 0.04391237\n",
      "Validation score: -0.073856\n",
      "Iteration 533, loss = 0.04358415\n",
      "Validation score: -0.067833\n",
      "Iteration 534, loss = 0.04325796\n",
      "Validation score: -0.061871\n",
      "Iteration 535, loss = 0.04293399\n",
      "Validation score: -0.055987\n",
      "Iteration 536, loss = 0.04261252\n",
      "Validation score: -0.050177\n",
      "Iteration 537, loss = 0.04229362\n",
      "Validation score: -0.044429\n",
      "Iteration 538, loss = 0.04197728\n",
      "Validation score: -0.038742\n",
      "Iteration 539, loss = 0.04166342\n",
      "Validation score: -0.033116\n",
      "Iteration 540, loss = 0.04135180\n",
      "Validation score: -0.027553\n",
      "Iteration 541, loss = 0.04104262\n",
      "Validation score: -0.022051\n",
      "Iteration 542, loss = 0.04073583\n",
      "Validation score: -0.016609\n",
      "Iteration 543, loss = 0.04043136\n",
      "Validation score: -0.011227\n",
      "Iteration 544, loss = 0.04012921\n",
      "Validation score: -0.005902\n",
      "Iteration 545, loss = 0.03982950\n",
      "Validation score: -0.000638\n",
      "Iteration 546, loss = 0.03953230\n",
      "Validation score: 0.004586\n",
      "Iteration 547, loss = 0.03923754\n",
      "Validation score: 0.009787\n",
      "Iteration 548, loss = 0.03894499\n",
      "Validation score: 0.014929\n",
      "Iteration 549, loss = 0.03865471\n",
      "Validation score: 0.020013\n",
      "Iteration 550, loss = 0.03836690\n",
      "Validation score: 0.025038\n",
      "Iteration 551, loss = 0.03808156\n",
      "Validation score: 0.029997\n",
      "Iteration 552, loss = 0.03779869\n",
      "Validation score: 0.034897\n",
      "Iteration 553, loss = 0.03751830\n",
      "Validation score: 0.039740\n",
      "Iteration 554, loss = 0.03724039\n",
      "Validation score: 0.044517\n",
      "Iteration 555, loss = 0.03696501\n",
      "Validation score: 0.049236\n",
      "Iteration 556, loss = 0.03669188\n",
      "Validation score: 0.053898\n",
      "Iteration 557, loss = 0.03642071\n",
      "Validation score: 0.058506\n",
      "Iteration 558, loss = 0.03615189\n",
      "Validation score: 0.063066\n",
      "Iteration 559, loss = 0.03588562\n",
      "Validation score: 0.067602\n",
      "Iteration 560, loss = 0.03562175\n",
      "Validation score: 0.072083\n",
      "Iteration 561, loss = 0.03536030\n",
      "Validation score: 0.076509\n",
      "Iteration 562, loss = 0.03510135\n",
      "Validation score: 0.080869\n",
      "Iteration 563, loss = 0.03484464\n",
      "Validation score: 0.085175\n",
      "Iteration 564, loss = 0.03459015\n",
      "Validation score: 0.089427\n",
      "Iteration 565, loss = 0.03433807\n",
      "Validation score: 0.093626\n",
      "Iteration 566, loss = 0.03408830\n",
      "Validation score: 0.097772\n",
      "Iteration 567, loss = 0.03384077\n",
      "Validation score: 0.101865\n",
      "Iteration 568, loss = 0.03359550\n",
      "Validation score: 0.105908\n",
      "Iteration 569, loss = 0.03335247\n",
      "Validation score: 0.109899\n",
      "Iteration 570, loss = 0.03311181\n",
      "Validation score: 0.113839\n",
      "Iteration 571, loss = 0.03287347\n",
      "Validation score: 0.117742\n",
      "Iteration 572, loss = 0.03263739\n",
      "Validation score: 0.121590\n",
      "Iteration 573, loss = 0.03240358\n",
      "Validation score: 0.125389\n",
      "Iteration 574, loss = 0.03217204\n",
      "Validation score: 0.129137\n",
      "Iteration 575, loss = 0.03194265\n",
      "Validation score: 0.132837\n",
      "Iteration 576, loss = 0.03171537\n",
      "Validation score: 0.136487\n",
      "Iteration 577, loss = 0.03149040\n",
      "Validation score: 0.140094\n",
      "Iteration 578, loss = 0.03126757\n",
      "Validation score: 0.143658\n",
      "Iteration 579, loss = 0.03104674\n",
      "Validation score: 0.147174\n",
      "Iteration 580, loss = 0.03082816\n",
      "Validation score: 0.150645\n",
      "Iteration 581, loss = 0.03061177\n",
      "Validation score: 0.154069\n",
      "Iteration 582, loss = 0.03039760\n",
      "Validation score: 0.157447\n",
      "Iteration 583, loss = 0.03018559\n",
      "Validation score: 0.160771\n",
      "Iteration 584, loss = 0.02997572\n",
      "Validation score: 0.164046\n",
      "Iteration 585, loss = 0.02976795\n",
      "Validation score: 0.167285\n",
      "Iteration 586, loss = 0.02956223\n",
      "Validation score: 0.170480\n",
      "Iteration 587, loss = 0.02935856\n",
      "Validation score: 0.173630\n",
      "Iteration 588, loss = 0.02915699\n",
      "Validation score: 0.176736\n",
      "Iteration 589, loss = 0.02895746\n",
      "Validation score: 0.179799\n",
      "Iteration 590, loss = 0.02875991\n",
      "Validation score: 0.182819\n",
      "Iteration 591, loss = 0.02856438\n",
      "Validation score: 0.185798\n",
      "Iteration 592, loss = 0.02837089\n",
      "Validation score: 0.188734\n",
      "Iteration 593, loss = 0.02817937\n",
      "Validation score: 0.191631\n",
      "Iteration 594, loss = 0.02798979\n",
      "Validation score: 0.194515\n",
      "Iteration 595, loss = 0.02780213\n",
      "Validation score: 0.197386\n",
      "Iteration 596, loss = 0.02761652\n",
      "Validation score: 0.200223\n",
      "Iteration 597, loss = 0.02743289\n",
      "Validation score: 0.203005\n",
      "Iteration 598, loss = 0.02725125\n",
      "Validation score: 0.205743\n",
      "Iteration 599, loss = 0.02707145\n",
      "Validation score: 0.208433\n",
      "Iteration 600, loss = 0.02689353\n",
      "Validation score: 0.211082\n",
      "Iteration 601, loss = 0.02671744\n",
      "Validation score: 0.213692\n",
      "Iteration 602, loss = 0.02654321\n",
      "Validation score: 0.216265\n",
      "Iteration 603, loss = 0.02637080\n",
      "Validation score: 0.218799\n",
      "Iteration 604, loss = 0.02620021\n",
      "Validation score: 0.221296\n",
      "Iteration 605, loss = 0.02603137\n",
      "Validation score: 0.223756\n",
      "Iteration 606, loss = 0.02586427\n",
      "Validation score: 0.226179\n",
      "Iteration 607, loss = 0.02569892\n",
      "Validation score: 0.228567\n",
      "Iteration 608, loss = 0.02553527\n",
      "Validation score: 0.230920\n",
      "Iteration 609, loss = 0.02537331\n",
      "Validation score: 0.233237\n",
      "Iteration 610, loss = 0.02521295\n",
      "Validation score: 0.235521\n",
      "Iteration 611, loss = 0.02505420\n",
      "Validation score: 0.237773\n",
      "Iteration 612, loss = 0.02489698\n",
      "Validation score: 0.239992\n",
      "Iteration 613, loss = 0.02474148\n",
      "Validation score: 0.242159\n",
      "Iteration 614, loss = 0.02458770\n",
      "Validation score: 0.244283\n",
      "Iteration 615, loss = 0.02443553\n",
      "Validation score: 0.246376\n",
      "Iteration 616, loss = 0.02428493\n",
      "Validation score: 0.248436\n",
      "Iteration 617, loss = 0.02413600\n",
      "Validation score: 0.250473\n",
      "Iteration 618, loss = 0.02398867\n",
      "Validation score: 0.252481\n",
      "Iteration 619, loss = 0.02384292\n",
      "Validation score: 0.254460\n",
      "Iteration 620, loss = 0.02369875\n",
      "Validation score: 0.256409\n",
      "Iteration 621, loss = 0.02355633\n",
      "Validation score: 0.258330\n",
      "Iteration 622, loss = 0.02341551\n",
      "Validation score: 0.260219\n",
      "Iteration 623, loss = 0.02327630\n",
      "Validation score: 0.262076\n",
      "Iteration 624, loss = 0.02313861\n",
      "Validation score: 0.263905\n",
      "Iteration 625, loss = 0.02300242\n",
      "Validation score: 0.265707\n",
      "Iteration 626, loss = 0.02286771\n",
      "Validation score: 0.267482\n",
      "Iteration 627, loss = 0.02273439\n",
      "Validation score: 0.269229\n",
      "Iteration 628, loss = 0.02260251\n",
      "Validation score: 0.270954\n",
      "Iteration 629, loss = 0.02247208\n",
      "Validation score: 0.272652\n",
      "Iteration 630, loss = 0.02234307\n",
      "Validation score: 0.274325\n",
      "Iteration 631, loss = 0.02221550\n",
      "Validation score: 0.275972\n",
      "Iteration 632, loss = 0.02208936\n",
      "Validation score: 0.277601\n",
      "Iteration 633, loss = 0.02196465\n",
      "Validation score: 0.279210\n",
      "Iteration 634, loss = 0.02184131\n",
      "Validation score: 0.280794\n",
      "Iteration 635, loss = 0.02171931\n",
      "Validation score: 0.282354\n",
      "Iteration 636, loss = 0.02159863\n",
      "Validation score: 0.283890\n",
      "Iteration 637, loss = 0.02147930\n",
      "Validation score: 0.285402\n",
      "Iteration 638, loss = 0.02136133\n",
      "Validation score: 0.286890\n",
      "Iteration 639, loss = 0.02124473\n",
      "Validation score: 0.288356\n",
      "Iteration 640, loss = 0.02112937\n",
      "Validation score: 0.289797\n",
      "Iteration 641, loss = 0.02101531\n",
      "Validation score: 0.291210\n",
      "Iteration 642, loss = 0.02090255\n",
      "Validation score: 0.292602\n",
      "Iteration 643, loss = 0.02079112\n",
      "Validation score: 0.293971\n",
      "Iteration 644, loss = 0.02068094\n",
      "Validation score: 0.295319\n",
      "Iteration 645, loss = 0.02057197\n",
      "Validation score: 0.296646\n",
      "Iteration 646, loss = 0.02046413\n",
      "Validation score: 0.297949\n",
      "Iteration 647, loss = 0.02035740\n",
      "Validation score: 0.299233\n",
      "Iteration 648, loss = 0.02025179\n",
      "Validation score: 0.300496\n",
      "Iteration 649, loss = 0.02014723\n",
      "Validation score: 0.301740\n",
      "Iteration 650, loss = 0.02004375\n",
      "Validation score: 0.302964\n",
      "Iteration 651, loss = 0.01994135\n",
      "Validation score: 0.304169\n",
      "Iteration 652, loss = 0.01984007\n",
      "Validation score: 0.305357\n",
      "Iteration 653, loss = 0.01973993\n",
      "Validation score: 0.306527\n",
      "Iteration 654, loss = 0.01964092\n",
      "Validation score: 0.307678\n",
      "Iteration 655, loss = 0.01954304\n",
      "Validation score: 0.308811\n",
      "Iteration 656, loss = 0.01944627\n",
      "Validation score: 0.309927\n",
      "Iteration 657, loss = 0.01935064\n",
      "Validation score: 0.311025\n",
      "Iteration 658, loss = 0.01925625\n",
      "Validation score: 0.312105\n",
      "Iteration 659, loss = 0.01916296\n",
      "Validation score: 0.313170\n",
      "Iteration 660, loss = 0.01907078\n",
      "Validation score: 0.314219\n",
      "Iteration 661, loss = 0.01897964\n",
      "Validation score: 0.315253\n",
      "Iteration 662, loss = 0.01888954\n",
      "Validation score: 0.316276\n",
      "Iteration 663, loss = 0.01880047\n",
      "Validation score: 0.317282\n",
      "Iteration 664, loss = 0.01871245\n",
      "Validation score: 0.318274\n",
      "Iteration 665, loss = 0.01862545\n",
      "Validation score: 0.319256\n",
      "Iteration 666, loss = 0.01853946\n",
      "Validation score: 0.320225\n",
      "Iteration 667, loss = 0.01845444\n",
      "Validation score: 0.321187\n",
      "Iteration 668, loss = 0.01837040\n",
      "Validation score: 0.322135\n",
      "Iteration 669, loss = 0.01828733\n",
      "Validation score: 0.323073\n",
      "Iteration 670, loss = 0.01820518\n",
      "Validation score: 0.324000\n",
      "Iteration 671, loss = 0.01812398\n",
      "Validation score: 0.324913\n",
      "Iteration 672, loss = 0.01804372\n",
      "Validation score: 0.325813\n",
      "Iteration 673, loss = 0.01796435\n",
      "Validation score: 0.326699\n",
      "Iteration 674, loss = 0.01788590\n",
      "Validation score: 0.327571\n",
      "Iteration 675, loss = 0.01780838\n",
      "Validation score: 0.328431\n",
      "Iteration 676, loss = 0.01773175\n",
      "Validation score: 0.329278\n",
      "Iteration 677, loss = 0.01765601\n",
      "Validation score: 0.330112\n",
      "Iteration 678, loss = 0.01758115\n",
      "Validation score: 0.330934\n",
      "Iteration 679, loss = 0.01750718\n",
      "Validation score: 0.331754\n",
      "Iteration 680, loss = 0.01743409\n",
      "Validation score: 0.332562\n",
      "Iteration 681, loss = 0.01736186\n",
      "Validation score: 0.333359\n",
      "Iteration 682, loss = 0.01729058\n",
      "Validation score: 0.334141\n",
      "Iteration 683, loss = 0.01722015\n",
      "Validation score: 0.334908\n",
      "Iteration 684, loss = 0.01715051\n",
      "Validation score: 0.335656\n",
      "Iteration 685, loss = 0.01708166\n",
      "Validation score: 0.336388\n",
      "Iteration 686, loss = 0.01701358\n",
      "Validation score: 0.337109\n",
      "Iteration 687, loss = 0.01694627\n",
      "Validation score: 0.337820\n",
      "Iteration 688, loss = 0.01687986\n",
      "Validation score: 0.338521\n",
      "Iteration 689, loss = 0.01681422\n",
      "Validation score: 0.339212\n",
      "Iteration 690, loss = 0.01674934\n",
      "Validation score: 0.339893\n",
      "Iteration 691, loss = 0.01668521\n",
      "Validation score: 0.340565\n",
      "Iteration 692, loss = 0.01662181\n",
      "Validation score: 0.341229\n",
      "Iteration 693, loss = 0.01655915\n",
      "Validation score: 0.341883\n",
      "Iteration 694, loss = 0.01649722\n",
      "Validation score: 0.342528\n",
      "Iteration 695, loss = 0.01643602\n",
      "Validation score: 0.343163\n",
      "Iteration 696, loss = 0.01637560\n",
      "Validation score: 0.343784\n",
      "Iteration 697, loss = 0.01631590\n",
      "Validation score: 0.344399\n",
      "Iteration 698, loss = 0.01625685\n",
      "Validation score: 0.345004\n",
      "Iteration 699, loss = 0.01619848\n",
      "Validation score: 0.345602\n",
      "Iteration 700, loss = 0.01614084\n",
      "Validation score: 0.346188\n",
      "Iteration 701, loss = 0.01608390\n",
      "Validation score: 0.346764\n",
      "Iteration 702, loss = 0.01602764\n",
      "Validation score: 0.347331\n",
      "Iteration 703, loss = 0.01597205\n",
      "Validation score: 0.347891\n",
      "Iteration 704, loss = 0.01591716\n",
      "Validation score: 0.348443\n",
      "Iteration 705, loss = 0.01586292\n",
      "Validation score: 0.348987\n",
      "Iteration 706, loss = 0.01580932\n",
      "Validation score: 0.349528\n",
      "Iteration 707, loss = 0.01575638\n",
      "Validation score: 0.350066\n",
      "Iteration 708, loss = 0.01570407\n",
      "Validation score: 0.350597\n",
      "Iteration 709, loss = 0.01565237\n",
      "Validation score: 0.351122\n",
      "Iteration 710, loss = 0.01560129\n",
      "Validation score: 0.351641\n",
      "Iteration 711, loss = 0.01555081\n",
      "Validation score: 0.352153\n",
      "Iteration 712, loss = 0.01550093\n",
      "Validation score: 0.352659\n",
      "Iteration 713, loss = 0.01545168\n",
      "Validation score: 0.353160\n",
      "Iteration 714, loss = 0.01540302\n",
      "Validation score: 0.353655\n",
      "Iteration 715, loss = 0.01535495\n",
      "Validation score: 0.354147\n",
      "Iteration 716, loss = 0.01530744\n",
      "Validation score: 0.354635\n",
      "Iteration 717, loss = 0.01526050\n",
      "Validation score: 0.355117\n",
      "Iteration 718, loss = 0.01521411\n",
      "Validation score: 0.355595\n",
      "Iteration 719, loss = 0.01516826\n",
      "Validation score: 0.356067\n",
      "Iteration 720, loss = 0.01512293\n",
      "Validation score: 0.356535\n",
      "Iteration 721, loss = 0.01507814\n",
      "Validation score: 0.357008\n",
      "Iteration 722, loss = 0.01503388\n",
      "Validation score: 0.357478\n",
      "Iteration 723, loss = 0.01499013\n",
      "Validation score: 0.357943\n",
      "Iteration 724, loss = 0.01494687\n",
      "Validation score: 0.358400\n",
      "Iteration 725, loss = 0.01490411\n",
      "Validation score: 0.358853\n",
      "Iteration 726, loss = 0.01486187\n",
      "Validation score: 0.359302\n",
      "Iteration 727, loss = 0.01482015\n",
      "Validation score: 0.359747\n",
      "Iteration 728, loss = 0.01477892\n",
      "Validation score: 0.360188\n",
      "Iteration 729, loss = 0.01473818\n",
      "Validation score: 0.360627\n",
      "Iteration 730, loss = 0.01469792\n",
      "Validation score: 0.361061\n",
      "Iteration 731, loss = 0.01465813\n",
      "Validation score: 0.361482\n",
      "Iteration 732, loss = 0.01461881\n",
      "Validation score: 0.361900\n",
      "Iteration 733, loss = 0.01457992\n",
      "Validation score: 0.362316\n",
      "Iteration 734, loss = 0.01454148\n",
      "Validation score: 0.362730\n",
      "Iteration 735, loss = 0.01450346\n",
      "Validation score: 0.363141\n",
      "Iteration 736, loss = 0.01446585\n",
      "Validation score: 0.363550\n",
      "Iteration 737, loss = 0.01442865\n",
      "Validation score: 0.363946\n",
      "Iteration 738, loss = 0.01439185\n",
      "Validation score: 0.364338\n",
      "Iteration 739, loss = 0.01435545\n",
      "Validation score: 0.364728\n",
      "Iteration 740, loss = 0.01431946\n",
      "Validation score: 0.365116\n",
      "Iteration 741, loss = 0.01428389\n",
      "Validation score: 0.365499\n",
      "Iteration 742, loss = 0.01424871\n",
      "Validation score: 0.365879\n",
      "Iteration 743, loss = 0.01421394\n",
      "Validation score: 0.366258\n",
      "Iteration 744, loss = 0.01417959\n",
      "Validation score: 0.366639\n",
      "Iteration 745, loss = 0.01414564\n",
      "Validation score: 0.367017\n",
      "Iteration 746, loss = 0.01411208\n",
      "Validation score: 0.367394\n",
      "Iteration 747, loss = 0.01407889\n",
      "Validation score: 0.367770\n",
      "Iteration 748, loss = 0.01404606\n",
      "Validation score: 0.368144\n",
      "Iteration 749, loss = 0.01401355\n",
      "Validation score: 0.368517\n",
      "Iteration 750, loss = 0.01398136\n",
      "Validation score: 0.368889\n",
      "Iteration 751, loss = 0.01394953\n",
      "Validation score: 0.369250\n",
      "Iteration 752, loss = 0.01391804\n",
      "Validation score: 0.369602\n",
      "Iteration 753, loss = 0.01388690\n",
      "Validation score: 0.369953\n",
      "Iteration 754, loss = 0.01385612\n",
      "Validation score: 0.370306\n",
      "Iteration 755, loss = 0.01382572\n",
      "Validation score: 0.370662\n",
      "Iteration 756, loss = 0.01379567\n",
      "Validation score: 0.371016\n",
      "Iteration 757, loss = 0.01376595\n",
      "Validation score: 0.371369\n",
      "Iteration 758, loss = 0.01373652\n",
      "Validation score: 0.371720\n",
      "Iteration 759, loss = 0.01370741\n",
      "Validation score: 0.372071\n",
      "Iteration 760, loss = 0.01367860\n",
      "Validation score: 0.372414\n",
      "Iteration 761, loss = 0.01365011\n",
      "Validation score: 0.372757\n",
      "Iteration 762, loss = 0.01362192\n",
      "Validation score: 0.373098\n",
      "Iteration 763, loss = 0.01359403\n",
      "Validation score: 0.373439\n",
      "Iteration 764, loss = 0.01356642\n",
      "Validation score: 0.373779\n",
      "Iteration 765, loss = 0.01353909\n",
      "Validation score: 0.374118\n",
      "Iteration 766, loss = 0.01351205\n",
      "Validation score: 0.374456\n",
      "Iteration 767, loss = 0.01348530\n",
      "Validation score: 0.374794\n",
      "Iteration 768, loss = 0.01345881\n",
      "Validation score: 0.375132\n",
      "Iteration 769, loss = 0.01343260\n",
      "Validation score: 0.375469\n",
      "Iteration 770, loss = 0.01340666\n",
      "Validation score: 0.375806\n",
      "Iteration 771, loss = 0.01338096\n",
      "Validation score: 0.376143\n",
      "Iteration 772, loss = 0.01335551\n",
      "Validation score: 0.376480\n",
      "Iteration 773, loss = 0.01333032\n",
      "Validation score: 0.376817\n",
      "Iteration 774, loss = 0.01330538\n",
      "Validation score: 0.377154\n",
      "Iteration 775, loss = 0.01328069\n",
      "Validation score: 0.377491\n",
      "Iteration 776, loss = 0.01325624\n",
      "Validation score: 0.377828\n",
      "Iteration 777, loss = 0.01323203\n",
      "Validation score: 0.378165\n",
      "Iteration 778, loss = 0.01320805\n",
      "Validation score: 0.378502\n",
      "Iteration 779, loss = 0.01318431\n",
      "Validation score: 0.378840\n",
      "Iteration 780, loss = 0.01316080\n",
      "Validation score: 0.379178\n",
      "Iteration 781, loss = 0.01313751\n",
      "Validation score: 0.379516\n",
      "Iteration 782, loss = 0.01311442\n",
      "Validation score: 0.379854\n",
      "Iteration 783, loss = 0.01309156\n",
      "Validation score: 0.380191\n",
      "Iteration 784, loss = 0.01306891\n",
      "Validation score: 0.380527\n",
      "Iteration 785, loss = 0.01304648\n",
      "Validation score: 0.380865\n",
      "Iteration 786, loss = 0.01302427\n",
      "Validation score: 0.381203\n",
      "Iteration 787, loss = 0.01300229\n",
      "Validation score: 0.381541\n",
      "Iteration 788, loss = 0.01298053\n",
      "Validation score: 0.381880\n",
      "Iteration 789, loss = 0.01295899\n",
      "Validation score: 0.382220\n",
      "Iteration 790, loss = 0.01293764\n",
      "Validation score: 0.382561\n",
      "Iteration 791, loss = 0.01291649\n",
      "Validation score: 0.382903\n",
      "Iteration 792, loss = 0.01289553\n",
      "Validation score: 0.383246\n",
      "Iteration 793, loss = 0.01287476\n",
      "Validation score: 0.383590\n",
      "Iteration 794, loss = 0.01285419\n",
      "Validation score: 0.383937\n",
      "Iteration 795, loss = 0.01283380\n",
      "Validation score: 0.384286\n",
      "Iteration 796, loss = 0.01281356\n",
      "Validation score: 0.384637\n",
      "Iteration 797, loss = 0.01279348\n",
      "Validation score: 0.384988\n",
      "Iteration 798, loss = 0.01277358\n",
      "Validation score: 0.385340\n",
      "Iteration 799, loss = 0.01275385\n",
      "Validation score: 0.385694\n",
      "Iteration 800, loss = 0.01273429\n",
      "Validation score: 0.386048\n",
      "Iteration 801, loss = 0.01271489\n",
      "Validation score: 0.386404\n",
      "Iteration 802, loss = 0.01269566\n",
      "Validation score: 0.386760\n",
      "Iteration 803, loss = 0.01267658\n",
      "Validation score: 0.387117\n",
      "Iteration 804, loss = 0.01265767\n",
      "Validation score: 0.387476\n",
      "Iteration 805, loss = 0.01263890\n",
      "Validation score: 0.387836\n",
      "Iteration 806, loss = 0.01262029\n",
      "Validation score: 0.388196\n",
      "Iteration 807, loss = 0.01260182\n",
      "Validation score: 0.388558\n",
      "Iteration 808, loss = 0.01258352\n",
      "Validation score: 0.388920\n",
      "Iteration 809, loss = 0.01256537\n",
      "Validation score: 0.389284\n",
      "Iteration 810, loss = 0.01254738\n",
      "Validation score: 0.389649\n",
      "Iteration 811, loss = 0.01252953\n",
      "Validation score: 0.390015\n",
      "Iteration 812, loss = 0.01251182\n",
      "Validation score: 0.390382\n",
      "Iteration 813, loss = 0.01249425\n",
      "Validation score: 0.390750\n",
      "Iteration 814, loss = 0.01247683\n",
      "Validation score: 0.391119\n",
      "Iteration 815, loss = 0.01245954\n",
      "Validation score: 0.391489\n",
      "Iteration 816, loss = 0.01244239\n",
      "Validation score: 0.391860\n",
      "Iteration 817, loss = 0.01242540\n",
      "Validation score: 0.392232\n",
      "Iteration 818, loss = 0.01240855\n",
      "Validation score: 0.392605\n",
      "Iteration 819, loss = 0.01239182\n",
      "Validation score: 0.392978\n",
      "Iteration 820, loss = 0.01237521\n",
      "Validation score: 0.393353\n",
      "Iteration 821, loss = 0.01235872\n",
      "Validation score: 0.393728\n",
      "Iteration 822, loss = 0.01234234\n",
      "Validation score: 0.394105\n",
      "Iteration 823, loss = 0.01232610\n",
      "Validation score: 0.394482\n",
      "Iteration 824, loss = 0.01230997\n",
      "Validation score: 0.394861\n",
      "Iteration 825, loss = 0.01229396\n",
      "Validation score: 0.395240\n",
      "Iteration 826, loss = 0.01227807\n",
      "Validation score: 0.395620\n",
      "Iteration 827, loss = 0.01226233\n",
      "Validation score: 0.396002\n",
      "Iteration 828, loss = 0.01224670\n",
      "Validation score: 0.396384\n",
      "Iteration 829, loss = 0.01223123\n",
      "Validation score: 0.396767\n",
      "Iteration 830, loss = 0.01221591\n",
      "Validation score: 0.397150\n",
      "Iteration 831, loss = 0.01220066\n",
      "Validation score: 0.397535\n",
      "Iteration 832, loss = 0.01218549\n",
      "Validation score: 0.397921\n",
      "Iteration 833, loss = 0.01217043\n",
      "Validation score: 0.398308\n",
      "Iteration 834, loss = 0.01215548\n",
      "Validation score: 0.398696\n",
      "Iteration 835, loss = 0.01214061\n",
      "Validation score: 0.399085\n",
      "Iteration 836, loss = 0.01212582\n",
      "Validation score: 0.399476\n",
      "Iteration 837, loss = 0.01211113\n",
      "Validation score: 0.399870\n",
      "Iteration 838, loss = 0.01209653\n",
      "Validation score: 0.400265\n",
      "Iteration 839, loss = 0.01208202\n",
      "Validation score: 0.400661\n",
      "Iteration 840, loss = 0.01206760\n",
      "Validation score: 0.401058\n",
      "Iteration 841, loss = 0.01205327\n",
      "Validation score: 0.401457\n",
      "Iteration 842, loss = 0.01203903\n",
      "Validation score: 0.401856\n",
      "Iteration 843, loss = 0.01202487\n",
      "Validation score: 0.402256\n",
      "Iteration 844, loss = 0.01201078\n",
      "Validation score: 0.402658\n",
      "Iteration 845, loss = 0.01199678\n",
      "Validation score: 0.403060\n",
      "Iteration 846, loss = 0.01198286\n",
      "Validation score: 0.403464\n",
      "Iteration 847, loss = 0.01196902\n",
      "Validation score: 0.403868\n",
      "Iteration 848, loss = 0.01195526\n",
      "Validation score: 0.404273\n",
      "Iteration 849, loss = 0.01194159\n",
      "Validation score: 0.404679\n",
      "Iteration 850, loss = 0.01192799\n",
      "Validation score: 0.405086\n",
      "Iteration 851, loss = 0.01191448\n",
      "Validation score: 0.405494\n",
      "Iteration 852, loss = 0.01190104\n",
      "Validation score: 0.405901\n",
      "Iteration 853, loss = 0.01188767\n",
      "Validation score: 0.406310\n",
      "Iteration 854, loss = 0.01187436\n",
      "Validation score: 0.406721\n",
      "Iteration 855, loss = 0.01186113\n",
      "Validation score: 0.407132\n",
      "Iteration 856, loss = 0.01184798\n",
      "Validation score: 0.407545\n",
      "Iteration 857, loss = 0.01183490\n",
      "Validation score: 0.407959\n",
      "Iteration 858, loss = 0.01182189\n",
      "Validation score: 0.408373\n",
      "Iteration 859, loss = 0.01180895\n",
      "Validation score: 0.408789\n",
      "Iteration 860, loss = 0.01179608\n",
      "Validation score: 0.409206\n",
      "Iteration 861, loss = 0.01178329\n",
      "Validation score: 0.409624\n",
      "Iteration 862, loss = 0.01177056\n",
      "Validation score: 0.410043\n",
      "Iteration 863, loss = 0.01175791\n",
      "Validation score: 0.410464\n",
      "Iteration 864, loss = 0.01174532\n",
      "Validation score: 0.410885\n",
      "Iteration 865, loss = 0.01173277\n",
      "Validation score: 0.411307\n",
      "Iteration 866, loss = 0.01172029\n",
      "Validation score: 0.411730\n",
      "Iteration 867, loss = 0.01170786\n",
      "Validation score: 0.412154\n",
      "Iteration 868, loss = 0.01169550\n",
      "Validation score: 0.412580\n",
      "Iteration 869, loss = 0.01168319\n",
      "Validation score: 0.413006\n",
      "Iteration 870, loss = 0.01167095\n",
      "Validation score: 0.413433\n",
      "Iteration 871, loss = 0.01165877\n",
      "Validation score: 0.413863\n",
      "Iteration 872, loss = 0.01164665\n",
      "Validation score: 0.414294\n",
      "Iteration 873, loss = 0.01163458\n",
      "Validation score: 0.414726\n",
      "Iteration 874, loss = 0.01162258\n",
      "Validation score: 0.415160\n",
      "Iteration 875, loss = 0.01161070\n",
      "Validation score: 0.415593\n",
      "Iteration 876, loss = 0.01159890\n",
      "Validation score: 0.416027\n",
      "Iteration 877, loss = 0.01158715\n",
      "Validation score: 0.416462\n",
      "Iteration 878, loss = 0.01157546\n",
      "Validation score: 0.416897\n",
      "Iteration 879, loss = 0.01156381\n",
      "Validation score: 0.417333\n",
      "Iteration 880, loss = 0.01155222\n",
      "Validation score: 0.417770\n",
      "Iteration 881, loss = 0.01154067\n",
      "Validation score: 0.418208\n",
      "Iteration 882, loss = 0.01152919\n",
      "Validation score: 0.418647\n",
      "Iteration 883, loss = 0.01151777\n",
      "Validation score: 0.419085\n",
      "Iteration 884, loss = 0.01150638\n",
      "Validation score: 0.419525\n",
      "Iteration 885, loss = 0.01149504\n",
      "Validation score: 0.419966\n",
      "Iteration 886, loss = 0.01148375\n",
      "Validation score: 0.420407\n",
      "Iteration 887, loss = 0.01147251\n",
      "Validation score: 0.420849\n",
      "Iteration 888, loss = 0.01146133\n",
      "Validation score: 0.421292\n",
      "Iteration 889, loss = 0.01145021\n",
      "Validation score: 0.421735\n",
      "Iteration 890, loss = 0.01143915\n",
      "Validation score: 0.422178\n",
      "Iteration 891, loss = 0.01142813\n",
      "Validation score: 0.422622\n",
      "Iteration 892, loss = 0.01141716\n",
      "Validation score: 0.423066\n",
      "Iteration 893, loss = 0.01140624\n",
      "Validation score: 0.423511\n",
      "Iteration 894, loss = 0.01139536\n",
      "Validation score: 0.423956\n",
      "Iteration 895, loss = 0.01138453\n",
      "Validation score: 0.424401\n",
      "Iteration 896, loss = 0.01137375\n",
      "Validation score: 0.424848\n",
      "Iteration 897, loss = 0.01136301\n",
      "Validation score: 0.425294\n",
      "Iteration 898, loss = 0.01135232\n",
      "Validation score: 0.425742\n",
      "Iteration 899, loss = 0.01134166\n",
      "Validation score: 0.426190\n",
      "Iteration 900, loss = 0.01133109\n",
      "Validation score: 0.426637\n",
      "Iteration 901, loss = 0.01132063\n",
      "Validation score: 0.427084\n",
      "Iteration 902, loss = 0.01131022\n",
      "Validation score: 0.427532\n",
      "Iteration 903, loss = 0.01129987\n",
      "Validation score: 0.427979\n",
      "Iteration 904, loss = 0.01128955\n",
      "Validation score: 0.428426\n",
      "Iteration 905, loss = 0.01127929\n",
      "Validation score: 0.428874\n",
      "Iteration 906, loss = 0.01126907\n",
      "Validation score: 0.429322\n",
      "Iteration 907, loss = 0.01125889\n",
      "Validation score: 0.429770\n",
      "Iteration 908, loss = 0.01124876\n",
      "Validation score: 0.430218\n",
      "Iteration 909, loss = 0.01123868\n",
      "Validation score: 0.430666\n",
      "Iteration 910, loss = 0.01122866\n",
      "Validation score: 0.431114\n",
      "Iteration 911, loss = 0.01121869\n",
      "Validation score: 0.431562\n",
      "Iteration 912, loss = 0.01120877\n",
      "Validation score: 0.432010\n",
      "Iteration 913, loss = 0.01119890\n",
      "Validation score: 0.432458\n",
      "Iteration 914, loss = 0.01118907\n",
      "Validation score: 0.432907\n",
      "Iteration 915, loss = 0.01117927\n",
      "Validation score: 0.433355\n",
      "Iteration 916, loss = 0.01116951\n",
      "Validation score: 0.433804\n",
      "Iteration 917, loss = 0.01115979\n",
      "Validation score: 0.434253\n",
      "Iteration 918, loss = 0.01115011\n",
      "Validation score: 0.434702\n",
      "Iteration 919, loss = 0.01114047\n",
      "Validation score: 0.435151\n",
      "Iteration 920, loss = 0.01113086\n",
      "Validation score: 0.435601\n",
      "Iteration 921, loss = 0.01112130\n",
      "Validation score: 0.436052\n",
      "Iteration 922, loss = 0.01111175\n",
      "Validation score: 0.436512\n",
      "Iteration 923, loss = 0.01110224\n",
      "Validation score: 0.436972\n",
      "Iteration 924, loss = 0.01109276\n",
      "Validation score: 0.437431\n",
      "Iteration 925, loss = 0.01108332\n",
      "Validation score: 0.437892\n",
      "Iteration 926, loss = 0.01107389\n",
      "Validation score: 0.438352\n",
      "Iteration 927, loss = 0.01106450\n",
      "Validation score: 0.438812\n",
      "Iteration 928, loss = 0.01105515\n",
      "Validation score: 0.439273\n",
      "Iteration 929, loss = 0.01104583\n",
      "Validation score: 0.439734\n",
      "Iteration 930, loss = 0.01103653\n",
      "Validation score: 0.440196\n",
      "Iteration 931, loss = 0.01102727\n",
      "Validation score: 0.440655\n",
      "Iteration 932, loss = 0.01101804\n",
      "Validation score: 0.441112\n",
      "Iteration 933, loss = 0.01100884\n",
      "Validation score: 0.441568\n",
      "Iteration 934, loss = 0.01099967\n",
      "Validation score: 0.442025\n",
      "Iteration 935, loss = 0.01099056\n",
      "Validation score: 0.442480\n",
      "Iteration 936, loss = 0.01098151\n",
      "Validation score: 0.442934\n",
      "Iteration 937, loss = 0.01097250\n",
      "Validation score: 0.443388\n",
      "Iteration 938, loss = 0.01096352\n",
      "Validation score: 0.443842\n",
      "Iteration 939, loss = 0.01095457\n",
      "Validation score: 0.444296\n",
      "Iteration 940, loss = 0.01094566\n",
      "Validation score: 0.444750\n",
      "Iteration 941, loss = 0.01093677\n",
      "Validation score: 0.445203\n",
      "Iteration 942, loss = 0.01092790\n",
      "Validation score: 0.445657\n",
      "Iteration 943, loss = 0.01091906\n",
      "Validation score: 0.446110\n",
      "Iteration 944, loss = 0.01091024\n",
      "Validation score: 0.446567\n",
      "Iteration 945, loss = 0.01090144\n",
      "Validation score: 0.447031\n",
      "Iteration 946, loss = 0.01089267\n",
      "Validation score: 0.447495\n",
      "Iteration 947, loss = 0.01088392\n",
      "Validation score: 0.447959\n",
      "Iteration 948, loss = 0.01087520\n",
      "Validation score: 0.448423\n",
      "Iteration 949, loss = 0.01086651\n",
      "Validation score: 0.448891\n",
      "Iteration 950, loss = 0.01085784\n",
      "Validation score: 0.449367\n",
      "Iteration 951, loss = 0.01084920\n",
      "Validation score: 0.449843\n",
      "Iteration 952, loss = 0.01084058\n",
      "Validation score: 0.450319\n",
      "Iteration 953, loss = 0.01083199\n",
      "Validation score: 0.450796\n",
      "Iteration 954, loss = 0.01082340\n",
      "Validation score: 0.451273\n",
      "Iteration 955, loss = 0.01081482\n",
      "Validation score: 0.451752\n",
      "Iteration 956, loss = 0.01080626\n",
      "Validation score: 0.452231\n",
      "Iteration 957, loss = 0.01079773\n",
      "Validation score: 0.452711\n",
      "Iteration 958, loss = 0.01078923\n",
      "Validation score: 0.453191\n",
      "Iteration 959, loss = 0.01078077\n",
      "Validation score: 0.453671\n",
      "Iteration 960, loss = 0.01077233\n",
      "Validation score: 0.454152\n",
      "Iteration 961, loss = 0.01076391\n",
      "Validation score: 0.454632\n",
      "Iteration 962, loss = 0.01075551\n",
      "Validation score: 0.455112\n",
      "Iteration 963, loss = 0.01074713\n",
      "Validation score: 0.455592\n",
      "Iteration 964, loss = 0.01073878\n",
      "Validation score: 0.456073\n",
      "Iteration 965, loss = 0.01073044\n",
      "Validation score: 0.456554\n",
      "Iteration 966, loss = 0.01072212\n",
      "Validation score: 0.457035\n",
      "Iteration 967, loss = 0.01071380\n",
      "Validation score: 0.457518\n",
      "Iteration 968, loss = 0.01070550\n",
      "Validation score: 0.458000\n",
      "Iteration 969, loss = 0.01069722\n",
      "Validation score: 0.458483\n",
      "Iteration 970, loss = 0.01068897\n",
      "Validation score: 0.458967\n",
      "Iteration 971, loss = 0.01068075\n",
      "Validation score: 0.459451\n",
      "Iteration 972, loss = 0.01067255\n",
      "Validation score: 0.459934\n",
      "Iteration 973, loss = 0.01066437\n",
      "Validation score: 0.460418\n",
      "Iteration 974, loss = 0.01065621\n",
      "Validation score: 0.460902\n",
      "Iteration 975, loss = 0.01064809\n",
      "Validation score: 0.461385\n",
      "Iteration 976, loss = 0.01064000\n",
      "Validation score: 0.461868\n",
      "Iteration 977, loss = 0.01063193\n",
      "Validation score: 0.462350\n",
      "Iteration 978, loss = 0.01062389\n",
      "Validation score: 0.462832\n",
      "Iteration 979, loss = 0.01061586\n",
      "Validation score: 0.463314\n",
      "Iteration 980, loss = 0.01060786\n",
      "Validation score: 0.463795\n",
      "Iteration 981, loss = 0.01059988\n",
      "Validation score: 0.464276\n",
      "Iteration 982, loss = 0.01059192\n",
      "Validation score: 0.464757\n",
      "Iteration 983, loss = 0.01058399\n",
      "Validation score: 0.465237\n",
      "Iteration 984, loss = 0.01057607\n",
      "Validation score: 0.465717\n",
      "Iteration 985, loss = 0.01056818\n",
      "Validation score: 0.466197\n",
      "Iteration 986, loss = 0.01056029\n",
      "Validation score: 0.466677\n",
      "Iteration 987, loss = 0.01055243\n",
      "Validation score: 0.467156\n",
      "Iteration 988, loss = 0.01054459\n",
      "Validation score: 0.467635\n",
      "Iteration 989, loss = 0.01053676\n",
      "Validation score: 0.468115\n",
      "Iteration 990, loss = 0.01052897\n",
      "Validation score: 0.468594\n",
      "Iteration 991, loss = 0.01052119\n",
      "Validation score: 0.469073\n",
      "Iteration 992, loss = 0.01051343\n",
      "Validation score: 0.469552\n",
      "Iteration 993, loss = 0.01050569\n",
      "Validation score: 0.470031\n",
      "Iteration 994, loss = 0.01049798\n",
      "Validation score: 0.470510\n",
      "Iteration 995, loss = 0.01049028\n",
      "Validation score: 0.470988\n",
      "Iteration 996, loss = 0.01048261\n",
      "Validation score: 0.471467\n",
      "Iteration 997, loss = 0.01047495\n",
      "Validation score: 0.471945\n",
      "Iteration 998, loss = 0.01046731\n",
      "Validation score: 0.472423\n",
      "Iteration 999, loss = 0.01045967\n",
      "Validation score: 0.472902\n",
      "Iteration 1000, loss = 0.01045205\n",
      "Validation score: 0.473382\n",
      "Iteration 1001, loss = 0.01044445\n",
      "Validation score: 0.473862\n",
      "Iteration 1002, loss = 0.01043686\n",
      "Validation score: 0.474342\n",
      "Iteration 1003, loss = 0.01042929\n",
      "Validation score: 0.474822\n",
      "Iteration 1004, loss = 0.01042173\n",
      "Validation score: 0.475300\n",
      "Iteration 1005, loss = 0.01041419\n",
      "Validation score: 0.475778\n",
      "Iteration 1006, loss = 0.01040668\n",
      "Validation score: 0.476256\n",
      "Iteration 1007, loss = 0.01039917\n",
      "Validation score: 0.476734\n",
      "Iteration 1008, loss = 0.01039169\n",
      "Validation score: 0.477212\n",
      "Iteration 1009, loss = 0.01038422\n",
      "Validation score: 0.477690\n",
      "Iteration 1010, loss = 0.01037677\n",
      "Validation score: 0.478168\n",
      "Iteration 1011, loss = 0.01036934\n",
      "Validation score: 0.478645\n",
      "Iteration 1012, loss = 0.01036193\n",
      "Validation score: 0.479122\n",
      "Iteration 1013, loss = 0.01035453\n",
      "Validation score: 0.479598\n",
      "Iteration 1014, loss = 0.01034716\n",
      "Validation score: 0.480074\n",
      "Iteration 1015, loss = 0.01033983\n",
      "Validation score: 0.480548\n",
      "Iteration 1016, loss = 0.01033252\n",
      "Validation score: 0.481022\n",
      "Iteration 1017, loss = 0.01032524\n",
      "Validation score: 0.481495\n",
      "Iteration 1018, loss = 0.01031797\n",
      "Validation score: 0.481967\n",
      "Iteration 1019, loss = 0.01031072\n",
      "Validation score: 0.482438\n",
      "Iteration 1020, loss = 0.01030349\n",
      "Validation score: 0.482909\n",
      "Iteration 1021, loss = 0.01029627\n",
      "Validation score: 0.483378\n",
      "Iteration 1022, loss = 0.01028908\n",
      "Validation score: 0.483847\n",
      "Iteration 1023, loss = 0.01028189\n",
      "Validation score: 0.484317\n",
      "Iteration 1024, loss = 0.01027471\n",
      "Validation score: 0.484785\n",
      "Iteration 1025, loss = 0.01026755\n",
      "Validation score: 0.485254\n",
      "Iteration 1026, loss = 0.01026041\n",
      "Validation score: 0.485722\n",
      "Iteration 1027, loss = 0.01025329\n",
      "Validation score: 0.486189\n",
      "Iteration 1028, loss = 0.01024618\n",
      "Validation score: 0.486655\n",
      "Iteration 1029, loss = 0.01023909\n",
      "Validation score: 0.487120\n",
      "Iteration 1030, loss = 0.01023203\n",
      "Validation score: 0.487586\n",
      "Iteration 1031, loss = 0.01022498\n",
      "Validation score: 0.488050\n",
      "Iteration 1032, loss = 0.01021795\n",
      "Validation score: 0.488514\n",
      "Iteration 1033, loss = 0.01021093\n",
      "Validation score: 0.488977\n",
      "Iteration 1034, loss = 0.01020393\n",
      "Validation score: 0.489439\n",
      "Iteration 1035, loss = 0.01019695\n",
      "Validation score: 0.489901\n",
      "Iteration 1036, loss = 0.01018998\n",
      "Validation score: 0.490361\n",
      "Iteration 1037, loss = 0.01018302\n",
      "Validation score: 0.490821\n",
      "Iteration 1038, loss = 0.01017608\n",
      "Validation score: 0.491281\n",
      "Iteration 1039, loss = 0.01016916\n",
      "Validation score: 0.491740\n",
      "Iteration 1040, loss = 0.01016224\n",
      "Validation score: 0.492198\n",
      "Iteration 1041, loss = 0.01015535\n",
      "Validation score: 0.492656\n",
      "Iteration 1042, loss = 0.01014848\n",
      "Validation score: 0.493112\n",
      "Iteration 1043, loss = 0.01014159\n",
      "Validation score: 0.493569\n",
      "Iteration 1044, loss = 0.01013471\n",
      "Validation score: 0.494025\n",
      "Iteration 1045, loss = 0.01012784\n",
      "Validation score: 0.494480\n",
      "Iteration 1046, loss = 0.01012099\n",
      "Validation score: 0.494935\n",
      "Iteration 1047, loss = 0.01011415\n",
      "Validation score: 0.495388\n",
      "Iteration 1048, loss = 0.01010732\n",
      "Validation score: 0.495842\n",
      "Iteration 1049, loss = 0.01010051\n",
      "Validation score: 0.496295\n",
      "Iteration 1050, loss = 0.01009371\n",
      "Validation score: 0.496747\n",
      "Iteration 1051, loss = 0.01008693\n",
      "Validation score: 0.497198\n",
      "Iteration 1052, loss = 0.01008016\n",
      "Validation score: 0.497649\n",
      "Iteration 1053, loss = 0.01007340\n",
      "Validation score: 0.498099\n",
      "Iteration 1054, loss = 0.01006666\n",
      "Validation score: 0.498548\n",
      "Iteration 1055, loss = 0.01005993\n",
      "Validation score: 0.498997\n",
      "Iteration 1056, loss = 0.01005321\n",
      "Validation score: 0.499445\n",
      "Iteration 1057, loss = 0.01004651\n",
      "Validation score: 0.499893\n",
      "Iteration 1058, loss = 0.01003979\n",
      "Validation score: 0.500340\n",
      "Iteration 1059, loss = 0.01003306\n",
      "Validation score: 0.500786\n",
      "Iteration 1060, loss = 0.01002635\n",
      "Validation score: 0.501232\n",
      "Iteration 1061, loss = 0.01001964\n",
      "Validation score: 0.501677\n",
      "Iteration 1062, loss = 0.01001295\n",
      "Validation score: 0.502121\n",
      "Iteration 1063, loss = 0.01000627\n",
      "Validation score: 0.502565\n",
      "Iteration 1064, loss = 0.00999961\n",
      "Validation score: 0.503007\n",
      "Iteration 1065, loss = 0.00999295\n",
      "Validation score: 0.503450\n",
      "Iteration 1066, loss = 0.00998628\n",
      "Validation score: 0.503891\n",
      "Iteration 1067, loss = 0.00997962\n",
      "Validation score: 0.504333\n",
      "Iteration 1068, loss = 0.00997297\n",
      "Validation score: 0.504774\n",
      "Iteration 1069, loss = 0.00996634\n",
      "Validation score: 0.505214\n",
      "Iteration 1070, loss = 0.00995971\n",
      "Validation score: 0.505654\n",
      "Iteration 1071, loss = 0.00995310\n",
      "Validation score: 0.506110\n",
      "Iteration 1072, loss = 0.00994650\n",
      "Validation score: 0.506568\n",
      "Iteration 1073, loss = 0.00993991\n",
      "Validation score: 0.507025\n",
      "Iteration 1074, loss = 0.00993330\n",
      "Validation score: 0.507483\n",
      "Iteration 1075, loss = 0.00992670\n",
      "Validation score: 0.507940\n",
      "Iteration 1076, loss = 0.00992011\n",
      "Validation score: 0.508396\n",
      "Iteration 1077, loss = 0.00991353\n",
      "Validation score: 0.508852\n",
      "Iteration 1078, loss = 0.00990695\n",
      "Validation score: 0.509308\n",
      "Iteration 1079, loss = 0.00990039\n",
      "Validation score: 0.509767\n",
      "Iteration 1080, loss = 0.00989384\n",
      "Validation score: 0.510224\n",
      "Iteration 1081, loss = 0.00988729\n",
      "Validation score: 0.510681\n",
      "Iteration 1082, loss = 0.00988076\n",
      "Validation score: 0.511137\n",
      "Iteration 1083, loss = 0.00987424\n",
      "Validation score: 0.511593\n",
      "Iteration 1084, loss = 0.00986773\n",
      "Validation score: 0.512047\n",
      "Iteration 1085, loss = 0.00986124\n",
      "Validation score: 0.512501\n",
      "Iteration 1086, loss = 0.00985477\n",
      "Validation score: 0.512954\n",
      "Iteration 1087, loss = 0.00984831\n",
      "Validation score: 0.513406\n",
      "Iteration 1088, loss = 0.00984187\n",
      "Validation score: 0.513857\n",
      "Iteration 1089, loss = 0.00983543\n",
      "Validation score: 0.514308\n",
      "Iteration 1090, loss = 0.00982902\n",
      "Validation score: 0.514758\n",
      "Iteration 1091, loss = 0.00982261\n",
      "Validation score: 0.515207\n",
      "Iteration 1092, loss = 0.00981622\n",
      "Validation score: 0.515654\n",
      "Iteration 1093, loss = 0.00980984\n",
      "Validation score: 0.516101\n",
      "Iteration 1094, loss = 0.00980347\n",
      "Validation score: 0.516547\n",
      "Iteration 1095, loss = 0.00979712\n",
      "Validation score: 0.516992\n",
      "Iteration 1096, loss = 0.00979078\n",
      "Validation score: 0.517435\n",
      "Iteration 1097, loss = 0.00978445\n",
      "Validation score: 0.517879\n",
      "Iteration 1098, loss = 0.00977812\n",
      "Validation score: 0.518322\n",
      "Iteration 1099, loss = 0.00977179\n",
      "Validation score: 0.518764\n",
      "Iteration 1100, loss = 0.00976544\n",
      "Validation score: 0.519194\n",
      "Iteration 1101, loss = 0.00975910\n",
      "Validation score: 0.519624\n",
      "Iteration 1102, loss = 0.00975277\n",
      "Validation score: 0.520053\n",
      "Iteration 1103, loss = 0.00974644\n",
      "Validation score: 0.520481\n",
      "Iteration 1104, loss = 0.00974013\n",
      "Validation score: 0.520909\n",
      "Iteration 1105, loss = 0.00973382\n",
      "Validation score: 0.521337\n",
      "Iteration 1106, loss = 0.00972752\n",
      "Validation score: 0.521764\n",
      "Iteration 1107, loss = 0.00972122\n",
      "Validation score: 0.522190\n",
      "Iteration 1108, loss = 0.00971493\n",
      "Validation score: 0.522616\n",
      "Iteration 1109, loss = 0.00970866\n",
      "Validation score: 0.523041\n",
      "Iteration 1110, loss = 0.00970241\n",
      "Validation score: 0.523464\n",
      "Iteration 1111, loss = 0.00969616\n",
      "Validation score: 0.523887\n",
      "Iteration 1112, loss = 0.00968992\n",
      "Validation score: 0.524310\n",
      "Iteration 1113, loss = 0.00968369\n",
      "Validation score: 0.524731\n",
      "Iteration 1114, loss = 0.00967747\n",
      "Validation score: 0.525153\n",
      "Iteration 1115, loss = 0.00967126\n",
      "Validation score: 0.525574\n",
      "Iteration 1116, loss = 0.00966507\n",
      "Validation score: 0.525994\n",
      "Iteration 1117, loss = 0.00965888\n",
      "Validation score: 0.526413\n",
      "Iteration 1118, loss = 0.00965271\n",
      "Validation score: 0.526832\n",
      "Iteration 1119, loss = 0.00964655\n",
      "Validation score: 0.527249\n",
      "Iteration 1120, loss = 0.00964039\n",
      "Validation score: 0.527662\n",
      "Iteration 1121, loss = 0.00963425\n",
      "Validation score: 0.528073\n",
      "Iteration 1122, loss = 0.00962812\n",
      "Validation score: 0.528483\n",
      "Iteration 1123, loss = 0.00962200\n",
      "Validation score: 0.528892\n",
      "Iteration 1124, loss = 0.00961588\n",
      "Validation score: 0.529301\n",
      "Iteration 1125, loss = 0.00960977\n",
      "Validation score: 0.529709\n",
      "Iteration 1126, loss = 0.00960368\n",
      "Validation score: 0.530117\n",
      "Iteration 1127, loss = 0.00959759\n",
      "Validation score: 0.530524\n",
      "Iteration 1128, loss = 0.00959152\n",
      "Validation score: 0.530930\n",
      "Iteration 1129, loss = 0.00958547\n",
      "Validation score: 0.531336\n",
      "Iteration 1130, loss = 0.00957943\n",
      "Validation score: 0.531740\n",
      "Iteration 1131, loss = 0.00957340\n",
      "Validation score: 0.532144\n",
      "Iteration 1132, loss = 0.00956738\n",
      "Validation score: 0.532547\n",
      "Iteration 1133, loss = 0.00956138\n",
      "Validation score: 0.532948\n",
      "Iteration 1134, loss = 0.00955540\n",
      "Validation score: 0.533349\n",
      "Iteration 1135, loss = 0.00954942\n",
      "Validation score: 0.533749\n",
      "Iteration 1136, loss = 0.00954346\n",
      "Validation score: 0.534148\n",
      "Iteration 1137, loss = 0.00953751\n",
      "Validation score: 0.534546\n",
      "Iteration 1138, loss = 0.00953157\n",
      "Validation score: 0.534944\n",
      "Iteration 1139, loss = 0.00952564\n",
      "Validation score: 0.535341\n",
      "Iteration 1140, loss = 0.00951972\n",
      "Validation score: 0.535738\n",
      "Iteration 1141, loss = 0.00951382\n",
      "Validation score: 0.536134\n",
      "Iteration 1142, loss = 0.00950792\n",
      "Validation score: 0.536529\n",
      "Iteration 1143, loss = 0.00950203\n",
      "Validation score: 0.536924\n",
      "Iteration 1144, loss = 0.00949616\n",
      "Validation score: 0.537317\n",
      "Iteration 1145, loss = 0.00949030\n",
      "Validation score: 0.537710\n",
      "Iteration 1146, loss = 0.00948445\n",
      "Validation score: 0.538102\n",
      "Iteration 1147, loss = 0.00947861\n",
      "Validation score: 0.538494\n",
      "Iteration 1148, loss = 0.00947274\n",
      "Validation score: 0.538885\n",
      "Iteration 1149, loss = 0.00946686\n",
      "Validation score: 0.539275\n",
      "Iteration 1150, loss = 0.00946098\n",
      "Validation score: 0.539665\n",
      "Iteration 1151, loss = 0.00945511\n",
      "Validation score: 0.540055\n",
      "Iteration 1152, loss = 0.00944923\n",
      "Validation score: 0.540443\n",
      "Iteration 1153, loss = 0.00944337\n",
      "Validation score: 0.540831\n",
      "Iteration 1154, loss = 0.00943751\n",
      "Validation score: 0.541218\n",
      "Iteration 1155, loss = 0.00943165\n",
      "Validation score: 0.541605\n",
      "Iteration 1156, loss = 0.00942580\n",
      "Validation score: 0.541990\n",
      "Iteration 1157, loss = 0.00941997\n",
      "Validation score: 0.542375\n",
      "Iteration 1158, loss = 0.00941414\n",
      "Validation score: 0.542759\n",
      "Iteration 1159, loss = 0.00940833\n",
      "Validation score: 0.543142\n",
      "Iteration 1160, loss = 0.00940253\n",
      "Validation score: 0.543524\n",
      "Iteration 1161, loss = 0.00939673\n",
      "Validation score: 0.543906\n",
      "Iteration 1162, loss = 0.00939094\n",
      "Validation score: 0.544287\n",
      "Iteration 1163, loss = 0.00938517\n",
      "Validation score: 0.544667\n",
      "Iteration 1164, loss = 0.00937940\n",
      "Validation score: 0.545047\n",
      "Iteration 1165, loss = 0.00937366\n",
      "Validation score: 0.545425\n",
      "Iteration 1166, loss = 0.00936792\n",
      "Validation score: 0.545804\n",
      "Iteration 1167, loss = 0.00936219\n",
      "Validation score: 0.546182\n",
      "Iteration 1168, loss = 0.00935648\n",
      "Validation score: 0.546559\n",
      "Iteration 1169, loss = 0.00935079\n",
      "Validation score: 0.546935\n",
      "Iteration 1170, loss = 0.00934511\n",
      "Validation score: 0.547311\n",
      "Iteration 1171, loss = 0.00933944\n",
      "Validation score: 0.547686\n",
      "Iteration 1172, loss = 0.00933379\n",
      "Validation score: 0.548060\n",
      "Iteration 1173, loss = 0.00932814\n",
      "Validation score: 0.548432\n",
      "Iteration 1174, loss = 0.00932251\n",
      "Validation score: 0.548804\n",
      "Iteration 1175, loss = 0.00931689\n",
      "Validation score: 0.549175\n",
      "Iteration 1176, loss = 0.00931128\n",
      "Validation score: 0.549546\n",
      "Iteration 1177, loss = 0.00930569\n",
      "Validation score: 0.549915\n",
      "Iteration 1178, loss = 0.00930011\n",
      "Validation score: 0.550283\n",
      "Iteration 1179, loss = 0.00929455\n",
      "Validation score: 0.550650\n",
      "Iteration 1180, loss = 0.00928901\n",
      "Validation score: 0.551016\n",
      "Iteration 1181, loss = 0.00928348\n",
      "Validation score: 0.551381\n",
      "Iteration 1182, loss = 0.00927796\n",
      "Validation score: 0.551746\n",
      "Iteration 1183, loss = 0.00927245\n",
      "Validation score: 0.552110\n",
      "Iteration 1184, loss = 0.00926694\n",
      "Validation score: 0.552472\n",
      "Iteration 1185, loss = 0.00926145\n",
      "Validation score: 0.552834\n",
      "Iteration 1186, loss = 0.00925597\n",
      "Validation score: 0.553196\n",
      "Iteration 1187, loss = 0.00925050\n",
      "Validation score: 0.553557\n",
      "Iteration 1188, loss = 0.00924504\n",
      "Validation score: 0.553917\n",
      "Iteration 1189, loss = 0.00923959\n",
      "Validation score: 0.554277\n",
      "Iteration 1190, loss = 0.00923416\n",
      "Validation score: 0.554636\n",
      "Iteration 1191, loss = 0.00922873\n",
      "Validation score: 0.554994\n",
      "Iteration 1192, loss = 0.00922331\n",
      "Validation score: 0.555353\n",
      "Iteration 1193, loss = 0.00921791\n",
      "Validation score: 0.555711\n",
      "Iteration 1194, loss = 0.00921251\n",
      "Validation score: 0.556068\n",
      "Iteration 1195, loss = 0.00920712\n",
      "Validation score: 0.556424\n",
      "Iteration 1196, loss = 0.00920174\n",
      "Validation score: 0.556779\n",
      "Iteration 1197, loss = 0.00919636\n",
      "Validation score: 0.557134\n",
      "Iteration 1198, loss = 0.00919100\n",
      "Validation score: 0.557488\n",
      "Iteration 1199, loss = 0.00918565\n",
      "Validation score: 0.557840\n",
      "Iteration 1200, loss = 0.00918034\n",
      "Validation score: 0.558192\n",
      "Iteration 1201, loss = 0.00917503\n",
      "Validation score: 0.558544\n",
      "Iteration 1202, loss = 0.00916973\n",
      "Validation score: 0.558894\n",
      "Iteration 1203, loss = 0.00916444\n",
      "Validation score: 0.559244\n",
      "Iteration 1204, loss = 0.00915916\n",
      "Validation score: 0.559593\n",
      "Iteration 1205, loss = 0.00915389\n",
      "Validation score: 0.559942\n",
      "Iteration 1206, loss = 0.00914863\n",
      "Validation score: 0.560290\n",
      "Iteration 1207, loss = 0.00914338\n",
      "Validation score: 0.560638\n",
      "Iteration 1208, loss = 0.00913814\n",
      "Validation score: 0.560985\n",
      "Iteration 1209, loss = 0.00913291\n",
      "Validation score: 0.561332\n",
      "Iteration 1210, loss = 0.00912769\n",
      "Validation score: 0.561678\n",
      "Iteration 1211, loss = 0.00912247\n",
      "Validation score: 0.562024\n",
      "Iteration 1212, loss = 0.00911727\n",
      "Validation score: 0.562368\n",
      "Iteration 1213, loss = 0.00911208\n",
      "Validation score: 0.562713\n",
      "Iteration 1214, loss = 0.00910689\n",
      "Validation score: 0.563056\n",
      "Iteration 1215, loss = 0.00910172\n",
      "Validation score: 0.563398\n",
      "Iteration 1216, loss = 0.00909656\n",
      "Validation score: 0.563741\n",
      "Iteration 1217, loss = 0.00909142\n",
      "Validation score: 0.564082\n",
      "Iteration 1218, loss = 0.00908630\n",
      "Validation score: 0.564424\n",
      "Iteration 1219, loss = 0.00908118\n",
      "Validation score: 0.564764\n",
      "Iteration 1220, loss = 0.00907604\n",
      "Validation score: 0.565104\n",
      "Iteration 1221, loss = 0.00907091\n",
      "Validation score: 0.565442\n",
      "Iteration 1222, loss = 0.00906578\n",
      "Validation score: 0.565780\n",
      "Iteration 1223, loss = 0.00906065\n",
      "Validation score: 0.566117\n",
      "Iteration 1224, loss = 0.00905553\n",
      "Validation score: 0.566454\n",
      "Iteration 1225, loss = 0.00905041\n",
      "Validation score: 0.566790\n",
      "Iteration 1226, loss = 0.00904529\n",
      "Validation score: 0.567126\n",
      "Iteration 1227, loss = 0.00904017\n",
      "Validation score: 0.567462\n",
      "Iteration 1228, loss = 0.00903507\n",
      "Validation score: 0.567797\n",
      "Iteration 1229, loss = 0.00902996\n",
      "Validation score: 0.568131\n",
      "Iteration 1230, loss = 0.00902488\n",
      "Validation score: 0.568466\n",
      "Iteration 1231, loss = 0.00901980\n",
      "Validation score: 0.568801\n",
      "Iteration 1232, loss = 0.00901473\n",
      "Validation score: 0.569134\n",
      "Iteration 1233, loss = 0.00900966\n",
      "Validation score: 0.569468\n",
      "Iteration 1234, loss = 0.00900460\n",
      "Validation score: 0.569800\n",
      "Iteration 1235, loss = 0.00899954\n",
      "Validation score: 0.570133\n",
      "Iteration 1236, loss = 0.00899447\n",
      "Validation score: 0.570466\n",
      "Iteration 1237, loss = 0.00898940\n",
      "Validation score: 0.570798\n",
      "Iteration 1238, loss = 0.00898429\n",
      "Validation score: 0.571130\n",
      "Iteration 1239, loss = 0.00897917\n",
      "Validation score: 0.571462\n",
      "Iteration 1240, loss = 0.00897406\n",
      "Validation score: 0.571795\n",
      "Iteration 1241, loss = 0.00896895\n",
      "Validation score: 0.572127\n",
      "Iteration 1242, loss = 0.00896383\n",
      "Validation score: 0.572458\n",
      "Iteration 1243, loss = 0.00895872\n",
      "Validation score: 0.572787\n",
      "Iteration 1244, loss = 0.00895361\n",
      "Validation score: 0.573113\n",
      "Iteration 1245, loss = 0.00894850\n",
      "Validation score: 0.573440\n",
      "Iteration 1246, loss = 0.00894339\n",
      "Validation score: 0.573766\n",
      "Iteration 1247, loss = 0.00893828\n",
      "Validation score: 0.574092\n",
      "Iteration 1248, loss = 0.00893318\n",
      "Validation score: 0.574418\n",
      "Iteration 1249, loss = 0.00892808\n",
      "Validation score: 0.574744\n",
      "Iteration 1250, loss = 0.00892299\n",
      "Validation score: 0.575070\n",
      "Iteration 1251, loss = 0.00891789\n",
      "Validation score: 0.575396\n",
      "Iteration 1252, loss = 0.00891280\n",
      "Validation score: 0.575721\n",
      "Iteration 1253, loss = 0.00890772\n",
      "Validation score: 0.576045\n",
      "Iteration 1254, loss = 0.00890265\n",
      "Validation score: 0.576368\n",
      "Iteration 1255, loss = 0.00889760\n",
      "Validation score: 0.576691\n",
      "Iteration 1256, loss = 0.00889257\n",
      "Validation score: 0.577013\n",
      "Iteration 1257, loss = 0.00888754\n",
      "Validation score: 0.577335\n",
      "Iteration 1258, loss = 0.00888252\n",
      "Validation score: 0.577658\n",
      "Iteration 1259, loss = 0.00887750\n",
      "Validation score: 0.577981\n",
      "Iteration 1260, loss = 0.00887250\n",
      "Validation score: 0.578305\n",
      "Iteration 1261, loss = 0.00886751\n",
      "Validation score: 0.578627\n",
      "Iteration 1262, loss = 0.00886252\n",
      "Validation score: 0.578950\n",
      "Iteration 1263, loss = 0.00885754\n",
      "Validation score: 0.579271\n",
      "Iteration 1264, loss = 0.00885257\n",
      "Validation score: 0.579592\n",
      "Iteration 1265, loss = 0.00884760\n",
      "Validation score: 0.579912\n",
      "Iteration 1266, loss = 0.00884265\n",
      "Validation score: 0.580231\n",
      "Iteration 1267, loss = 0.00883769\n",
      "Validation score: 0.580549\n",
      "Iteration 1268, loss = 0.00883275\n",
      "Validation score: 0.580866\n",
      "Iteration 1269, loss = 0.00882785\n",
      "Validation score: 0.581184\n",
      "Iteration 1270, loss = 0.00882297\n",
      "Validation score: 0.581501\n",
      "Iteration 1271, loss = 0.00881809\n",
      "Validation score: 0.581818\n",
      "Iteration 1272, loss = 0.00881319\n",
      "Validation score: 0.582135\n",
      "Iteration 1273, loss = 0.00880829\n",
      "Validation score: 0.582452\n",
      "Iteration 1274, loss = 0.00880340\n",
      "Validation score: 0.582769\n",
      "Iteration 1275, loss = 0.00879851\n",
      "Validation score: 0.583086\n",
      "Iteration 1276, loss = 0.00879363\n",
      "Validation score: 0.583404\n",
      "Iteration 1277, loss = 0.00878872\n",
      "Validation score: 0.583721\n",
      "Iteration 1278, loss = 0.00878382\n",
      "Validation score: 0.584039\n",
      "Iteration 1279, loss = 0.00877892\n",
      "Validation score: 0.584357\n",
      "Iteration 1280, loss = 0.00877402\n",
      "Validation score: 0.584673\n",
      "Iteration 1281, loss = 0.00876911\n",
      "Validation score: 0.584994\n",
      "Iteration 1282, loss = 0.00876421\n",
      "Validation score: 0.585328\n",
      "Iteration 1283, loss = 0.00875931\n",
      "Validation score: 0.585670\n",
      "Iteration 1284, loss = 0.00875440\n",
      "Validation score: 0.586011\n",
      "Iteration 1285, loss = 0.00874948\n",
      "Validation score: 0.586353\n",
      "Iteration 1286, loss = 0.00874457\n",
      "Validation score: 0.586693\n",
      "Iteration 1287, loss = 0.00873965\n",
      "Validation score: 0.587033\n",
      "Iteration 1288, loss = 0.00873474\n",
      "Validation score: 0.587372\n",
      "Iteration 1289, loss = 0.00872983\n",
      "Validation score: 0.587712\n",
      "Iteration 1290, loss = 0.00872492\n",
      "Validation score: 0.588051\n",
      "Iteration 1291, loss = 0.00872001\n",
      "Validation score: 0.588390\n",
      "Iteration 1292, loss = 0.00871511\n",
      "Validation score: 0.588728\n",
      "Iteration 1293, loss = 0.00871021\n",
      "Validation score: 0.589066\n",
      "Iteration 1294, loss = 0.00870531\n",
      "Validation score: 0.589403\n",
      "Iteration 1295, loss = 0.00870042\n",
      "Validation score: 0.589740\n",
      "Iteration 1296, loss = 0.00869553\n",
      "Validation score: 0.590076\n",
      "Iteration 1297, loss = 0.00869064\n",
      "Validation score: 0.590410\n",
      "Iteration 1298, loss = 0.00868578\n",
      "Validation score: 0.590744\n",
      "Iteration 1299, loss = 0.00868091\n",
      "Validation score: 0.591078\n",
      "Iteration 1300, loss = 0.00867606\n",
      "Validation score: 0.591411\n",
      "Iteration 1301, loss = 0.00867121\n",
      "Validation score: 0.591744\n",
      "Iteration 1302, loss = 0.00866637\n",
      "Validation score: 0.592076\n",
      "Iteration 1303, loss = 0.00866153\n",
      "Validation score: 0.592407\n",
      "Iteration 1304, loss = 0.00865670\n",
      "Validation score: 0.592738\n",
      "Iteration 1305, loss = 0.00865188\n",
      "Validation score: 0.593069\n",
      "Iteration 1306, loss = 0.00864706\n",
      "Validation score: 0.593399\n",
      "Iteration 1307, loss = 0.00864225\n",
      "Validation score: 0.593728\n",
      "Iteration 1308, loss = 0.00863745\n",
      "Validation score: 0.594057\n",
      "Iteration 1309, loss = 0.00863265\n",
      "Validation score: 0.594385\n",
      "Iteration 1310, loss = 0.00862785\n",
      "Validation score: 0.594714\n",
      "Iteration 1311, loss = 0.00862306\n",
      "Validation score: 0.595041\n",
      "Iteration 1312, loss = 0.00861828\n",
      "Validation score: 0.595368\n",
      "Iteration 1313, loss = 0.00861351\n",
      "Validation score: 0.595694\n",
      "Iteration 1314, loss = 0.00860874\n",
      "Validation score: 0.596019\n",
      "Iteration 1315, loss = 0.00860398\n",
      "Validation score: 0.596344\n",
      "Iteration 1316, loss = 0.00859921\n",
      "Validation score: 0.596669\n",
      "Iteration 1317, loss = 0.00859444\n",
      "Validation score: 0.596993\n",
      "Iteration 1318, loss = 0.00858968\n",
      "Validation score: 0.597317\n",
      "Iteration 1319, loss = 0.00858492\n",
      "Validation score: 0.597640\n",
      "Iteration 1320, loss = 0.00858016\n",
      "Validation score: 0.597962\n",
      "Iteration 1321, loss = 0.00857542\n",
      "Validation score: 0.598279\n",
      "Iteration 1322, loss = 0.00857067\n",
      "Validation score: 0.598591\n",
      "Iteration 1323, loss = 0.00856593\n",
      "Validation score: 0.598903\n",
      "Iteration 1324, loss = 0.00856120\n",
      "Validation score: 0.599215\n",
      "Iteration 1325, loss = 0.00855647\n",
      "Validation score: 0.599525\n",
      "Iteration 1326, loss = 0.00855175\n",
      "Validation score: 0.599835\n",
      "Iteration 1327, loss = 0.00854704\n",
      "Validation score: 0.600142\n",
      "Iteration 1328, loss = 0.00854233\n",
      "Validation score: 0.600448\n",
      "Iteration 1329, loss = 0.00853763\n",
      "Validation score: 0.600751\n",
      "Iteration 1330, loss = 0.00853292\n",
      "Validation score: 0.601053\n",
      "Iteration 1331, loss = 0.00852822\n",
      "Validation score: 0.601355\n",
      "Iteration 1332, loss = 0.00852353\n",
      "Validation score: 0.601655\n",
      "Iteration 1333, loss = 0.00851884\n",
      "Validation score: 0.601955\n",
      "Iteration 1334, loss = 0.00851416\n",
      "Validation score: 0.602255\n",
      "Iteration 1335, loss = 0.00850948\n",
      "Validation score: 0.602554\n",
      "Iteration 1336, loss = 0.00850481\n",
      "Validation score: 0.602852\n",
      "Iteration 1337, loss = 0.00850016\n",
      "Validation score: 0.603150\n",
      "Iteration 1338, loss = 0.00849551\n",
      "Validation score: 0.603447\n",
      "Iteration 1339, loss = 0.00849087\n",
      "Validation score: 0.603743\n",
      "Iteration 1340, loss = 0.00848624\n",
      "Validation score: 0.604038\n",
      "Iteration 1341, loss = 0.00848161\n",
      "Validation score: 0.604332\n",
      "Iteration 1342, loss = 0.00847699\n",
      "Validation score: 0.604624\n",
      "Iteration 1343, loss = 0.00847238\n",
      "Validation score: 0.604916\n",
      "Iteration 1344, loss = 0.00846776\n",
      "Validation score: 0.605206\n",
      "Iteration 1345, loss = 0.00846314\n",
      "Validation score: 0.605496\n",
      "Iteration 1346, loss = 0.00845852\n",
      "Validation score: 0.605785\n",
      "Iteration 1347, loss = 0.00845390\n",
      "Validation score: 0.606074\n",
      "Iteration 1348, loss = 0.00844928\n",
      "Validation score: 0.606361\n",
      "Iteration 1349, loss = 0.00844467\n",
      "Validation score: 0.606647\n",
      "Iteration 1350, loss = 0.00844007\n",
      "Validation score: 0.606933\n",
      "Iteration 1351, loss = 0.00843546\n",
      "Validation score: 0.607217\n",
      "Iteration 1352, loss = 0.00843085\n",
      "Validation score: 0.607501\n",
      "Iteration 1353, loss = 0.00842625\n",
      "Validation score: 0.607787\n",
      "Iteration 1354, loss = 0.00842163\n",
      "Validation score: 0.608074\n",
      "Iteration 1355, loss = 0.00841702\n",
      "Validation score: 0.608361\n",
      "Iteration 1356, loss = 0.00841240\n",
      "Validation score: 0.608648\n",
      "Iteration 1357, loss = 0.00840779\n",
      "Validation score: 0.608935\n",
      "Iteration 1358, loss = 0.00840317\n",
      "Validation score: 0.609221\n",
      "Iteration 1359, loss = 0.00839856\n",
      "Validation score: 0.609508\n",
      "Iteration 1360, loss = 0.00839397\n",
      "Validation score: 0.609791\n",
      "Iteration 1361, loss = 0.00838937\n",
      "Validation score: 0.610073\n",
      "Iteration 1362, loss = 0.00838478\n",
      "Validation score: 0.610356\n",
      "Iteration 1363, loss = 0.00838019\n",
      "Validation score: 0.610638\n",
      "Iteration 1364, loss = 0.00837559\n",
      "Validation score: 0.610920\n",
      "Iteration 1365, loss = 0.00837100\n",
      "Validation score: 0.611201\n",
      "Iteration 1366, loss = 0.00836642\n",
      "Validation score: 0.611481\n",
      "Iteration 1367, loss = 0.00836185\n",
      "Validation score: 0.611761\n",
      "Iteration 1368, loss = 0.00835728\n",
      "Validation score: 0.612040\n",
      "Iteration 1369, loss = 0.00835273\n",
      "Validation score: 0.612319\n",
      "Iteration 1370, loss = 0.00834820\n",
      "Validation score: 0.612596\n",
      "Iteration 1371, loss = 0.00834367\n",
      "Validation score: 0.612873\n",
      "Iteration 1372, loss = 0.00833916\n",
      "Validation score: 0.613148\n",
      "Iteration 1373, loss = 0.00833466\n",
      "Validation score: 0.613422\n",
      "Iteration 1374, loss = 0.00833018\n",
      "Validation score: 0.613695\n",
      "Iteration 1375, loss = 0.00832571\n",
      "Validation score: 0.613966\n",
      "Iteration 1376, loss = 0.00832124\n",
      "Validation score: 0.614235\n",
      "Iteration 1377, loss = 0.00831677\n",
      "Validation score: 0.614503\n",
      "Iteration 1378, loss = 0.00831230\n",
      "Validation score: 0.614775\n",
      "Iteration 1379, loss = 0.00830784\n",
      "Validation score: 0.615051\n",
      "Iteration 1380, loss = 0.00830337\n",
      "Validation score: 0.615325\n",
      "Iteration 1381, loss = 0.00829891\n",
      "Validation score: 0.615598\n",
      "Iteration 1382, loss = 0.00829446\n",
      "Validation score: 0.615870\n",
      "Iteration 1383, loss = 0.00829001\n",
      "Validation score: 0.616140\n",
      "Iteration 1384, loss = 0.00828556\n",
      "Validation score: 0.616412\n",
      "Iteration 1385, loss = 0.00828112\n",
      "Validation score: 0.616684\n",
      "Iteration 1386, loss = 0.00827668\n",
      "Validation score: 0.616954\n",
      "Iteration 1387, loss = 0.00827224\n",
      "Validation score: 0.617223\n",
      "Iteration 1388, loss = 0.00826780\n",
      "Validation score: 0.617492\n",
      "Iteration 1389, loss = 0.00826338\n",
      "Validation score: 0.617759\n",
      "Iteration 1390, loss = 0.00825896\n",
      "Validation score: 0.618026\n",
      "Iteration 1391, loss = 0.00825454\n",
      "Validation score: 0.618292\n",
      "Iteration 1392, loss = 0.00825012\n",
      "Validation score: 0.618558\n",
      "Iteration 1393, loss = 0.00824571\n",
      "Validation score: 0.618823\n",
      "Iteration 1394, loss = 0.00824130\n",
      "Validation score: 0.619088\n",
      "Iteration 1395, loss = 0.00823690\n",
      "Validation score: 0.619352\n",
      "Iteration 1396, loss = 0.00823251\n",
      "Validation score: 0.619615\n",
      "Iteration 1397, loss = 0.00822811\n",
      "Validation score: 0.619877\n",
      "Iteration 1398, loss = 0.00822372\n",
      "Validation score: 0.620139\n",
      "Iteration 1399, loss = 0.00821934\n",
      "Validation score: 0.620399\n",
      "Iteration 1400, loss = 0.00821496\n",
      "Validation score: 0.620658\n",
      "Iteration 1401, loss = 0.00821058\n",
      "Validation score: 0.620916\n",
      "Iteration 1402, loss = 0.00820621\n",
      "Validation score: 0.621173\n",
      "Iteration 1403, loss = 0.00820185\n",
      "Validation score: 0.621430\n",
      "Iteration 1404, loss = 0.00819749\n",
      "Validation score: 0.621686\n",
      "Iteration 1405, loss = 0.00819314\n",
      "Validation score: 0.621942\n",
      "Iteration 1406, loss = 0.00818880\n",
      "Validation score: 0.622201\n",
      "Iteration 1407, loss = 0.00818446\n",
      "Validation score: 0.622460\n",
      "Iteration 1408, loss = 0.00818013\n",
      "Validation score: 0.622719\n",
      "Iteration 1409, loss = 0.00817580\n",
      "Validation score: 0.622978\n",
      "Iteration 1410, loss = 0.00817147\n",
      "Validation score: 0.623236\n",
      "Iteration 1411, loss = 0.00816713\n",
      "Validation score: 0.623494\n",
      "Iteration 1412, loss = 0.00816279\n",
      "Validation score: 0.623751\n",
      "Iteration 1413, loss = 0.00815846\n",
      "Validation score: 0.624008\n",
      "Iteration 1414, loss = 0.00815412\n",
      "Validation score: 0.624265\n",
      "Iteration 1415, loss = 0.00814978\n",
      "Validation score: 0.624521\n",
      "Iteration 1416, loss = 0.00814546\n",
      "Validation score: 0.624775\n",
      "Iteration 1417, loss = 0.00814114\n",
      "Validation score: 0.625028\n",
      "Iteration 1418, loss = 0.00813682\n",
      "Validation score: 0.625292\n",
      "Iteration 1419, loss = 0.00813251\n",
      "Validation score: 0.625554\n",
      "Iteration 1420, loss = 0.00812820\n",
      "Validation score: 0.625813\n",
      "Iteration 1421, loss = 0.00812390\n",
      "Validation score: 0.626070\n",
      "Iteration 1422, loss = 0.00811960\n",
      "Validation score: 0.626325\n",
      "Iteration 1423, loss = 0.00811529\n",
      "Validation score: 0.626580\n",
      "Iteration 1424, loss = 0.00811100\n",
      "Validation score: 0.626834\n",
      "Iteration 1425, loss = 0.00810671\n",
      "Validation score: 0.627088\n",
      "Iteration 1426, loss = 0.00810242\n",
      "Validation score: 0.627341\n",
      "Iteration 1427, loss = 0.00809813\n",
      "Validation score: 0.627593\n",
      "Iteration 1428, loss = 0.00809385\n",
      "Validation score: 0.627845\n",
      "Iteration 1429, loss = 0.00808958\n",
      "Validation score: 0.628095\n",
      "Iteration 1430, loss = 0.00808531\n",
      "Validation score: 0.628345\n",
      "Iteration 1431, loss = 0.00808104\n",
      "Validation score: 0.628596\n",
      "Iteration 1432, loss = 0.00807675\n",
      "Validation score: 0.628846\n",
      "Iteration 1433, loss = 0.00807248\n",
      "Validation score: 0.629096\n",
      "Iteration 1434, loss = 0.00806821\n",
      "Validation score: 0.629344\n",
      "Iteration 1435, loss = 0.00806395\n",
      "Validation score: 0.629592\n",
      "Iteration 1436, loss = 0.00805968\n",
      "Validation score: 0.629839\n",
      "Iteration 1437, loss = 0.00805541\n",
      "Validation score: 0.630085\n",
      "Iteration 1438, loss = 0.00805115\n",
      "Validation score: 0.630331\n",
      "Iteration 1439, loss = 0.00804688\n",
      "Validation score: 0.630575\n",
      "Iteration 1440, loss = 0.00804263\n",
      "Validation score: 0.630820\n",
      "Iteration 1441, loss = 0.00803838\n",
      "Validation score: 0.631064\n",
      "Iteration 1442, loss = 0.00803413\n",
      "Validation score: 0.631307\n",
      "Iteration 1443, loss = 0.00802988\n",
      "Validation score: 0.631550\n",
      "Iteration 1444, loss = 0.00802566\n",
      "Validation score: 0.631792\n",
      "Iteration 1445, loss = 0.00802144\n",
      "Validation score: 0.632033\n",
      "Iteration 1446, loss = 0.00801722\n",
      "Validation score: 0.632273\n",
      "Iteration 1447, loss = 0.00801301\n",
      "Validation score: 0.632514\n",
      "Iteration 1448, loss = 0.00800882\n",
      "Validation score: 0.632755\n",
      "Iteration 1449, loss = 0.00800465\n",
      "Validation score: 0.632995\n",
      "Iteration 1450, loss = 0.00800049\n",
      "Validation score: 0.633236\n",
      "Iteration 1451, loss = 0.00799634\n",
      "Validation score: 0.633476\n",
      "Iteration 1452, loss = 0.00799221\n",
      "Validation score: 0.633715\n",
      "Iteration 1453, loss = 0.00798807\n",
      "Validation score: 0.633954\n",
      "Iteration 1454, loss = 0.00798394\n",
      "Validation score: 0.634191\n",
      "Iteration 1455, loss = 0.00797982\n",
      "Validation score: 0.634429\n",
      "Iteration 1456, loss = 0.00797570\n",
      "Validation score: 0.634663\n",
      "Iteration 1457, loss = 0.00797157\n",
      "Validation score: 0.634898\n",
      "Iteration 1458, loss = 0.00796744\n",
      "Validation score: 0.635132\n",
      "Iteration 1459, loss = 0.00796330\n",
      "Validation score: 0.635365\n",
      "Iteration 1460, loss = 0.00795916\n",
      "Validation score: 0.635598\n",
      "Iteration 1461, loss = 0.00795499\n",
      "Validation score: 0.635831\n",
      "Iteration 1462, loss = 0.00795082\n",
      "Validation score: 0.636062\n",
      "Iteration 1463, loss = 0.00794665\n",
      "Validation score: 0.636293\n",
      "Iteration 1464, loss = 0.00794248\n",
      "Validation score: 0.636523\n",
      "Iteration 1465, loss = 0.00793831\n",
      "Validation score: 0.636752\n",
      "Iteration 1466, loss = 0.00793418\n",
      "Validation score: 0.636981\n",
      "Iteration 1467, loss = 0.00793009\n",
      "Validation score: 0.637210\n",
      "Iteration 1468, loss = 0.00792601\n",
      "Validation score: 0.637438\n",
      "Iteration 1469, loss = 0.00792193\n",
      "Validation score: 0.637666\n",
      "Iteration 1470, loss = 0.00791785\n",
      "Validation score: 0.637894\n",
      "Iteration 1471, loss = 0.00791376\n",
      "Validation score: 0.638123\n",
      "Iteration 1472, loss = 0.00790968\n",
      "Validation score: 0.638352\n",
      "Iteration 1473, loss = 0.00790560\n",
      "Validation score: 0.638580\n",
      "Iteration 1474, loss = 0.00790153\n",
      "Validation score: 0.638809\n",
      "Iteration 1475, loss = 0.00789745\n",
      "Validation score: 0.639037\n",
      "Iteration 1476, loss = 0.00789338\n",
      "Validation score: 0.639265\n",
      "Iteration 1477, loss = 0.00788932\n",
      "Validation score: 0.639493\n",
      "Iteration 1478, loss = 0.00788527\n",
      "Validation score: 0.639721\n",
      "Iteration 1479, loss = 0.00788121\n",
      "Validation score: 0.639949\n",
      "Iteration 1480, loss = 0.00787716\n",
      "Validation score: 0.640177\n",
      "Iteration 1481, loss = 0.00787312\n",
      "Validation score: 0.640405\n",
      "Iteration 1482, loss = 0.00786908\n",
      "Validation score: 0.640633\n",
      "Iteration 1483, loss = 0.00786505\n",
      "Validation score: 0.640862\n",
      "Iteration 1484, loss = 0.00786102\n",
      "Validation score: 0.641091\n",
      "Iteration 1485, loss = 0.00785699\n",
      "Validation score: 0.641319\n",
      "Iteration 1486, loss = 0.00785295\n",
      "Validation score: 0.641547\n",
      "Iteration 1487, loss = 0.00784892\n",
      "Validation score: 0.641773\n",
      "Iteration 1488, loss = 0.00784488\n",
      "Validation score: 0.641999\n",
      "Iteration 1489, loss = 0.00784085\n",
      "Validation score: 0.642224\n",
      "Iteration 1490, loss = 0.00783682\n",
      "Validation score: 0.642448\n",
      "Iteration 1491, loss = 0.00783280\n",
      "Validation score: 0.642671\n",
      "Iteration 1492, loss = 0.00782878\n",
      "Validation score: 0.642895\n",
      "Iteration 1493, loss = 0.00782476\n",
      "Validation score: 0.643117\n",
      "Iteration 1494, loss = 0.00782074\n",
      "Validation score: 0.643339\n",
      "Iteration 1495, loss = 0.00781673\n",
      "Validation score: 0.643561\n",
      "Iteration 1496, loss = 0.00781273\n",
      "Validation score: 0.643781\n",
      "Iteration 1497, loss = 0.00780873\n",
      "Validation score: 0.644001\n",
      "Iteration 1498, loss = 0.00780474\n",
      "Validation score: 0.644219\n",
      "Iteration 1499, loss = 0.00780075\n",
      "Validation score: 0.644436\n",
      "Iteration 1500, loss = 0.00779676\n",
      "Validation score: 0.644653\n",
      "Iteration 1501, loss = 0.00779278\n",
      "Validation score: 0.644868\n",
      "Iteration 1502, loss = 0.00778882\n",
      "Validation score: 0.645082\n",
      "Iteration 1503, loss = 0.00778486\n",
      "Validation score: 0.645296\n",
      "Iteration 1504, loss = 0.00778087\n",
      "Validation score: 0.645511\n",
      "Iteration 1505, loss = 0.00777689\n",
      "Validation score: 0.645726\n",
      "Iteration 1506, loss = 0.00777292\n",
      "Validation score: 0.645941\n",
      "Iteration 1507, loss = 0.00776894\n",
      "Validation score: 0.646156\n",
      "Iteration 1508, loss = 0.00776497\n",
      "Validation score: 0.646370\n",
      "Iteration 1509, loss = 0.00776099\n",
      "Validation score: 0.646583\n",
      "Iteration 1510, loss = 0.00775701\n",
      "Validation score: 0.646796\n",
      "Iteration 1511, loss = 0.00775305\n",
      "Validation score: 0.647009\n",
      "Iteration 1512, loss = 0.00774908\n",
      "Validation score: 0.647222\n",
      "Iteration 1513, loss = 0.00774512\n",
      "Validation score: 0.647435\n",
      "Iteration 1514, loss = 0.00774117\n",
      "Validation score: 0.647647\n",
      "Iteration 1515, loss = 0.00773721\n",
      "Validation score: 0.647858\n",
      "Iteration 1516, loss = 0.00773325\n",
      "Validation score: 0.648069\n",
      "Iteration 1517, loss = 0.00772930\n",
      "Validation score: 0.648280\n",
      "Iteration 1518, loss = 0.00772531\n",
      "Validation score: 0.648492\n",
      "Iteration 1519, loss = 0.00772131\n",
      "Validation score: 0.648705\n",
      "Iteration 1520, loss = 0.00771732\n",
      "Validation score: 0.648918\n",
      "Iteration 1521, loss = 0.00771333\n",
      "Validation score: 0.649132\n",
      "Iteration 1522, loss = 0.00770935\n",
      "Validation score: 0.649348\n",
      "Iteration 1523, loss = 0.00770537\n",
      "Validation score: 0.649566\n",
      "Iteration 1524, loss = 0.00770140\n",
      "Validation score: 0.649783\n",
      "Iteration 1525, loss = 0.00769744\n",
      "Validation score: 0.649999\n",
      "Iteration 1526, loss = 0.00769348\n",
      "Validation score: 0.650216\n",
      "Iteration 1527, loss = 0.00768954\n",
      "Validation score: 0.650432\n",
      "Iteration 1528, loss = 0.00768560\n",
      "Validation score: 0.650648\n",
      "Iteration 1529, loss = 0.00768166\n",
      "Validation score: 0.650863\n",
      "Iteration 1530, loss = 0.00767773\n",
      "Validation score: 0.651078\n",
      "Iteration 1531, loss = 0.00767380\n",
      "Validation score: 0.651292\n",
      "Iteration 1532, loss = 0.00766988\n",
      "Validation score: 0.651506\n",
      "Iteration 1533, loss = 0.00766596\n",
      "Validation score: 0.651721\n",
      "Iteration 1534, loss = 0.00766204\n",
      "Validation score: 0.651935\n",
      "Iteration 1535, loss = 0.00765815\n",
      "Validation score: 0.652149\n",
      "Iteration 1536, loss = 0.00765426\n",
      "Validation score: 0.652363\n",
      "Iteration 1537, loss = 0.00765037\n",
      "Validation score: 0.652578\n",
      "Iteration 1538, loss = 0.00764648\n",
      "Validation score: 0.652793\n",
      "Iteration 1539, loss = 0.00764259\n",
      "Validation score: 0.653007\n",
      "Iteration 1540, loss = 0.00763871\n",
      "Validation score: 0.653222\n",
      "Iteration 1541, loss = 0.00763482\n",
      "Validation score: 0.653436\n",
      "Iteration 1542, loss = 0.00763094\n",
      "Validation score: 0.653649\n",
      "Iteration 1543, loss = 0.00762707\n",
      "Validation score: 0.653862\n",
      "Iteration 1544, loss = 0.00762320\n",
      "Validation score: 0.654074\n",
      "Iteration 1545, loss = 0.00761933\n",
      "Validation score: 0.654285\n",
      "Iteration 1546, loss = 0.00761545\n",
      "Validation score: 0.654496\n",
      "Iteration 1547, loss = 0.00761156\n",
      "Validation score: 0.654706\n",
      "Iteration 1548, loss = 0.00760767\n",
      "Validation score: 0.654916\n",
      "Iteration 1549, loss = 0.00760378\n",
      "Validation score: 0.655126\n",
      "Iteration 1550, loss = 0.00759990\n",
      "Validation score: 0.655335\n",
      "Iteration 1551, loss = 0.00759600\n",
      "Validation score: 0.655544\n",
      "Iteration 1552, loss = 0.00759211\n",
      "Validation score: 0.655752\n",
      "Iteration 1553, loss = 0.00758823\n",
      "Validation score: 0.655959\n",
      "Iteration 1554, loss = 0.00758434\n",
      "Validation score: 0.656166\n",
      "Iteration 1555, loss = 0.00758046\n",
      "Validation score: 0.656374\n",
      "Iteration 1556, loss = 0.00757658\n",
      "Validation score: 0.656581\n",
      "Iteration 1557, loss = 0.00757270\n",
      "Validation score: 0.656787\n",
      "Iteration 1558, loss = 0.00756882\n",
      "Validation score: 0.656991\n",
      "Iteration 1559, loss = 0.00756493\n",
      "Validation score: 0.657194\n",
      "Iteration 1560, loss = 0.00756104\n",
      "Validation score: 0.657396\n",
      "Iteration 1561, loss = 0.00755715\n",
      "Validation score: 0.657599\n",
      "Iteration 1562, loss = 0.00755326\n",
      "Validation score: 0.657801\n",
      "Iteration 1563, loss = 0.00754938\n",
      "Validation score: 0.658003\n",
      "Iteration 1564, loss = 0.00754549\n",
      "Validation score: 0.658204\n",
      "Iteration 1565, loss = 0.00754161\n",
      "Validation score: 0.658404\n",
      "Iteration 1566, loss = 0.00753773\n",
      "Validation score: 0.658605\n",
      "Iteration 1567, loss = 0.00753386\n",
      "Validation score: 0.658805\n",
      "Iteration 1568, loss = 0.00753001\n",
      "Validation score: 0.659004\n",
      "Iteration 1569, loss = 0.00752618\n",
      "Validation score: 0.659203\n",
      "Iteration 1570, loss = 0.00752235\n",
      "Validation score: 0.659400\n",
      "Iteration 1571, loss = 0.00751853\n",
      "Validation score: 0.659596\n",
      "Iteration 1572, loss = 0.00751471\n",
      "Validation score: 0.659792\n",
      "Iteration 1573, loss = 0.00751090\n",
      "Validation score: 0.659988\n",
      "Iteration 1574, loss = 0.00750709\n",
      "Validation score: 0.660182\n",
      "Iteration 1575, loss = 0.00750328\n",
      "Validation score: 0.660376\n",
      "Iteration 1576, loss = 0.00749948\n",
      "Validation score: 0.660569\n",
      "Iteration 1577, loss = 0.00749568\n",
      "Validation score: 0.660761\n",
      "Iteration 1578, loss = 0.00749189\n",
      "Validation score: 0.660954\n",
      "Iteration 1579, loss = 0.00748810\n",
      "Validation score: 0.661145\n",
      "Iteration 1580, loss = 0.00748431\n",
      "Validation score: 0.661336\n",
      "Iteration 1581, loss = 0.00748053\n",
      "Validation score: 0.661527\n",
      "Iteration 1582, loss = 0.00747675\n",
      "Validation score: 0.661717\n",
      "Iteration 1583, loss = 0.00747299\n",
      "Validation score: 0.661907\n",
      "Iteration 1584, loss = 0.00746922\n",
      "Validation score: 0.662096\n",
      "Iteration 1585, loss = 0.00746547\n",
      "Validation score: 0.662285\n",
      "Iteration 1586, loss = 0.00746171\n",
      "Validation score: 0.662474\n",
      "Iteration 1587, loss = 0.00745797\n",
      "Validation score: 0.662662\n",
      "Iteration 1588, loss = 0.00745423\n",
      "Validation score: 0.662849\n",
      "Iteration 1589, loss = 0.00745050\n",
      "Validation score: 0.663036\n",
      "Iteration 1590, loss = 0.00744676\n",
      "Validation score: 0.663223\n",
      "Iteration 1591, loss = 0.00744304\n",
      "Validation score: 0.663409\n",
      "Iteration 1592, loss = 0.00743931\n",
      "Validation score: 0.663594\n",
      "Iteration 1593, loss = 0.00743558\n",
      "Validation score: 0.663779\n",
      "Iteration 1594, loss = 0.00743185\n",
      "Validation score: 0.663963\n",
      "Iteration 1595, loss = 0.00742812\n",
      "Validation score: 0.664146\n",
      "Iteration 1596, loss = 0.00742440\n",
      "Validation score: 0.664329\n",
      "Iteration 1597, loss = 0.00742070\n",
      "Validation score: 0.664511\n",
      "Iteration 1598, loss = 0.00741700\n",
      "Validation score: 0.664693\n",
      "Iteration 1599, loss = 0.00741330\n",
      "Validation score: 0.664875\n",
      "Iteration 1600, loss = 0.00740961\n",
      "Validation score: 0.665056\n",
      "Iteration 1601, loss = 0.00740593\n",
      "Validation score: 0.665237\n",
      "Iteration 1602, loss = 0.00740225\n",
      "Validation score: 0.665417\n",
      "Iteration 1603, loss = 0.00739857\n",
      "Validation score: 0.665597\n",
      "Iteration 1604, loss = 0.00739489\n",
      "Validation score: 0.665777\n",
      "Iteration 1605, loss = 0.00739121\n",
      "Validation score: 0.665956\n",
      "Iteration 1606, loss = 0.00738755\n",
      "Validation score: 0.666135\n",
      "Iteration 1607, loss = 0.00738388\n",
      "Validation score: 0.666314\n",
      "Iteration 1608, loss = 0.00738022\n",
      "Validation score: 0.666492\n",
      "Iteration 1609, loss = 0.00737657\n",
      "Validation score: 0.666670\n",
      "Iteration 1610, loss = 0.00737292\n",
      "Validation score: 0.666848\n",
      "Iteration 1611, loss = 0.00736927\n",
      "Validation score: 0.667026\n",
      "Iteration 1612, loss = 0.00736563\n",
      "Validation score: 0.667205\n",
      "Iteration 1613, loss = 0.00736199\n",
      "Validation score: 0.667383\n",
      "Iteration 1614, loss = 0.00735835\n",
      "Validation score: 0.667562\n",
      "Iteration 1615, loss = 0.00735471\n",
      "Validation score: 0.667738\n",
      "Iteration 1616, loss = 0.00735109\n",
      "Validation score: 0.667916\n",
      "Iteration 1617, loss = 0.00734747\n",
      "Validation score: 0.668093\n",
      "Iteration 1618, loss = 0.00734384\n",
      "Validation score: 0.668271\n",
      "Iteration 1619, loss = 0.00734023\n",
      "Validation score: 0.668450\n",
      "Iteration 1620, loss = 0.00733662\n",
      "Validation score: 0.668630\n",
      "Iteration 1621, loss = 0.00733301\n",
      "Validation score: 0.668811\n",
      "Iteration 1622, loss = 0.00732942\n",
      "Validation score: 0.668990\n",
      "Iteration 1623, loss = 0.00732583\n",
      "Validation score: 0.669169\n",
      "Iteration 1624, loss = 0.00732225\n",
      "Validation score: 0.669348\n",
      "Iteration 1625, loss = 0.00731866\n",
      "Validation score: 0.669529\n",
      "Iteration 1626, loss = 0.00731506\n",
      "Validation score: 0.669709\n",
      "Iteration 1627, loss = 0.00731146\n",
      "Validation score: 0.669888\n",
      "Iteration 1628, loss = 0.00730786\n",
      "Validation score: 0.670068\n",
      "Iteration 1629, loss = 0.00730425\n",
      "Validation score: 0.670247\n",
      "Iteration 1630, loss = 0.00730064\n",
      "Validation score: 0.670427\n",
      "Iteration 1631, loss = 0.00729705\n",
      "Validation score: 0.670606\n",
      "Iteration 1632, loss = 0.00729349\n",
      "Validation score: 0.670785\n",
      "Iteration 1633, loss = 0.00728994\n",
      "Validation score: 0.670964\n",
      "Iteration 1634, loss = 0.00728640\n",
      "Validation score: 0.671143\n",
      "Iteration 1635, loss = 0.00728286\n",
      "Validation score: 0.671323\n",
      "Iteration 1636, loss = 0.00727934\n",
      "Validation score: 0.671502\n",
      "Iteration 1637, loss = 0.00727581\n",
      "Validation score: 0.671681\n",
      "Iteration 1638, loss = 0.00727230\n",
      "Validation score: 0.671860\n",
      "Iteration 1639, loss = 0.00726879\n",
      "Validation score: 0.672040\n",
      "Iteration 1640, loss = 0.00726529\n",
      "Validation score: 0.672220\n",
      "Iteration 1641, loss = 0.00726179\n",
      "Validation score: 0.672400\n",
      "Iteration 1642, loss = 0.00725829\n",
      "Validation score: 0.672579\n",
      "Iteration 1643, loss = 0.00725481\n",
      "Validation score: 0.672756\n",
      "Iteration 1644, loss = 0.00725130\n",
      "Validation score: 0.672932\n",
      "Iteration 1645, loss = 0.00724776\n",
      "Validation score: 0.673109\n",
      "Iteration 1646, loss = 0.00724423\n",
      "Validation score: 0.673286\n",
      "Iteration 1647, loss = 0.00724069\n",
      "Validation score: 0.673462\n",
      "Iteration 1648, loss = 0.00723715\n",
      "Validation score: 0.673638\n",
      "Iteration 1649, loss = 0.00723361\n",
      "Validation score: 0.673814\n",
      "Iteration 1650, loss = 0.00723008\n",
      "Validation score: 0.673990\n",
      "Iteration 1651, loss = 0.00722655\n",
      "Validation score: 0.674166\n",
      "Iteration 1652, loss = 0.00722300\n",
      "Validation score: 0.674343\n",
      "Iteration 1653, loss = 0.00721945\n",
      "Validation score: 0.674520\n",
      "Iteration 1654, loss = 0.00721591\n",
      "Validation score: 0.674695\n",
      "Iteration 1655, loss = 0.00721236\n",
      "Validation score: 0.674868\n",
      "Iteration 1656, loss = 0.00720881\n",
      "Validation score: 0.675041\n",
      "Iteration 1657, loss = 0.00720527\n",
      "Validation score: 0.675212\n",
      "Iteration 1658, loss = 0.00720173\n",
      "Validation score: 0.675384\n",
      "Iteration 1659, loss = 0.00719819\n",
      "Validation score: 0.675555\n",
      "Iteration 1660, loss = 0.00719465\n",
      "Validation score: 0.675726\n",
      "Iteration 1661, loss = 0.00719111\n",
      "Validation score: 0.675897\n",
      "Iteration 1662, loss = 0.00718757\n",
      "Validation score: 0.676069\n",
      "Iteration 1663, loss = 0.00718405\n",
      "Validation score: 0.676241\n",
      "Iteration 1664, loss = 0.00718053\n",
      "Validation score: 0.676412\n",
      "Iteration 1665, loss = 0.00717701\n",
      "Validation score: 0.676584\n",
      "Iteration 1666, loss = 0.00717351\n",
      "Validation score: 0.676754\n",
      "Iteration 1667, loss = 0.00717001\n",
      "Validation score: 0.676925\n",
      "Iteration 1668, loss = 0.00716652\n",
      "Validation score: 0.677096\n",
      "Iteration 1669, loss = 0.00716304\n",
      "Validation score: 0.677266\n",
      "Iteration 1670, loss = 0.00715957\n",
      "Validation score: 0.677437\n",
      "Iteration 1671, loss = 0.00715611\n",
      "Validation score: 0.677608\n",
      "Iteration 1672, loss = 0.00715265\n",
      "Validation score: 0.677778\n",
      "Iteration 1673, loss = 0.00714919\n",
      "Validation score: 0.677948\n",
      "Iteration 1674, loss = 0.00714575\n",
      "Validation score: 0.678116\n",
      "Iteration 1675, loss = 0.00714231\n",
      "Validation score: 0.678284\n",
      "Iteration 1676, loss = 0.00713887\n",
      "Validation score: 0.678451\n",
      "Iteration 1677, loss = 0.00713544\n",
      "Validation score: 0.678616\n",
      "Iteration 1678, loss = 0.00713201\n",
      "Validation score: 0.678778\n",
      "Iteration 1679, loss = 0.00712858\n",
      "Validation score: 0.678940\n",
      "Iteration 1680, loss = 0.00712516\n",
      "Validation score: 0.679102\n",
      "Iteration 1681, loss = 0.00712175\n",
      "Validation score: 0.679264\n",
      "Iteration 1682, loss = 0.00711835\n",
      "Validation score: 0.679426\n",
      "Iteration 1683, loss = 0.00711496\n",
      "Validation score: 0.679588\n",
      "Iteration 1684, loss = 0.00711158\n",
      "Validation score: 0.679750\n",
      "Iteration 1685, loss = 0.00710820\n",
      "Validation score: 0.679912\n",
      "Iteration 1686, loss = 0.00710481\n",
      "Validation score: 0.680075\n",
      "Iteration 1687, loss = 0.00710140\n",
      "Validation score: 0.680238\n",
      "Iteration 1688, loss = 0.00709798\n",
      "Validation score: 0.680400\n",
      "Iteration 1689, loss = 0.00709457\n",
      "Validation score: 0.680563\n",
      "Iteration 1690, loss = 0.00709118\n",
      "Validation score: 0.680727\n",
      "Iteration 1691, loss = 0.00708779\n",
      "Validation score: 0.680890\n",
      "Iteration 1692, loss = 0.00708439\n",
      "Validation score: 0.681053\n",
      "Iteration 1693, loss = 0.00708100\n",
      "Validation score: 0.681216\n",
      "Iteration 1694, loss = 0.00707761\n",
      "Validation score: 0.681379\n",
      "Iteration 1695, loss = 0.00707423\n",
      "Validation score: 0.681541\n",
      "Iteration 1696, loss = 0.00707084\n",
      "Validation score: 0.681705\n",
      "Iteration 1697, loss = 0.00706746\n",
      "Validation score: 0.681870\n",
      "Iteration 1698, loss = 0.00706407\n",
      "Validation score: 0.682034\n",
      "Iteration 1699, loss = 0.00706069\n",
      "Validation score: 0.682198\n",
      "Iteration 1700, loss = 0.00705732\n",
      "Validation score: 0.682361\n",
      "Iteration 1701, loss = 0.00705396\n",
      "Validation score: 0.682525\n",
      "Iteration 1702, loss = 0.00705060\n",
      "Validation score: 0.682689\n",
      "Iteration 1703, loss = 0.00704725\n",
      "Validation score: 0.682853\n",
      "Iteration 1704, loss = 0.00704389\n",
      "Validation score: 0.683016\n",
      "Iteration 1705, loss = 0.00704054\n",
      "Validation score: 0.683179\n",
      "Iteration 1706, loss = 0.00703719\n",
      "Validation score: 0.683342\n",
      "Iteration 1707, loss = 0.00703384\n",
      "Validation score: 0.683505\n",
      "Iteration 1708, loss = 0.00703048\n",
      "Validation score: 0.683668\n",
      "Iteration 1709, loss = 0.00702712\n",
      "Validation score: 0.683829\n",
      "Iteration 1710, loss = 0.00702377\n",
      "Validation score: 0.683988\n",
      "Iteration 1711, loss = 0.00702042\n",
      "Validation score: 0.684147\n",
      "Iteration 1712, loss = 0.00701708\n",
      "Validation score: 0.684306\n",
      "Iteration 1713, loss = 0.00701374\n",
      "Validation score: 0.684464\n",
      "Iteration 1714, loss = 0.00701040\n",
      "Validation score: 0.684622\n",
      "Iteration 1715, loss = 0.00700706\n",
      "Validation score: 0.684780\n",
      "Iteration 1716, loss = 0.00700374\n",
      "Validation score: 0.684938\n",
      "Iteration 1717, loss = 0.00700043\n",
      "Validation score: 0.685096\n",
      "Iteration 1718, loss = 0.00699713\n",
      "Validation score: 0.685254\n",
      "Iteration 1719, loss = 0.00699384\n",
      "Validation score: 0.685411\n",
      "Iteration 1720, loss = 0.00699057\n",
      "Validation score: 0.685568\n",
      "Iteration 1721, loss = 0.00698731\n",
      "Validation score: 0.685725\n",
      "Iteration 1722, loss = 0.00698405\n",
      "Validation score: 0.685881\n",
      "Iteration 1723, loss = 0.00698081\n",
      "Validation score: 0.686038\n",
      "Iteration 1724, loss = 0.00697758\n",
      "Validation score: 0.686194\n",
      "Iteration 1725, loss = 0.00697437\n",
      "Validation score: 0.686349\n",
      "Iteration 1726, loss = 0.00697117\n",
      "Validation score: 0.686503\n",
      "Iteration 1727, loss = 0.00696799\n",
      "Validation score: 0.686655\n",
      "Iteration 1728, loss = 0.00696484\n",
      "Validation score: 0.686807\n",
      "Iteration 1729, loss = 0.00696171\n",
      "Validation score: 0.686959\n",
      "Iteration 1730, loss = 0.00695857\n",
      "Validation score: 0.687109\n",
      "Iteration 1731, loss = 0.00695545\n",
      "Validation score: 0.687259\n",
      "Iteration 1732, loss = 0.00695233\n",
      "Validation score: 0.687409\n",
      "Iteration 1733, loss = 0.00694921\n",
      "Validation score: 0.687557\n",
      "Iteration 1734, loss = 0.00694611\n",
      "Validation score: 0.687705\n",
      "Iteration 1735, loss = 0.00694300\n",
      "Validation score: 0.687853\n",
      "Iteration 1736, loss = 0.00693990\n",
      "Validation score: 0.688002\n",
      "Iteration 1737, loss = 0.00693680\n",
      "Validation score: 0.688150\n",
      "Iteration 1738, loss = 0.00693371\n",
      "Validation score: 0.688297\n",
      "Iteration 1739, loss = 0.00693062\n",
      "Validation score: 0.688444\n",
      "Iteration 1740, loss = 0.00692753\n",
      "Validation score: 0.688590\n",
      "Iteration 1741, loss = 0.00692443\n",
      "Validation score: 0.688735\n",
      "Iteration 1742, loss = 0.00692134\n",
      "Validation score: 0.688880\n",
      "Iteration 1743, loss = 0.00691825\n",
      "Validation score: 0.689024\n",
      "Iteration 1744, loss = 0.00691516\n",
      "Validation score: 0.689168\n",
      "Iteration 1745, loss = 0.00691208\n",
      "Validation score: 0.689312\n",
      "Iteration 1746, loss = 0.00690900\n",
      "Validation score: 0.689455\n",
      "Iteration 1747, loss = 0.00690593\n",
      "Validation score: 0.689599\n",
      "Iteration 1748, loss = 0.00690288\n",
      "Validation score: 0.689742\n",
      "Iteration 1749, loss = 0.00689984\n",
      "Validation score: 0.689885\n",
      "Iteration 1750, loss = 0.00689680\n",
      "Validation score: 0.690029\n",
      "Iteration 1751, loss = 0.00689376\n",
      "Validation score: 0.690172\n",
      "Iteration 1752, loss = 0.00689072\n",
      "Validation score: 0.690315\n",
      "Iteration 1753, loss = 0.00688769\n",
      "Validation score: 0.690457\n",
      "Iteration 1754, loss = 0.00688466\n",
      "Validation score: 0.690598\n",
      "Iteration 1755, loss = 0.00688164\n",
      "Validation score: 0.690739\n",
      "Iteration 1756, loss = 0.00687862\n",
      "Validation score: 0.690881\n",
      "Iteration 1757, loss = 0.00687562\n",
      "Validation score: 0.691023\n",
      "Iteration 1758, loss = 0.00687262\n",
      "Validation score: 0.691164\n",
      "Iteration 1759, loss = 0.00686962\n",
      "Validation score: 0.691304\n",
      "Iteration 1760, loss = 0.00686663\n",
      "Validation score: 0.691444\n",
      "Iteration 1761, loss = 0.00686365\n",
      "Validation score: 0.691582\n",
      "Iteration 1762, loss = 0.00686067\n",
      "Validation score: 0.691720\n",
      "Iteration 1763, loss = 0.00685770\n",
      "Validation score: 0.691858\n",
      "Iteration 1764, loss = 0.00685473\n",
      "Validation score: 0.691997\n",
      "Iteration 1765, loss = 0.00685176\n",
      "Validation score: 0.692136\n",
      "Iteration 1766, loss = 0.00684879\n",
      "Validation score: 0.692274\n",
      "Iteration 1767, loss = 0.00684582\n",
      "Validation score: 0.692412\n",
      "Iteration 1768, loss = 0.00684285\n",
      "Validation score: 0.692550\n",
      "Iteration 1769, loss = 0.00683989\n",
      "Validation score: 0.692687\n",
      "Iteration 1770, loss = 0.00683692\n",
      "Validation score: 0.692823\n",
      "Iteration 1771, loss = 0.00683395\n",
      "Validation score: 0.692958\n",
      "Iteration 1772, loss = 0.00683098\n",
      "Validation score: 0.693094\n",
      "Iteration 1773, loss = 0.00682801\n",
      "Validation score: 0.693229\n",
      "Iteration 1774, loss = 0.00682504\n",
      "Validation score: 0.693363\n",
      "Iteration 1775, loss = 0.00682207\n",
      "Validation score: 0.693498\n",
      "Iteration 1776, loss = 0.00681911\n",
      "Validation score: 0.693631\n",
      "Iteration 1777, loss = 0.00681615\n",
      "Validation score: 0.693765\n",
      "Iteration 1778, loss = 0.00681319\n",
      "Validation score: 0.693899\n",
      "Iteration 1779, loss = 0.00681024\n",
      "Validation score: 0.694032\n",
      "Iteration 1780, loss = 0.00680728\n",
      "Validation score: 0.694165\n",
      "Iteration 1781, loss = 0.00680432\n",
      "Validation score: 0.694298\n",
      "Iteration 1782, loss = 0.00680137\n",
      "Validation score: 0.694430\n",
      "Iteration 1783, loss = 0.00679844\n",
      "Validation score: 0.694563\n",
      "Iteration 1784, loss = 0.00679551\n",
      "Validation score: 0.694697\n",
      "Iteration 1785, loss = 0.00679259\n",
      "Validation score: 0.694832\n",
      "Iteration 1786, loss = 0.00678967\n",
      "Validation score: 0.694966\n",
      "Iteration 1787, loss = 0.00678675\n",
      "Validation score: 0.695100\n",
      "Iteration 1788, loss = 0.00678383\n",
      "Validation score: 0.695235\n",
      "Iteration 1789, loss = 0.00678092\n",
      "Validation score: 0.695370\n",
      "Iteration 1790, loss = 0.00677801\n",
      "Validation score: 0.695507\n",
      "Iteration 1791, loss = 0.00677510\n",
      "Validation score: 0.695645\n",
      "Iteration 1792, loss = 0.00677219\n",
      "Validation score: 0.695782\n",
      "Iteration 1793, loss = 0.00676928\n",
      "Validation score: 0.695919\n",
      "Iteration 1794, loss = 0.00676636\n",
      "Validation score: 0.696056\n",
      "Iteration 1795, loss = 0.00676344\n",
      "Validation score: 0.696193\n",
      "Iteration 1796, loss = 0.00676052\n",
      "Validation score: 0.696328\n",
      "Iteration 1797, loss = 0.00675760\n",
      "Validation score: 0.696464\n",
      "Iteration 1798, loss = 0.00675467\n",
      "Validation score: 0.696599\n",
      "Iteration 1799, loss = 0.00675173\n",
      "Validation score: 0.696735\n",
      "Iteration 1800, loss = 0.00674879\n",
      "Validation score: 0.696872\n",
      "Iteration 1801, loss = 0.00674585\n",
      "Validation score: 0.697008\n",
      "Iteration 1802, loss = 0.00674292\n",
      "Validation score: 0.697143\n",
      "Iteration 1803, loss = 0.00673999\n",
      "Validation score: 0.697277\n",
      "Iteration 1804, loss = 0.00673706\n",
      "Validation score: 0.697410\n",
      "Iteration 1805, loss = 0.00673413\n",
      "Validation score: 0.697542\n",
      "Iteration 1806, loss = 0.00673121\n",
      "Validation score: 0.697675\n",
      "Iteration 1807, loss = 0.00672828\n",
      "Validation score: 0.697807\n",
      "Iteration 1808, loss = 0.00672536\n",
      "Validation score: 0.697939\n",
      "Iteration 1809, loss = 0.00672244\n",
      "Validation score: 0.698070\n",
      "Iteration 1810, loss = 0.00671952\n",
      "Validation score: 0.698206\n",
      "Iteration 1811, loss = 0.00671661\n",
      "Validation score: 0.698347\n",
      "Iteration 1812, loss = 0.00671370\n",
      "Validation score: 0.698487\n",
      "Iteration 1813, loss = 0.00671079\n",
      "Validation score: 0.698628\n",
      "Iteration 1814, loss = 0.00670788\n",
      "Validation score: 0.698770\n",
      "Iteration 1815, loss = 0.00670495\n",
      "Validation score: 0.698913\n",
      "Iteration 1816, loss = 0.00670203\n",
      "Validation score: 0.699055\n",
      "Iteration 1817, loss = 0.00669910\n",
      "Validation score: 0.699196\n",
      "Iteration 1818, loss = 0.00669618\n",
      "Validation score: 0.699337\n",
      "Iteration 1819, loss = 0.00669327\n",
      "Validation score: 0.699477\n",
      "Iteration 1820, loss = 0.00669037\n",
      "Validation score: 0.699616\n",
      "Iteration 1821, loss = 0.00668748\n",
      "Validation score: 0.699755\n",
      "Iteration 1822, loss = 0.00668460\n",
      "Validation score: 0.699893\n",
      "Iteration 1823, loss = 0.00668172\n",
      "Validation score: 0.700031\n",
      "Iteration 1824, loss = 0.00667883\n",
      "Validation score: 0.700170\n",
      "Iteration 1825, loss = 0.00667591\n",
      "Validation score: 0.700310\n",
      "Iteration 1826, loss = 0.00667298\n",
      "Validation score: 0.700449\n",
      "Iteration 1827, loss = 0.00667006\n",
      "Validation score: 0.700589\n",
      "Iteration 1828, loss = 0.00666714\n",
      "Validation score: 0.700728\n",
      "Iteration 1829, loss = 0.00666422\n",
      "Validation score: 0.700867\n",
      "Iteration 1830, loss = 0.00666131\n",
      "Validation score: 0.701006\n",
      "Iteration 1831, loss = 0.00665839\n",
      "Validation score: 0.701145\n",
      "Iteration 1832, loss = 0.00665549\n",
      "Validation score: 0.701284\n",
      "Iteration 1833, loss = 0.00665257\n",
      "Validation score: 0.701422\n",
      "Iteration 1834, loss = 0.00664966\n",
      "Validation score: 0.701560\n",
      "Iteration 1835, loss = 0.00664674\n",
      "Validation score: 0.701697\n",
      "Iteration 1836, loss = 0.00664383\n",
      "Validation score: 0.701835\n",
      "Iteration 1837, loss = 0.00664092\n",
      "Validation score: 0.701973\n",
      "Iteration 1838, loss = 0.00663800\n",
      "Validation score: 0.702111\n",
      "Iteration 1839, loss = 0.00663508\n",
      "Validation score: 0.702248\n",
      "Iteration 1840, loss = 0.00663217\n",
      "Validation score: 0.702386\n",
      "Iteration 1841, loss = 0.00662928\n",
      "Validation score: 0.702523\n",
      "Iteration 1842, loss = 0.00662639\n",
      "Validation score: 0.702659\n",
      "Iteration 1843, loss = 0.00662350\n",
      "Validation score: 0.702794\n",
      "Iteration 1844, loss = 0.00662061\n",
      "Validation score: 0.702929\n",
      "Iteration 1845, loss = 0.00661772\n",
      "Validation score: 0.703064\n",
      "Iteration 1846, loss = 0.00661484\n",
      "Validation score: 0.703199\n",
      "Iteration 1847, loss = 0.00661196\n",
      "Validation score: 0.703334\n",
      "Iteration 1848, loss = 0.00660908\n",
      "Validation score: 0.703467\n",
      "Iteration 1849, loss = 0.00660619\n",
      "Validation score: 0.703599\n",
      "Iteration 1850, loss = 0.00660331\n",
      "Validation score: 0.703730\n",
      "Iteration 1851, loss = 0.00660043\n",
      "Validation score: 0.703860\n",
      "Iteration 1852, loss = 0.00659755\n",
      "Validation score: 0.703989\n",
      "Iteration 1853, loss = 0.00659466\n",
      "Validation score: 0.704118\n",
      "Iteration 1854, loss = 0.00659176\n",
      "Validation score: 0.704247\n",
      "Iteration 1855, loss = 0.00658885\n",
      "Validation score: 0.704375\n",
      "Iteration 1856, loss = 0.00658594\n",
      "Validation score: 0.704503\n",
      "Iteration 1857, loss = 0.00658302\n",
      "Validation score: 0.704630\n",
      "Iteration 1858, loss = 0.00658010\n",
      "Validation score: 0.704757\n",
      "Iteration 1859, loss = 0.00657718\n",
      "Validation score: 0.704883\n",
      "Iteration 1860, loss = 0.00657426\n",
      "Validation score: 0.705009\n",
      "Iteration 1861, loss = 0.00657133\n",
      "Validation score: 0.705133\n",
      "Iteration 1862, loss = 0.00656841\n",
      "Validation score: 0.705258\n",
      "Iteration 1863, loss = 0.00656549\n",
      "Validation score: 0.705382\n",
      "Iteration 1864, loss = 0.00656257\n",
      "Validation score: 0.705507\n",
      "Iteration 1865, loss = 0.00655965\n",
      "Validation score: 0.705632\n",
      "Iteration 1866, loss = 0.00655674\n",
      "Validation score: 0.705755\n",
      "Iteration 1867, loss = 0.00655382\n",
      "Validation score: 0.705877\n",
      "Iteration 1868, loss = 0.00655090\n",
      "Validation score: 0.705999\n",
      "Iteration 1869, loss = 0.00654799\n",
      "Validation score: 0.706121\n",
      "Iteration 1870, loss = 0.00654511\n",
      "Validation score: 0.706242\n",
      "Iteration 1871, loss = 0.00654223\n",
      "Validation score: 0.706363\n",
      "Iteration 1872, loss = 0.00653937\n",
      "Validation score: 0.706483\n",
      "Iteration 1873, loss = 0.00653653\n",
      "Validation score: 0.706604\n",
      "Iteration 1874, loss = 0.00653370\n",
      "Validation score: 0.706724\n",
      "Iteration 1875, loss = 0.00653086\n",
      "Validation score: 0.706844\n",
      "Iteration 1876, loss = 0.00652803\n",
      "Validation score: 0.706962\n",
      "Iteration 1877, loss = 0.00652519\n",
      "Validation score: 0.707080\n",
      "Iteration 1878, loss = 0.00652231\n",
      "Validation score: 0.707196\n",
      "Iteration 1879, loss = 0.00651943\n",
      "Validation score: 0.707312\n",
      "Iteration 1880, loss = 0.00651654\n",
      "Validation score: 0.707428\n",
      "Iteration 1881, loss = 0.00651365\n",
      "Validation score: 0.707542\n",
      "Iteration 1882, loss = 0.00651077\n",
      "Validation score: 0.707656\n",
      "Iteration 1883, loss = 0.00650789\n",
      "Validation score: 0.707770\n",
      "Iteration 1884, loss = 0.00650500\n",
      "Validation score: 0.707883\n",
      "Iteration 1885, loss = 0.00650210\n",
      "Validation score: 0.707997\n",
      "Iteration 1886, loss = 0.00649920\n",
      "Validation score: 0.708110\n",
      "Iteration 1887, loss = 0.00649630\n",
      "Validation score: 0.708223\n",
      "Iteration 1888, loss = 0.00649340\n",
      "Validation score: 0.708336\n",
      "Iteration 1889, loss = 0.00649051\n",
      "Validation score: 0.708447\n",
      "Iteration 1890, loss = 0.00648762\n",
      "Validation score: 0.708559\n",
      "Iteration 1891, loss = 0.00648474\n",
      "Validation score: 0.708670\n",
      "Iteration 1892, loss = 0.00648187\n",
      "Validation score: 0.708780\n",
      "Iteration 1893, loss = 0.00647902\n",
      "Validation score: 0.708891\n",
      "Iteration 1894, loss = 0.00647617\n",
      "Validation score: 0.709002\n",
      "Iteration 1895, loss = 0.00647332\n",
      "Validation score: 0.709114\n",
      "Iteration 1896, loss = 0.00647047\n",
      "Validation score: 0.709226\n",
      "Iteration 1897, loss = 0.00646763\n",
      "Validation score: 0.709338\n",
      "Iteration 1898, loss = 0.00646479\n",
      "Validation score: 0.709449\n",
      "Iteration 1899, loss = 0.00646197\n",
      "Validation score: 0.709561\n",
      "Iteration 1900, loss = 0.00645915\n",
      "Validation score: 0.709674\n",
      "Iteration 1901, loss = 0.00645634\n",
      "Validation score: 0.709787\n",
      "Iteration 1902, loss = 0.00645353\n",
      "Validation score: 0.709900\n",
      "Iteration 1903, loss = 0.00645072\n",
      "Validation score: 0.710014\n",
      "Iteration 1904, loss = 0.00644792\n",
      "Validation score: 0.710128\n",
      "Iteration 1905, loss = 0.00644511\n",
      "Validation score: 0.710243\n",
      "Iteration 1906, loss = 0.00644235\n",
      "Validation score: 0.710358\n",
      "Iteration 1907, loss = 0.00643961\n",
      "Validation score: 0.710475\n",
      "Iteration 1908, loss = 0.00643688\n",
      "Validation score: 0.710595\n",
      "Iteration 1909, loss = 0.00643416\n",
      "Validation score: 0.710715\n",
      "Iteration 1910, loss = 0.00643144\n",
      "Validation score: 0.710834\n",
      "Iteration 1911, loss = 0.00642873\n",
      "Validation score: 0.710955\n",
      "Iteration 1912, loss = 0.00642603\n",
      "Validation score: 0.711075\n",
      "Iteration 1913, loss = 0.00642333\n",
      "Validation score: 0.711195\n",
      "Iteration 1914, loss = 0.00642064\n",
      "Validation score: 0.711315\n",
      "Iteration 1915, loss = 0.00641796\n",
      "Validation score: 0.711435\n",
      "Iteration 1916, loss = 0.00641528\n",
      "Validation score: 0.711555\n",
      "Iteration 1917, loss = 0.00641262\n",
      "Validation score: 0.711675\n",
      "Iteration 1918, loss = 0.00640995\n",
      "Validation score: 0.711796\n",
      "Iteration 1919, loss = 0.00640729\n",
      "Validation score: 0.711917\n",
      "Iteration 1920, loss = 0.00640463\n",
      "Validation score: 0.712038\n",
      "Iteration 1921, loss = 0.00640199\n",
      "Validation score: 0.712158\n",
      "Iteration 1922, loss = 0.00639935\n",
      "Validation score: 0.712277\n",
      "Iteration 1923, loss = 0.00639672\n",
      "Validation score: 0.712396\n",
      "Iteration 1924, loss = 0.00639409\n",
      "Validation score: 0.712514\n",
      "Iteration 1925, loss = 0.00639147\n",
      "Validation score: 0.712632\n",
      "Iteration 1926, loss = 0.00638884\n",
      "Validation score: 0.712749\n",
      "Iteration 1927, loss = 0.00638620\n",
      "Validation score: 0.712867\n",
      "Iteration 1928, loss = 0.00638356\n",
      "Validation score: 0.712985\n",
      "Iteration 1929, loss = 0.00638093\n",
      "Validation score: 0.713102\n",
      "Iteration 1930, loss = 0.00637830\n",
      "Validation score: 0.713219\n",
      "Iteration 1931, loss = 0.00637567\n",
      "Validation score: 0.713337\n",
      "Iteration 1932, loss = 0.00637303\n",
      "Validation score: 0.713454\n",
      "Iteration 1933, loss = 0.00637038\n",
      "Validation score: 0.713570\n",
      "Iteration 1934, loss = 0.00636773\n",
      "Validation score: 0.713686\n",
      "Iteration 1935, loss = 0.00636509\n",
      "Validation score: 0.713802\n",
      "Iteration 1936, loss = 0.00636245\n",
      "Validation score: 0.713917\n",
      "Iteration 1937, loss = 0.00635980\n",
      "Validation score: 0.714032\n",
      "Iteration 1938, loss = 0.00635716\n",
      "Validation score: 0.714146\n",
      "Iteration 1939, loss = 0.00635452\n",
      "Validation score: 0.714259\n",
      "Iteration 1940, loss = 0.00635187\n",
      "Validation score: 0.714373\n",
      "Iteration 1941, loss = 0.00634924\n",
      "Validation score: 0.714485\n",
      "Iteration 1942, loss = 0.00634661\n",
      "Validation score: 0.714597\n",
      "Iteration 1943, loss = 0.00634398\n",
      "Validation score: 0.714708\n",
      "Iteration 1944, loss = 0.00634134\n",
      "Validation score: 0.714818\n",
      "Iteration 1945, loss = 0.00633868\n",
      "Validation score: 0.714927\n",
      "Iteration 1946, loss = 0.00633600\n",
      "Validation score: 0.715036\n",
      "Iteration 1947, loss = 0.00633332\n",
      "Validation score: 0.715145\n",
      "Iteration 1948, loss = 0.00633063\n",
      "Validation score: 0.715254\n",
      "Iteration 1949, loss = 0.00632793\n",
      "Validation score: 0.715363\n",
      "Iteration 1950, loss = 0.00632524\n",
      "Validation score: 0.715472\n",
      "Iteration 1951, loss = 0.00632255\n",
      "Validation score: 0.715580\n",
      "Iteration 1952, loss = 0.00631986\n",
      "Validation score: 0.715688\n",
      "Iteration 1953, loss = 0.00631718\n",
      "Validation score: 0.715796\n",
      "Iteration 1954, loss = 0.00631448\n",
      "Validation score: 0.715904\n",
      "Iteration 1955, loss = 0.00631179\n",
      "Validation score: 0.716012\n",
      "Iteration 1956, loss = 0.00630910\n",
      "Validation score: 0.716119\n",
      "Iteration 1957, loss = 0.00630642\n",
      "Validation score: 0.716225\n",
      "Iteration 1958, loss = 0.00630375\n",
      "Validation score: 0.716333\n",
      "Iteration 1959, loss = 0.00630108\n",
      "Validation score: 0.716441\n",
      "Iteration 1960, loss = 0.00629841\n",
      "Validation score: 0.716548\n",
      "Iteration 1961, loss = 0.00629575\n",
      "Validation score: 0.716655\n",
      "Iteration 1962, loss = 0.00629315\n",
      "Validation score: 0.716761\n",
      "Iteration 1963, loss = 0.00629056\n",
      "Validation score: 0.716867\n",
      "Iteration 1964, loss = 0.00628796\n",
      "Validation score: 0.716971\n",
      "Iteration 1965, loss = 0.00628535\n",
      "Validation score: 0.717076\n",
      "Iteration 1966, loss = 0.00628277\n",
      "Validation score: 0.717181\n",
      "Iteration 1967, loss = 0.00628020\n",
      "Validation score: 0.717286\n",
      "Iteration 1968, loss = 0.00627763\n",
      "Validation score: 0.717391\n",
      "Iteration 1969, loss = 0.00627506\n",
      "Validation score: 0.717496\n",
      "Iteration 1970, loss = 0.00627250\n",
      "Validation score: 0.717601\n",
      "Iteration 1971, loss = 0.00626995\n",
      "Validation score: 0.717707\n",
      "Iteration 1972, loss = 0.00626740\n",
      "Validation score: 0.717814\n",
      "Iteration 1973, loss = 0.00626486\n",
      "Validation score: 0.717920\n",
      "Iteration 1974, loss = 0.00626233\n",
      "Validation score: 0.718026\n",
      "Iteration 1975, loss = 0.00625981\n",
      "Validation score: 0.718131\n",
      "Iteration 1976, loss = 0.00625729\n",
      "Validation score: 0.718237\n",
      "Iteration 1977, loss = 0.00625478\n",
      "Validation score: 0.718343\n",
      "Iteration 1978, loss = 0.00625228\n",
      "Validation score: 0.718449\n",
      "Iteration 1979, loss = 0.00624978\n",
      "Validation score: 0.718555\n",
      "Iteration 1980, loss = 0.00624727\n",
      "Validation score: 0.718662\n",
      "Iteration 1981, loss = 0.00624476\n",
      "Validation score: 0.718770\n",
      "Iteration 1982, loss = 0.00624225\n",
      "Validation score: 0.718878\n",
      "Iteration 1983, loss = 0.00623973\n",
      "Validation score: 0.718985\n",
      "Iteration 1984, loss = 0.00623720\n",
      "Validation score: 0.719093\n",
      "Iteration 1985, loss = 0.00623467\n",
      "Validation score: 0.719201\n",
      "Iteration 1986, loss = 0.00623214\n",
      "Validation score: 0.719309\n",
      "Iteration 1987, loss = 0.00622961\n",
      "Validation score: 0.719417\n",
      "Iteration 1988, loss = 0.00622709\n",
      "Validation score: 0.719527\n",
      "Iteration 1989, loss = 0.00622453\n",
      "Validation score: 0.719637\n",
      "Iteration 1990, loss = 0.00622195\n",
      "Validation score: 0.719750\n",
      "Iteration 1991, loss = 0.00621937\n",
      "Validation score: 0.719863\n",
      "Iteration 1992, loss = 0.00621678\n",
      "Validation score: 0.719977\n",
      "Iteration 1993, loss = 0.00621419\n",
      "Validation score: 0.720091\n",
      "Iteration 1994, loss = 0.00621160\n",
      "Validation score: 0.720206\n",
      "Iteration 1995, loss = 0.00620901\n",
      "Validation score: 0.720323\n",
      "Iteration 1996, loss = 0.00620642\n",
      "Validation score: 0.720439\n",
      "Iteration 1997, loss = 0.00620382\n",
      "Validation score: 0.720557\n",
      "Iteration 1998, loss = 0.00620123\n",
      "Validation score: 0.720675\n",
      "Iteration 1999, loss = 0.00619864\n",
      "Validation score: 0.720795\n",
      "Iteration 2000, loss = 0.00619604\n",
      "Validation score: 0.720914\n",
      "Iteration 2001, loss = 0.00619345\n",
      "Validation score: 0.721034\n",
      "Iteration 2002, loss = 0.00619086\n",
      "Validation score: 0.721152\n",
      "Iteration 2003, loss = 0.00618827\n",
      "Validation score: 0.721270\n",
      "Iteration 2004, loss = 0.00618568\n",
      "Validation score: 0.721388\n",
      "Iteration 2005, loss = 0.00618309\n",
      "Validation score: 0.721505\n",
      "Iteration 2006, loss = 0.00618051\n",
      "Validation score: 0.721623\n",
      "Iteration 2007, loss = 0.00617792\n",
      "Validation score: 0.721742\n",
      "Iteration 2008, loss = 0.00617535\n",
      "Validation score: 0.721863\n",
      "Iteration 2009, loss = 0.00617279\n",
      "Validation score: 0.721982\n",
      "Iteration 2010, loss = 0.00617023\n",
      "Validation score: 0.722100\n",
      "Iteration 2011, loss = 0.00616767\n",
      "Validation score: 0.722217\n",
      "Iteration 2012, loss = 0.00616512\n",
      "Validation score: 0.722333\n",
      "Iteration 2013, loss = 0.00616257\n",
      "Validation score: 0.722449\n",
      "Iteration 2014, loss = 0.00616003\n",
      "Validation score: 0.722566\n",
      "Iteration 2015, loss = 0.00615750\n",
      "Validation score: 0.722683\n",
      "Iteration 2016, loss = 0.00615498\n",
      "Validation score: 0.722800\n",
      "Iteration 2017, loss = 0.00615245\n",
      "Validation score: 0.722918\n",
      "Iteration 2018, loss = 0.00614993\n",
      "Validation score: 0.723035\n",
      "Iteration 2019, loss = 0.00614742\n",
      "Validation score: 0.723153\n",
      "Iteration 2020, loss = 0.00614490\n",
      "Validation score: 0.723271\n",
      "Iteration 2021, loss = 0.00614239\n",
      "Validation score: 0.723387\n",
      "Iteration 2022, loss = 0.00613989\n",
      "Validation score: 0.723502\n",
      "Iteration 2023, loss = 0.00613739\n",
      "Validation score: 0.723616\n",
      "Iteration 2024, loss = 0.00613490\n",
      "Validation score: 0.723731\n",
      "Iteration 2025, loss = 0.00613243\n",
      "Validation score: 0.723846\n",
      "Iteration 2026, loss = 0.00612997\n",
      "Validation score: 0.723961\n",
      "Iteration 2027, loss = 0.00612751\n",
      "Validation score: 0.724075\n",
      "Iteration 2028, loss = 0.00612505\n",
      "Validation score: 0.724188\n",
      "Iteration 2029, loss = 0.00612259\n",
      "Validation score: 0.724301\n",
      "Iteration 2030, loss = 0.00612014\n",
      "Validation score: 0.724414\n",
      "Iteration 2031, loss = 0.00611775\n",
      "Validation score: 0.724528\n",
      "Iteration 2032, loss = 0.00611537\n",
      "Validation score: 0.724640\n",
      "Iteration 2033, loss = 0.00611300\n",
      "Validation score: 0.724751\n",
      "Iteration 2034, loss = 0.00611064\n",
      "Validation score: 0.724861\n",
      "Iteration 2035, loss = 0.00610828\n",
      "Validation score: 0.724971\n",
      "Iteration 2036, loss = 0.00610592\n",
      "Validation score: 0.725080\n",
      "Iteration 2037, loss = 0.00610357\n",
      "Validation score: 0.725188\n",
      "Iteration 2038, loss = 0.00610123\n",
      "Validation score: 0.725296\n",
      "Iteration 2039, loss = 0.00609890\n",
      "Validation score: 0.725404\n",
      "Iteration 2040, loss = 0.00609657\n",
      "Validation score: 0.725510\n",
      "Iteration 2041, loss = 0.00609426\n",
      "Validation score: 0.725615\n",
      "Iteration 2042, loss = 0.00609193\n",
      "Validation score: 0.725720\n",
      "Iteration 2043, loss = 0.00608961\n",
      "Validation score: 0.725825\n",
      "Iteration 2044, loss = 0.00608729\n",
      "Validation score: 0.725929\n",
      "Iteration 2045, loss = 0.00608497\n",
      "Validation score: 0.726033\n",
      "Iteration 2046, loss = 0.00608266\n",
      "Validation score: 0.726137\n",
      "Iteration 2047, loss = 0.00608035\n",
      "Validation score: 0.726239\n",
      "Iteration 2048, loss = 0.00607804\n",
      "Validation score: 0.726340\n",
      "Iteration 2049, loss = 0.00607574\n",
      "Validation score: 0.726442\n",
      "Iteration 2050, loss = 0.00607343\n",
      "Validation score: 0.726544\n",
      "Iteration 2051, loss = 0.00607112\n",
      "Validation score: 0.726645\n",
      "Iteration 2052, loss = 0.00606880\n",
      "Validation score: 0.726746\n",
      "Iteration 2053, loss = 0.00606649\n",
      "Validation score: 0.726846\n",
      "Iteration 2054, loss = 0.00606417\n",
      "Validation score: 0.726947\n",
      "Iteration 2055, loss = 0.00606185\n",
      "Validation score: 0.727048\n",
      "Iteration 2056, loss = 0.00605953\n",
      "Validation score: 0.727147\n",
      "Iteration 2057, loss = 0.00605721\n",
      "Validation score: 0.727246\n",
      "Iteration 2058, loss = 0.00605489\n",
      "Validation score: 0.727344\n",
      "Iteration 2059, loss = 0.00605256\n",
      "Validation score: 0.727442\n",
      "Iteration 2060, loss = 0.00605024\n",
      "Validation score: 0.727540\n",
      "Iteration 2061, loss = 0.00604792\n",
      "Validation score: 0.727638\n",
      "Iteration 2062, loss = 0.00604561\n",
      "Validation score: 0.727736\n",
      "Iteration 2063, loss = 0.00604330\n",
      "Validation score: 0.727834\n",
      "Iteration 2064, loss = 0.00604100\n",
      "Validation score: 0.727932\n",
      "Iteration 2065, loss = 0.00603868\n",
      "Validation score: 0.728030\n",
      "Iteration 2066, loss = 0.00603638\n",
      "Validation score: 0.728126\n",
      "Iteration 2067, loss = 0.00603408\n",
      "Validation score: 0.728221\n",
      "Iteration 2068, loss = 0.00603178\n",
      "Validation score: 0.728315\n",
      "Iteration 2069, loss = 0.00602947\n",
      "Validation score: 0.728409\n",
      "Iteration 2070, loss = 0.00602717\n",
      "Validation score: 0.728503\n",
      "Iteration 2071, loss = 0.00602486\n",
      "Validation score: 0.728598\n",
      "Iteration 2072, loss = 0.00602254\n",
      "Validation score: 0.728695\n",
      "Iteration 2073, loss = 0.00602022\n",
      "Validation score: 0.728792\n",
      "Iteration 2074, loss = 0.00601790\n",
      "Validation score: 0.728891\n",
      "Iteration 2075, loss = 0.00601558\n",
      "Validation score: 0.728989\n",
      "Iteration 2076, loss = 0.00601326\n",
      "Validation score: 0.729087\n",
      "Iteration 2077, loss = 0.00601092\n",
      "Validation score: 0.729185\n",
      "Iteration 2078, loss = 0.00600857\n",
      "Validation score: 0.729282\n",
      "Iteration 2079, loss = 0.00600621\n",
      "Validation score: 0.729381\n",
      "Iteration 2080, loss = 0.00600385\n",
      "Validation score: 0.729481\n",
      "Iteration 2081, loss = 0.00600149\n",
      "Validation score: 0.729581\n",
      "Iteration 2082, loss = 0.00599914\n",
      "Validation score: 0.729681\n",
      "Iteration 2083, loss = 0.00599678\n",
      "Validation score: 0.729781\n",
      "Iteration 2084, loss = 0.00599443\n",
      "Validation score: 0.729882\n",
      "Iteration 2085, loss = 0.00599207\n",
      "Validation score: 0.729982\n",
      "Iteration 2086, loss = 0.00598972\n",
      "Validation score: 0.730082\n",
      "Iteration 2087, loss = 0.00598737\n",
      "Validation score: 0.730182\n",
      "Iteration 2088, loss = 0.00598502\n",
      "Validation score: 0.730282\n",
      "Iteration 2089, loss = 0.00598266\n",
      "Validation score: 0.730383\n",
      "Iteration 2090, loss = 0.00598032\n",
      "Validation score: 0.730483\n",
      "Iteration 2091, loss = 0.00597797\n",
      "Validation score: 0.730583\n",
      "Iteration 2092, loss = 0.00597563\n",
      "Validation score: 0.730683\n",
      "Iteration 2093, loss = 0.00597330\n",
      "Validation score: 0.730784\n",
      "Iteration 2094, loss = 0.00597096\n",
      "Validation score: 0.730886\n",
      "Iteration 2095, loss = 0.00596863\n",
      "Validation score: 0.730987\n",
      "Iteration 2096, loss = 0.00596630\n",
      "Validation score: 0.731088\n",
      "Iteration 2097, loss = 0.00596397\n",
      "Validation score: 0.731189\n",
      "Iteration 2098, loss = 0.00596165\n",
      "Validation score: 0.731289\n",
      "Iteration 2099, loss = 0.00595933\n",
      "Validation score: 0.731389\n",
      "Iteration 2100, loss = 0.00595700\n",
      "Validation score: 0.731489\n",
      "Iteration 2101, loss = 0.00595468\n",
      "Validation score: 0.731588\n",
      "Iteration 2102, loss = 0.00595236\n",
      "Validation score: 0.731689\n",
      "Iteration 2103, loss = 0.00595005\n",
      "Validation score: 0.731790\n",
      "Iteration 2104, loss = 0.00594773\n",
      "Validation score: 0.731890\n",
      "Iteration 2105, loss = 0.00594541\n",
      "Validation score: 0.731990\n",
      "Iteration 2106, loss = 0.00594308\n",
      "Validation score: 0.732090\n",
      "Iteration 2107, loss = 0.00594075\n",
      "Validation score: 0.732189\n",
      "Iteration 2108, loss = 0.00593842\n",
      "Validation score: 0.732289\n",
      "Iteration 2109, loss = 0.00593609\n",
      "Validation score: 0.732390\n",
      "Iteration 2110, loss = 0.00593375\n",
      "Validation score: 0.732491\n",
      "Iteration 2111, loss = 0.00593140\n",
      "Validation score: 0.732592\n",
      "Iteration 2112, loss = 0.00592907\n",
      "Validation score: 0.732692\n",
      "Iteration 2113, loss = 0.00592672\n",
      "Validation score: 0.732796\n",
      "Iteration 2114, loss = 0.00592439\n",
      "Validation score: 0.732902\n",
      "Iteration 2115, loss = 0.00592205\n",
      "Validation score: 0.733008\n",
      "Iteration 2116, loss = 0.00591972\n",
      "Validation score: 0.733116\n",
      "Iteration 2117, loss = 0.00591739\n",
      "Validation score: 0.733223\n",
      "Iteration 2118, loss = 0.00591505\n",
      "Validation score: 0.733331\n",
      "Iteration 2119, loss = 0.00591272\n",
      "Validation score: 0.733437\n",
      "Iteration 2120, loss = 0.00591039\n",
      "Validation score: 0.733542\n",
      "Iteration 2121, loss = 0.00590805\n",
      "Validation score: 0.733648\n",
      "Iteration 2122, loss = 0.00590572\n",
      "Validation score: 0.733758\n",
      "Iteration 2123, loss = 0.00590340\n",
      "Validation score: 0.733869\n",
      "Iteration 2124, loss = 0.00590107\n",
      "Validation score: 0.733979\n",
      "Iteration 2125, loss = 0.00589875\n",
      "Validation score: 0.734090\n",
      "Iteration 2126, loss = 0.00589644\n",
      "Validation score: 0.734202\n",
      "Iteration 2127, loss = 0.00589413\n",
      "Validation score: 0.734317\n",
      "Iteration 2128, loss = 0.00589179\n",
      "Validation score: 0.734432\n",
      "Iteration 2129, loss = 0.00588943\n",
      "Validation score: 0.734548\n",
      "Iteration 2130, loss = 0.00588707\n",
      "Validation score: 0.734665\n",
      "Iteration 2131, loss = 0.00588470\n",
      "Validation score: 0.734786\n",
      "Iteration 2132, loss = 0.00588233\n",
      "Validation score: 0.734908\n",
      "Iteration 2133, loss = 0.00587996\n",
      "Validation score: 0.735029\n",
      "Iteration 2134, loss = 0.00587759\n",
      "Validation score: 0.735151\n",
      "Iteration 2135, loss = 0.00587522\n",
      "Validation score: 0.735277\n",
      "Iteration 2136, loss = 0.00587284\n",
      "Validation score: 0.735403\n",
      "Iteration 2137, loss = 0.00587047\n",
      "Validation score: 0.735527\n",
      "Iteration 2138, loss = 0.00586809\n",
      "Validation score: 0.735652\n",
      "Iteration 2139, loss = 0.00586571\n",
      "Validation score: 0.735777\n",
      "Iteration 2140, loss = 0.00586334\n",
      "Validation score: 0.735901\n",
      "Iteration 2141, loss = 0.00586096\n",
      "Validation score: 0.736026\n",
      "Iteration 2142, loss = 0.00585856\n",
      "Validation score: 0.736150\n",
      "Iteration 2143, loss = 0.00585616\n",
      "Validation score: 0.736275\n",
      "Iteration 2144, loss = 0.00585375\n",
      "Validation score: 0.736400\n",
      "Iteration 2145, loss = 0.00585135\n",
      "Validation score: 0.736526\n",
      "Iteration 2146, loss = 0.00584894\n",
      "Validation score: 0.736652\n",
      "Iteration 2147, loss = 0.00584653\n",
      "Validation score: 0.736776\n",
      "Iteration 2148, loss = 0.00584411\n",
      "Validation score: 0.736899\n",
      "Iteration 2149, loss = 0.00584169\n",
      "Validation score: 0.737021\n",
      "Iteration 2150, loss = 0.00583927\n",
      "Validation score: 0.737143\n",
      "Iteration 2151, loss = 0.00583685\n",
      "Validation score: 0.737265\n",
      "Iteration 2152, loss = 0.00583442\n",
      "Validation score: 0.737388\n",
      "Iteration 2153, loss = 0.00583200\n",
      "Validation score: 0.737511\n",
      "Iteration 2154, loss = 0.00582959\n",
      "Validation score: 0.737634\n",
      "Iteration 2155, loss = 0.00582716\n",
      "Validation score: 0.737756\n",
      "Iteration 2156, loss = 0.00582473\n",
      "Validation score: 0.737877\n",
      "Iteration 2157, loss = 0.00582231\n",
      "Validation score: 0.737997\n",
      "Iteration 2158, loss = 0.00581990\n",
      "Validation score: 0.738117\n",
      "Iteration 2159, loss = 0.00581749\n",
      "Validation score: 0.738236\n",
      "Iteration 2160, loss = 0.00581508\n",
      "Validation score: 0.738355\n",
      "Iteration 2161, loss = 0.00581268\n",
      "Validation score: 0.738474\n",
      "Iteration 2162, loss = 0.00581028\n",
      "Validation score: 0.738591\n",
      "Iteration 2163, loss = 0.00580789\n",
      "Validation score: 0.738708\n",
      "Iteration 2164, loss = 0.00580550\n",
      "Validation score: 0.738824\n",
      "Iteration 2165, loss = 0.00580311\n",
      "Validation score: 0.738939\n",
      "Iteration 2166, loss = 0.00580071\n",
      "Validation score: 0.739054\n",
      "Iteration 2167, loss = 0.00579832\n",
      "Validation score: 0.739169\n",
      "Iteration 2168, loss = 0.00579592\n",
      "Validation score: 0.739282\n",
      "Iteration 2169, loss = 0.00579352\n",
      "Validation score: 0.739395\n",
      "Iteration 2170, loss = 0.00579111\n",
      "Validation score: 0.739507\n",
      "Iteration 2171, loss = 0.00578871\n",
      "Validation score: 0.739618\n",
      "Iteration 2172, loss = 0.00578631\n",
      "Validation score: 0.739729\n",
      "Iteration 2173, loss = 0.00578391\n",
      "Validation score: 0.739840\n",
      "Iteration 2174, loss = 0.00578151\n",
      "Validation score: 0.739949\n",
      "Iteration 2175, loss = 0.00577911\n",
      "Validation score: 0.740058\n",
      "Iteration 2176, loss = 0.00577671\n",
      "Validation score: 0.740167\n",
      "Iteration 2177, loss = 0.00577431\n",
      "Validation score: 0.740275\n",
      "Iteration 2178, loss = 0.00577190\n",
      "Validation score: 0.740382\n",
      "Iteration 2179, loss = 0.00576949\n",
      "Validation score: 0.740490\n",
      "Iteration 2180, loss = 0.00576708\n",
      "Validation score: 0.740600\n",
      "Iteration 2181, loss = 0.00576468\n",
      "Validation score: 0.740710\n",
      "Iteration 2182, loss = 0.00576227\n",
      "Validation score: 0.740820\n",
      "Iteration 2183, loss = 0.00575986\n",
      "Validation score: 0.740930\n",
      "Iteration 2184, loss = 0.00575744\n",
      "Validation score: 0.741039\n",
      "Iteration 2185, loss = 0.00575503\n",
      "Validation score: 0.741147\n",
      "Iteration 2186, loss = 0.00575262\n",
      "Validation score: 0.741255\n",
      "Iteration 2187, loss = 0.00575022\n",
      "Validation score: 0.741363\n",
      "Iteration 2188, loss = 0.00574780\n",
      "Validation score: 0.741470\n",
      "Iteration 2189, loss = 0.00574537\n",
      "Validation score: 0.741577\n",
      "Iteration 2190, loss = 0.00574295\n",
      "Validation score: 0.741684\n",
      "Iteration 2191, loss = 0.00574053\n",
      "Validation score: 0.741791\n",
      "Iteration 2192, loss = 0.00573810\n",
      "Validation score: 0.741900\n",
      "Iteration 2193, loss = 0.00573568\n",
      "Validation score: 0.742008\n",
      "Iteration 2194, loss = 0.00573325\n",
      "Validation score: 0.742116\n",
      "Iteration 2195, loss = 0.00573083\n",
      "Validation score: 0.742222\n",
      "Iteration 2196, loss = 0.00572841\n",
      "Validation score: 0.742328\n",
      "Iteration 2197, loss = 0.00572601\n",
      "Validation score: 0.742433\n",
      "Iteration 2198, loss = 0.00572362\n",
      "Validation score: 0.742538\n",
      "Iteration 2199, loss = 0.00572122\n",
      "Validation score: 0.742642\n",
      "Iteration 2200, loss = 0.00571883\n",
      "Validation score: 0.742745\n",
      "Iteration 2201, loss = 0.00571644\n",
      "Validation score: 0.742848\n",
      "Iteration 2202, loss = 0.00571406\n",
      "Validation score: 0.742950\n",
      "Iteration 2203, loss = 0.00571168\n",
      "Validation score: 0.743052\n",
      "Iteration 2204, loss = 0.00570929\n",
      "Validation score: 0.743154\n",
      "Iteration 2205, loss = 0.00570690\n",
      "Validation score: 0.743256\n",
      "Iteration 2206, loss = 0.00570450\n",
      "Validation score: 0.743358\n",
      "Iteration 2207, loss = 0.00570208\n",
      "Validation score: 0.743460\n",
      "Iteration 2208, loss = 0.00569965\n",
      "Validation score: 0.743563\n",
      "Iteration 2209, loss = 0.00569721\n",
      "Validation score: 0.743664\n",
      "Iteration 2210, loss = 0.00569477\n",
      "Validation score: 0.743766\n",
      "Iteration 2211, loss = 0.00569234\n",
      "Validation score: 0.743866\n",
      "Iteration 2212, loss = 0.00568991\n",
      "Validation score: 0.743966\n",
      "Iteration 2213, loss = 0.00568748\n",
      "Validation score: 0.744065\n",
      "Iteration 2214, loss = 0.00568505\n",
      "Validation score: 0.744164\n",
      "Iteration 2215, loss = 0.00568262\n",
      "Validation score: 0.744263\n",
      "Iteration 2216, loss = 0.00568020\n",
      "Validation score: 0.744362\n",
      "Iteration 2217, loss = 0.00567778\n",
      "Validation score: 0.744461\n",
      "Iteration 2218, loss = 0.00567536\n",
      "Validation score: 0.744560\n",
      "Iteration 2219, loss = 0.00567295\n",
      "Validation score: 0.744658\n",
      "Iteration 2220, loss = 0.00567054\n",
      "Validation score: 0.744756\n",
      "Iteration 2221, loss = 0.00566814\n",
      "Validation score: 0.744855\n",
      "Iteration 2222, loss = 0.00566574\n",
      "Validation score: 0.744953\n",
      "Iteration 2223, loss = 0.00566335\n",
      "Validation score: 0.745050\n",
      "Iteration 2224, loss = 0.00566095\n",
      "Validation score: 0.745149\n",
      "Iteration 2225, loss = 0.00565856\n",
      "Validation score: 0.745247\n",
      "Iteration 2226, loss = 0.00565617\n",
      "Validation score: 0.745346\n",
      "Iteration 2227, loss = 0.00565379\n",
      "Validation score: 0.745445\n",
      "Iteration 2228, loss = 0.00565141\n",
      "Validation score: 0.745545\n",
      "Iteration 2229, loss = 0.00564903\n",
      "Validation score: 0.745644\n",
      "Iteration 2230, loss = 0.00564667\n",
      "Validation score: 0.745741\n",
      "Iteration 2231, loss = 0.00564431\n",
      "Validation score: 0.745839\n",
      "Iteration 2232, loss = 0.00564196\n",
      "Validation score: 0.745937\n",
      "Iteration 2233, loss = 0.00563962\n",
      "Validation score: 0.746036\n",
      "Iteration 2234, loss = 0.00563729\n",
      "Validation score: 0.746149\n",
      "Iteration 2235, loss = 0.00563498\n",
      "Validation score: 0.746266\n",
      "Iteration 2236, loss = 0.00563270\n",
      "Validation score: 0.746381\n",
      "Iteration 2237, loss = 0.00563042\n",
      "Validation score: 0.746495\n",
      "Iteration 2238, loss = 0.00562814\n",
      "Validation score: 0.746609\n",
      "Iteration 2239, loss = 0.00562587\n",
      "Validation score: 0.746721\n",
      "Iteration 2240, loss = 0.00562361\n",
      "Validation score: 0.746833\n",
      "Iteration 2241, loss = 0.00562134\n",
      "Validation score: 0.746943\n",
      "Iteration 2242, loss = 0.00561909\n",
      "Validation score: 0.747054\n",
      "Iteration 2243, loss = 0.00561684\n",
      "Validation score: 0.747166\n",
      "Iteration 2244, loss = 0.00561460\n",
      "Validation score: 0.747277\n",
      "Iteration 2245, loss = 0.00561235\n",
      "Validation score: 0.747388\n",
      "Iteration 2246, loss = 0.00561011\n",
      "Validation score: 0.747497\n",
      "Iteration 2247, loss = 0.00560788\n",
      "Validation score: 0.747606\n",
      "Iteration 2248, loss = 0.00560565\n",
      "Validation score: 0.747715\n",
      "Iteration 2249, loss = 0.00560342\n",
      "Validation score: 0.747823\n",
      "Iteration 2250, loss = 0.00560122\n",
      "Validation score: 0.747932\n",
      "Iteration 2251, loss = 0.00559901\n",
      "Validation score: 0.748040\n",
      "Iteration 2252, loss = 0.00559682\n",
      "Validation score: 0.748148\n",
      "Iteration 2253, loss = 0.00559465\n",
      "Validation score: 0.748256\n",
      "Iteration 2254, loss = 0.00559249\n",
      "Validation score: 0.748363\n",
      "Iteration 2255, loss = 0.00559033\n",
      "Validation score: 0.748469\n",
      "Iteration 2256, loss = 0.00558818\n",
      "Validation score: 0.748573\n",
      "Iteration 2257, loss = 0.00558604\n",
      "Validation score: 0.748682\n",
      "Iteration 2258, loss = 0.00558391\n",
      "Validation score: 0.748792\n",
      "Iteration 2259, loss = 0.00558179\n",
      "Validation score: 0.748901\n",
      "Iteration 2260, loss = 0.00557966\n",
      "Validation score: 0.749009\n",
      "Iteration 2261, loss = 0.00557754\n",
      "Validation score: 0.749117\n",
      "Iteration 2262, loss = 0.00557543\n",
      "Validation score: 0.749225\n",
      "Iteration 2263, loss = 0.00557331\n",
      "Validation score: 0.749333\n",
      "Iteration 2264, loss = 0.00557121\n",
      "Validation score: 0.749440\n",
      "Iteration 2265, loss = 0.00556910\n",
      "Validation score: 0.749546\n",
      "Iteration 2266, loss = 0.00556701\n",
      "Validation score: 0.749653\n",
      "Iteration 2267, loss = 0.00556492\n",
      "Validation score: 0.749758\n",
      "Iteration 2268, loss = 0.00556283\n",
      "Validation score: 0.749865\n",
      "Iteration 2269, loss = 0.00556074\n",
      "Validation score: 0.749970\n",
      "Iteration 2270, loss = 0.00555867\n",
      "Validation score: 0.750076\n",
      "Iteration 2271, loss = 0.00555659\n",
      "Validation score: 0.750183\n",
      "Iteration 2272, loss = 0.00555452\n",
      "Validation score: 0.750289\n",
      "Iteration 2273, loss = 0.00555244\n",
      "Validation score: 0.750399\n",
      "Iteration 2274, loss = 0.00555036\n",
      "Validation score: 0.750509\n",
      "Iteration 2275, loss = 0.00554829\n",
      "Validation score: 0.750618\n",
      "Iteration 2276, loss = 0.00554623\n",
      "Validation score: 0.750726\n",
      "Iteration 2277, loss = 0.00554418\n",
      "Validation score: 0.750834\n",
      "Iteration 2278, loss = 0.00554213\n",
      "Validation score: 0.750941\n",
      "Iteration 2279, loss = 0.00554007\n",
      "Validation score: 0.751049\n",
      "Iteration 2280, loss = 0.00553802\n",
      "Validation score: 0.751155\n",
      "Iteration 2281, loss = 0.00553598\n",
      "Validation score: 0.751260\n",
      "Iteration 2282, loss = 0.00553394\n",
      "Validation score: 0.751365\n",
      "Iteration 2283, loss = 0.00553191\n",
      "Validation score: 0.751471\n",
      "Iteration 2284, loss = 0.00552988\n",
      "Validation score: 0.751578\n",
      "Iteration 2285, loss = 0.00552785\n",
      "Validation score: 0.751684\n",
      "Iteration 2286, loss = 0.00552582\n",
      "Validation score: 0.751788\n",
      "Iteration 2287, loss = 0.00552379\n",
      "Validation score: 0.751892\n",
      "Iteration 2288, loss = 0.00552176\n",
      "Validation score: 0.751997\n",
      "Iteration 2289, loss = 0.00551974\n",
      "Validation score: 0.752102\n",
      "Iteration 2290, loss = 0.00551771\n",
      "Validation score: 0.752206\n",
      "Iteration 2291, loss = 0.00551569\n",
      "Validation score: 0.752311\n",
      "Iteration 2292, loss = 0.00551367\n",
      "Validation score: 0.752415\n",
      "Iteration 2293, loss = 0.00551165\n",
      "Validation score: 0.752519\n",
      "Iteration 2294, loss = 0.00550963\n",
      "Validation score: 0.752622\n",
      "Iteration 2295, loss = 0.00550761\n",
      "Validation score: 0.752725\n",
      "Iteration 2296, loss = 0.00550559\n",
      "Validation score: 0.752828\n",
      "Iteration 2297, loss = 0.00550356\n",
      "Validation score: 0.752932\n",
      "Iteration 2298, loss = 0.00550153\n",
      "Validation score: 0.753036\n",
      "Iteration 2299, loss = 0.00549951\n",
      "Validation score: 0.753139\n",
      "Iteration 2300, loss = 0.00549748\n",
      "Validation score: 0.753242\n",
      "Iteration 2301, loss = 0.00549546\n",
      "Validation score: 0.753344\n",
      "Iteration 2302, loss = 0.00549346\n",
      "Validation score: 0.753449\n",
      "Iteration 2303, loss = 0.00549147\n",
      "Validation score: 0.753559\n",
      "Iteration 2304, loss = 0.00548949\n",
      "Validation score: 0.753670\n",
      "Iteration 2305, loss = 0.00548751\n",
      "Validation score: 0.753783\n",
      "Iteration 2306, loss = 0.00548553\n",
      "Validation score: 0.753896\n",
      "Iteration 2307, loss = 0.00548356\n",
      "Validation score: 0.754009\n",
      "Iteration 2308, loss = 0.00548159\n",
      "Validation score: 0.754121\n",
      "Iteration 2309, loss = 0.00547963\n",
      "Validation score: 0.754232\n",
      "Iteration 2310, loss = 0.00547767\n",
      "Validation score: 0.754342\n",
      "Iteration 2311, loss = 0.00547571\n",
      "Validation score: 0.754453\n",
      "Iteration 2312, loss = 0.00547375\n",
      "Validation score: 0.754563\n",
      "Iteration 2313, loss = 0.00547181\n",
      "Validation score: 0.754674\n",
      "Iteration 2314, loss = 0.00546986\n",
      "Validation score: 0.754784\n",
      "Iteration 2315, loss = 0.00546794\n",
      "Validation score: 0.754892\n",
      "Iteration 2316, loss = 0.00546601\n",
      "Validation score: 0.754997\n",
      "Iteration 2317, loss = 0.00546410\n",
      "Validation score: 0.755102\n",
      "Iteration 2318, loss = 0.00546218\n",
      "Validation score: 0.755207\n",
      "Iteration 2319, loss = 0.00546027\n",
      "Validation score: 0.755311\n",
      "Iteration 2320, loss = 0.00545837\n",
      "Validation score: 0.755415\n",
      "Iteration 2321, loss = 0.00545647\n",
      "Validation score: 0.755518\n",
      "Iteration 2322, loss = 0.00545458\n",
      "Validation score: 0.755619\n",
      "Iteration 2323, loss = 0.00545268\n",
      "Validation score: 0.755721\n",
      "Iteration 2324, loss = 0.00545079\n",
      "Validation score: 0.755821\n",
      "Iteration 2325, loss = 0.00544891\n",
      "Validation score: 0.755921\n",
      "Iteration 2326, loss = 0.00544702\n",
      "Validation score: 0.756021\n",
      "Iteration 2327, loss = 0.00544514\n",
      "Validation score: 0.756120\n",
      "Iteration 2328, loss = 0.00544327\n",
      "Validation score: 0.756220\n",
      "Iteration 2329, loss = 0.00544139\n",
      "Validation score: 0.756320\n",
      "Iteration 2330, loss = 0.00543952\n",
      "Validation score: 0.756420\n",
      "Iteration 2331, loss = 0.00543768\n",
      "Validation score: 0.756518\n",
      "Iteration 2332, loss = 0.00543584\n",
      "Validation score: 0.756616\n",
      "Iteration 2333, loss = 0.00543398\n",
      "Validation score: 0.756712\n",
      "Iteration 2334, loss = 0.00543211\n",
      "Validation score: 0.756808\n",
      "Iteration 2335, loss = 0.00543024\n",
      "Validation score: 0.756904\n",
      "Iteration 2336, loss = 0.00542838\n",
      "Validation score: 0.757000\n",
      "Iteration 2337, loss = 0.00542652\n",
      "Validation score: 0.757097\n",
      "Iteration 2338, loss = 0.00542465\n",
      "Validation score: 0.757193\n",
      "Iteration 2339, loss = 0.00542279\n",
      "Validation score: 0.757289\n",
      "Iteration 2340, loss = 0.00542094\n",
      "Validation score: 0.757384\n",
      "Iteration 2341, loss = 0.00541909\n",
      "Validation score: 0.757479\n",
      "Iteration 2342, loss = 0.00541725\n",
      "Validation score: 0.757572\n",
      "Iteration 2343, loss = 0.00541541\n",
      "Validation score: 0.757664\n",
      "Iteration 2344, loss = 0.00541358\n",
      "Validation score: 0.757757\n",
      "Iteration 2345, loss = 0.00541176\n",
      "Validation score: 0.757849\n",
      "Iteration 2346, loss = 0.00540994\n",
      "Validation score: 0.757943\n",
      "Iteration 2347, loss = 0.00540814\n",
      "Validation score: 0.758037\n",
      "Iteration 2348, loss = 0.00540636\n",
      "Validation score: 0.758129\n",
      "Iteration 2349, loss = 0.00540461\n",
      "Validation score: 0.758220\n",
      "Iteration 2350, loss = 0.00540286\n",
      "Validation score: 0.758312\n",
      "Iteration 2351, loss = 0.00540113\n",
      "Validation score: 0.758403\n",
      "Iteration 2352, loss = 0.00539939\n",
      "Validation score: 0.758496\n",
      "Iteration 2353, loss = 0.00539768\n",
      "Validation score: 0.758588\n",
      "Iteration 2354, loss = 0.00539596\n",
      "Validation score: 0.758682\n",
      "Iteration 2355, loss = 0.00539425\n",
      "Validation score: 0.758775\n",
      "Iteration 2356, loss = 0.00539256\n",
      "Validation score: 0.758869\n",
      "Iteration 2357, loss = 0.00539087\n",
      "Validation score: 0.758962\n",
      "Iteration 2358, loss = 0.00538918\n",
      "Validation score: 0.759055\n",
      "Iteration 2359, loss = 0.00538749\n",
      "Validation score: 0.759147\n",
      "Iteration 2360, loss = 0.00538580\n",
      "Validation score: 0.759239\n",
      "Iteration 2361, loss = 0.00538411\n",
      "Validation score: 0.759332\n",
      "Iteration 2362, loss = 0.00538242\n",
      "Validation score: 0.759426\n",
      "Iteration 2363, loss = 0.00538074\n",
      "Validation score: 0.759520\n",
      "Iteration 2364, loss = 0.00537905\n",
      "Validation score: 0.759614\n",
      "Iteration 2365, loss = 0.00537737\n",
      "Validation score: 0.759708\n",
      "Iteration 2366, loss = 0.00537569\n",
      "Validation score: 0.759802\n",
      "Iteration 2367, loss = 0.00537401\n",
      "Validation score: 0.759898\n",
      "Iteration 2368, loss = 0.00537231\n",
      "Validation score: 0.759993\n",
      "Iteration 2369, loss = 0.00537061\n",
      "Validation score: 0.760089\n",
      "Iteration 2370, loss = 0.00536891\n",
      "Validation score: 0.760184\n",
      "Iteration 2371, loss = 0.00536721\n",
      "Validation score: 0.760281\n",
      "Iteration 2372, loss = 0.00536551\n",
      "Validation score: 0.760378\n",
      "Iteration 2373, loss = 0.00536380\n",
      "Validation score: 0.760476\n",
      "Iteration 2374, loss = 0.00536209\n",
      "Validation score: 0.760574\n",
      "Iteration 2375, loss = 0.00536041\n",
      "Validation score: 0.760671\n",
      "Iteration 2376, loss = 0.00535872\n",
      "Validation score: 0.760769\n",
      "Iteration 2377, loss = 0.00535704\n",
      "Validation score: 0.760866\n",
      "Iteration 2378, loss = 0.00535535\n",
      "Validation score: 0.760963\n",
      "Iteration 2379, loss = 0.00535366\n",
      "Validation score: 0.761060\n",
      "Iteration 2380, loss = 0.00535197\n",
      "Validation score: 0.761155\n",
      "Iteration 2381, loss = 0.00535028\n",
      "Validation score: 0.761250\n",
      "Iteration 2382, loss = 0.00534859\n",
      "Validation score: 0.761344\n",
      "Iteration 2383, loss = 0.00534690\n",
      "Validation score: 0.761438\n",
      "Iteration 2384, loss = 0.00534521\n",
      "Validation score: 0.761532\n",
      "Iteration 2385, loss = 0.00534352\n",
      "Validation score: 0.761627\n",
      "Iteration 2386, loss = 0.00534184\n",
      "Validation score: 0.761722\n",
      "Iteration 2387, loss = 0.00534015\n",
      "Validation score: 0.761817\n",
      "Iteration 2388, loss = 0.00533847\n",
      "Validation score: 0.761912\n",
      "Iteration 2389, loss = 0.00533677\n",
      "Validation score: 0.762007\n",
      "Iteration 2390, loss = 0.00533508\n",
      "Validation score: 0.762103\n",
      "Iteration 2391, loss = 0.00533339\n",
      "Validation score: 0.762197\n",
      "Iteration 2392, loss = 0.00533171\n",
      "Validation score: 0.762291\n",
      "Iteration 2393, loss = 0.00533003\n",
      "Validation score: 0.762384\n",
      "Iteration 2394, loss = 0.00532835\n",
      "Validation score: 0.762476\n",
      "Iteration 2395, loss = 0.00532667\n",
      "Validation score: 0.762567\n",
      "Iteration 2396, loss = 0.00532500\n",
      "Validation score: 0.762658\n",
      "Iteration 2397, loss = 0.00532334\n",
      "Validation score: 0.762748\n",
      "Iteration 2398, loss = 0.00532169\n",
      "Validation score: 0.762837\n",
      "Iteration 2399, loss = 0.00532004\n",
      "Validation score: 0.762926\n",
      "Iteration 2400, loss = 0.00531839\n",
      "Validation score: 0.763013\n",
      "Iteration 2401, loss = 0.00531674\n",
      "Validation score: 0.763100\n",
      "Iteration 2402, loss = 0.00531510\n",
      "Validation score: 0.763185\n",
      "Iteration 2403, loss = 0.00531346\n",
      "Validation score: 0.763270\n",
      "Iteration 2404, loss = 0.00531183\n",
      "Validation score: 0.763354\n",
      "Iteration 2405, loss = 0.00531019\n",
      "Validation score: 0.763438\n",
      "Iteration 2406, loss = 0.00530856\n",
      "Validation score: 0.763522\n",
      "Iteration 2407, loss = 0.00530694\n",
      "Validation score: 0.763606\n",
      "Iteration 2408, loss = 0.00530531\n",
      "Validation score: 0.763689\n",
      "Iteration 2409, loss = 0.00530369\n",
      "Validation score: 0.763773\n",
      "Iteration 2410, loss = 0.00530206\n",
      "Validation score: 0.763858\n",
      "Iteration 2411, loss = 0.00530045\n",
      "Validation score: 0.763943\n",
      "Iteration 2412, loss = 0.00529883\n",
      "Validation score: 0.764026\n",
      "Iteration 2413, loss = 0.00529722\n",
      "Validation score: 0.764109\n",
      "Iteration 2414, loss = 0.00529561\n",
      "Validation score: 0.764191\n",
      "Iteration 2415, loss = 0.00529400\n",
      "Validation score: 0.764273\n",
      "Iteration 2416, loss = 0.00529240\n",
      "Validation score: 0.764354\n",
      "Iteration 2417, loss = 0.00529079\n",
      "Validation score: 0.764435\n",
      "Iteration 2418, loss = 0.00528918\n",
      "Validation score: 0.764516\n",
      "Iteration 2419, loss = 0.00528756\n",
      "Validation score: 0.764597\n",
      "Iteration 2420, loss = 0.00528594\n",
      "Validation score: 0.764679\n",
      "Iteration 2421, loss = 0.00528432\n",
      "Validation score: 0.764760\n",
      "Iteration 2422, loss = 0.00528270\n",
      "Validation score: 0.764841\n",
      "Iteration 2423, loss = 0.00528107\n",
      "Validation score: 0.764922\n",
      "Iteration 2424, loss = 0.00527945\n",
      "Validation score: 0.765004\n",
      "Iteration 2425, loss = 0.00527783\n",
      "Validation score: 0.765085\n",
      "Iteration 2426, loss = 0.00527620\n",
      "Validation score: 0.765167\n",
      "Iteration 2427, loss = 0.00527458\n",
      "Validation score: 0.765248\n",
      "Iteration 2428, loss = 0.00527296\n",
      "Validation score: 0.765329\n",
      "Iteration 2429, loss = 0.00527134\n",
      "Validation score: 0.765410\n",
      "Iteration 2430, loss = 0.00526972\n",
      "Validation score: 0.765491\n",
      "Iteration 2431, loss = 0.00526811\n",
      "Validation score: 0.765571\n",
      "Iteration 2432, loss = 0.00526649\n",
      "Validation score: 0.765650\n",
      "Iteration 2433, loss = 0.00526489\n",
      "Validation score: 0.765728\n",
      "Iteration 2434, loss = 0.00526329\n",
      "Validation score: 0.765806\n",
      "Iteration 2435, loss = 0.00526170\n",
      "Validation score: 0.765883\n",
      "Iteration 2436, loss = 0.00526011\n",
      "Validation score: 0.765960\n",
      "Iteration 2437, loss = 0.00525851\n",
      "Validation score: 0.766037\n",
      "Iteration 2438, loss = 0.00525692\n",
      "Validation score: 0.766113\n",
      "Iteration 2439, loss = 0.00525533\n",
      "Validation score: 0.766189\n",
      "Iteration 2440, loss = 0.00525375\n",
      "Validation score: 0.766265\n",
      "Iteration 2441, loss = 0.00525217\n",
      "Validation score: 0.766340\n",
      "Iteration 2442, loss = 0.00525059\n",
      "Validation score: 0.766416\n",
      "Iteration 2443, loss = 0.00524901\n",
      "Validation score: 0.766491\n",
      "Iteration 2444, loss = 0.00524743\n",
      "Validation score: 0.766567\n",
      "Iteration 2445, loss = 0.00524585\n",
      "Validation score: 0.766643\n",
      "Iteration 2446, loss = 0.00524426\n",
      "Validation score: 0.766719\n",
      "Iteration 2447, loss = 0.00524266\n",
      "Validation score: 0.766794\n",
      "Iteration 2448, loss = 0.00524107\n",
      "Validation score: 0.766870\n",
      "Iteration 2449, loss = 0.00523949\n",
      "Validation score: 0.766944\n",
      "Iteration 2450, loss = 0.00523790\n",
      "Validation score: 0.767019\n",
      "Iteration 2451, loss = 0.00523631\n",
      "Validation score: 0.767094\n",
      "Iteration 2452, loss = 0.00523472\n",
      "Validation score: 0.767169\n",
      "Iteration 2453, loss = 0.00523313\n",
      "Validation score: 0.767243\n",
      "Iteration 2454, loss = 0.00523155\n",
      "Validation score: 0.767318\n",
      "Iteration 2455, loss = 0.00522997\n",
      "Validation score: 0.767394\n",
      "Iteration 2456, loss = 0.00522839\n",
      "Validation score: 0.767469\n",
      "Iteration 2457, loss = 0.00522682\n",
      "Validation score: 0.767543\n",
      "Iteration 2458, loss = 0.00522524\n",
      "Validation score: 0.767616\n",
      "Iteration 2459, loss = 0.00522367\n",
      "Validation score: 0.767689\n",
      "Iteration 2460, loss = 0.00522212\n",
      "Validation score: 0.767761\n",
      "Iteration 2461, loss = 0.00522058\n",
      "Validation score: 0.767833\n",
      "Iteration 2462, loss = 0.00521903\n",
      "Validation score: 0.767903\n",
      "Iteration 2463, loss = 0.00521748\n",
      "Validation score: 0.767973\n",
      "Iteration 2464, loss = 0.00521592\n",
      "Validation score: 0.768044\n",
      "Iteration 2465, loss = 0.00521436\n",
      "Validation score: 0.768114\n",
      "Iteration 2466, loss = 0.00521280\n",
      "Validation score: 0.768184\n",
      "Iteration 2467, loss = 0.00521124\n",
      "Validation score: 0.768255\n",
      "Iteration 2468, loss = 0.00520968\n",
      "Validation score: 0.768325\n",
      "Iteration 2469, loss = 0.00520813\n",
      "Validation score: 0.768396\n",
      "Iteration 2470, loss = 0.00520657\n",
      "Validation score: 0.768466\n",
      "Iteration 2471, loss = 0.00520502\n",
      "Validation score: 0.768537\n",
      "Iteration 2472, loss = 0.00520347\n",
      "Validation score: 0.768608\n",
      "Iteration 2473, loss = 0.00520191\n",
      "Validation score: 0.768678\n",
      "Iteration 2474, loss = 0.00520035\n",
      "Validation score: 0.768746\n",
      "Iteration 2475, loss = 0.00519879\n",
      "Validation score: 0.768814\n",
      "Iteration 2476, loss = 0.00519724\n",
      "Validation score: 0.768882\n",
      "Iteration 2477, loss = 0.00519570\n",
      "Validation score: 0.768949\n",
      "Iteration 2478, loss = 0.00519415\n",
      "Validation score: 0.769016\n",
      "Iteration 2479, loss = 0.00519260\n",
      "Validation score: 0.769083\n",
      "Iteration 2480, loss = 0.00519106\n",
      "Validation score: 0.769150\n",
      "Iteration 2481, loss = 0.00518951\n",
      "Validation score: 0.769216\n",
      "Iteration 2482, loss = 0.00518797\n",
      "Validation score: 0.769285\n",
      "Iteration 2483, loss = 0.00518643\n",
      "Validation score: 0.769354\n",
      "Iteration 2484, loss = 0.00518489\n",
      "Validation score: 0.769424\n",
      "Iteration 2485, loss = 0.00518335\n",
      "Validation score: 0.769494\n",
      "Iteration 2486, loss = 0.00518181\n",
      "Validation score: 0.769564\n",
      "Iteration 2487, loss = 0.00518027\n",
      "Validation score: 0.769633\n",
      "Iteration 2488, loss = 0.00517871\n",
      "Validation score: 0.769704\n",
      "Iteration 2489, loss = 0.00517715\n",
      "Validation score: 0.769774\n",
      "Iteration 2490, loss = 0.00517558\n",
      "Validation score: 0.769844\n",
      "Iteration 2491, loss = 0.00517401\n",
      "Validation score: 0.769913\n",
      "Iteration 2492, loss = 0.00517244\n",
      "Validation score: 0.769982\n",
      "Iteration 2493, loss = 0.00517087\n",
      "Validation score: 0.770051\n",
      "Iteration 2494, loss = 0.00516930\n",
      "Validation score: 0.770119\n",
      "Iteration 2495, loss = 0.00516774\n",
      "Validation score: 0.770187\n",
      "Iteration 2496, loss = 0.00516617\n",
      "Validation score: 0.770254\n",
      "Iteration 2497, loss = 0.00516459\n",
      "Validation score: 0.770320\n",
      "Iteration 2498, loss = 0.00516300\n",
      "Validation score: 0.770388\n",
      "Iteration 2499, loss = 0.00516140\n",
      "Validation score: 0.770454\n",
      "Iteration 2500, loss = 0.00515980\n",
      "Validation score: 0.770521\n",
      "Iteration 2501, loss = 0.00515819\n",
      "Validation score: 0.770589\n",
      "Iteration 2502, loss = 0.00515659\n",
      "Validation score: 0.770656\n",
      "Iteration 2503, loss = 0.00515500\n",
      "Validation score: 0.770722\n",
      "Iteration 2504, loss = 0.00515342\n",
      "Validation score: 0.770788\n",
      "Iteration 2505, loss = 0.00515183\n",
      "Validation score: 0.770854\n",
      "Iteration 2506, loss = 0.00515023\n",
      "Validation score: 0.770921\n",
      "Iteration 2507, loss = 0.00514865\n",
      "Validation score: 0.770987\n",
      "Iteration 2508, loss = 0.00514709\n",
      "Validation score: 0.771053\n",
      "Iteration 2509, loss = 0.00514554\n",
      "Validation score: 0.771116\n",
      "Iteration 2510, loss = 0.00514402\n",
      "Validation score: 0.771178\n",
      "Iteration 2511, loss = 0.00514250\n",
      "Validation score: 0.771238\n",
      "Iteration 2512, loss = 0.00514099\n",
      "Validation score: 0.771296\n",
      "Iteration 2513, loss = 0.00513950\n",
      "Validation score: 0.771354\n",
      "Iteration 2514, loss = 0.00513801\n",
      "Validation score: 0.771410\n",
      "Iteration 2515, loss = 0.00513653\n",
      "Validation score: 0.771467\n",
      "Iteration 2516, loss = 0.00513505\n",
      "Validation score: 0.771523\n",
      "Iteration 2517, loss = 0.00513357\n",
      "Validation score: 0.771577\n",
      "Iteration 2518, loss = 0.00513211\n",
      "Validation score: 0.771630\n",
      "Iteration 2519, loss = 0.00513064\n",
      "Validation score: 0.771682\n",
      "Iteration 2520, loss = 0.00512918\n",
      "Validation score: 0.771733\n",
      "Iteration 2521, loss = 0.00512772\n",
      "Validation score: 0.771782\n",
      "Iteration 2522, loss = 0.00512626\n",
      "Validation score: 0.771831\n",
      "Iteration 2523, loss = 0.00512481\n",
      "Validation score: 0.771879\n",
      "Iteration 2524, loss = 0.00512336\n",
      "Validation score: 0.771925\n",
      "Iteration 2525, loss = 0.00512191\n",
      "Validation score: 0.771970\n",
      "Iteration 2526, loss = 0.00512047\n",
      "Validation score: 0.772014\n",
      "Iteration 2527, loss = 0.00511904\n",
      "Validation score: 0.772056\n",
      "Iteration 2528, loss = 0.00511761\n",
      "Validation score: 0.772095\n",
      "Iteration 2529, loss = 0.00511619\n",
      "Validation score: 0.772132\n",
      "Iteration 2530, loss = 0.00511479\n",
      "Validation score: 0.772169\n",
      "Iteration 2531, loss = 0.00511339\n",
      "Validation score: 0.772205\n",
      "Iteration 2532, loss = 0.00511201\n",
      "Validation score: 0.772240\n",
      "Iteration 2533, loss = 0.00511063\n",
      "Validation score: 0.772274\n",
      "Iteration 2534, loss = 0.00510926\n",
      "Validation score: 0.772307\n",
      "Iteration 2535, loss = 0.00510789\n",
      "Validation score: 0.772339\n",
      "Iteration 2536, loss = 0.00510652\n",
      "Validation score: 0.772371\n",
      "Iteration 2537, loss = 0.00510514\n",
      "Validation score: 0.772402\n",
      "Iteration 2538, loss = 0.00510376\n",
      "Validation score: 0.772433\n",
      "Iteration 2539, loss = 0.00510238\n",
      "Validation score: 0.772464\n",
      "Iteration 2540, loss = 0.00510099\n",
      "Validation score: 0.772494\n",
      "Iteration 2541, loss = 0.00509961\n",
      "Validation score: 0.772523\n",
      "Iteration 2542, loss = 0.00509822\n",
      "Validation score: 0.772550\n",
      "Iteration 2543, loss = 0.00509683\n",
      "Validation score: 0.772576\n",
      "Iteration 2544, loss = 0.00509544\n",
      "Validation score: 0.772601\n",
      "Iteration 2545, loss = 0.00509405\n",
      "Validation score: 0.772624\n",
      "Iteration 2546, loss = 0.00509266\n",
      "Validation score: 0.772651\n",
      "Iteration 2547, loss = 0.00509127\n",
      "Validation score: 0.772683\n",
      "Iteration 2548, loss = 0.00508988\n",
      "Validation score: 0.772715\n",
      "Iteration 2549, loss = 0.00508849\n",
      "Validation score: 0.772748\n",
      "Iteration 2550, loss = 0.00508711\n",
      "Validation score: 0.772781\n",
      "Iteration 2551, loss = 0.00508573\n",
      "Validation score: 0.772815\n",
      "Iteration 2552, loss = 0.00508434\n",
      "Validation score: 0.772849\n",
      "Iteration 2553, loss = 0.00508296\n",
      "Validation score: 0.772884\n",
      "Iteration 2554, loss = 0.00508159\n",
      "Validation score: 0.772920\n",
      "Iteration 2555, loss = 0.00508022\n",
      "Validation score: 0.772958\n",
      "Iteration 2556, loss = 0.00507886\n",
      "Validation score: 0.772995\n",
      "Iteration 2557, loss = 0.00507750\n",
      "Validation score: 0.773033\n",
      "Iteration 2558, loss = 0.00507613\n",
      "Validation score: 0.773072\n",
      "Iteration 2559, loss = 0.00507478\n",
      "Validation score: 0.773111\n",
      "Iteration 2560, loss = 0.00507343\n",
      "Validation score: 0.773151\n",
      "Iteration 2561, loss = 0.00507209\n",
      "Validation score: 0.773191\n",
      "Iteration 2562, loss = 0.00507076\n",
      "Validation score: 0.773231\n",
      "Iteration 2563, loss = 0.00506943\n",
      "Validation score: 0.773270\n",
      "Iteration 2564, loss = 0.00506811\n",
      "Validation score: 0.773311\n",
      "Iteration 2565, loss = 0.00506680\n",
      "Validation score: 0.773351\n",
      "Iteration 2566, loss = 0.00506550\n",
      "Validation score: 0.773392\n",
      "Iteration 2567, loss = 0.00506421\n",
      "Validation score: 0.773434\n",
      "Iteration 2568, loss = 0.00506291\n",
      "Validation score: 0.773476\n",
      "Iteration 2569, loss = 0.00506162\n",
      "Validation score: 0.773518\n",
      "Iteration 2570, loss = 0.00506034\n",
      "Validation score: 0.773559\n",
      "Iteration 2571, loss = 0.00505905\n",
      "Validation score: 0.773600\n",
      "Iteration 2572, loss = 0.00505777\n",
      "Validation score: 0.773642\n",
      "Iteration 2573, loss = 0.00505649\n",
      "Validation score: 0.773683\n",
      "Iteration 2574, loss = 0.00505520\n",
      "Validation score: 0.773725\n",
      "Iteration 2575, loss = 0.00505392\n",
      "Validation score: 0.773767\n",
      "Iteration 2576, loss = 0.00505264\n",
      "Validation score: 0.773809\n",
      "Iteration 2577, loss = 0.00505136\n",
      "Validation score: 0.773850\n",
      "Iteration 2578, loss = 0.00505008\n",
      "Validation score: 0.773892\n",
      "Iteration 2579, loss = 0.00504880\n",
      "Validation score: 0.773936\n",
      "Iteration 2580, loss = 0.00504752\n",
      "Validation score: 0.773981\n",
      "Iteration 2581, loss = 0.00504624\n",
      "Validation score: 0.774025\n",
      "Iteration 2582, loss = 0.00504497\n",
      "Validation score: 0.774069\n",
      "Iteration 2583, loss = 0.00504370\n",
      "Validation score: 0.774113\n",
      "Iteration 2584, loss = 0.00504243\n",
      "Validation score: 0.774157\n",
      "Iteration 2585, loss = 0.00504116\n",
      "Validation score: 0.774202\n",
      "Iteration 2586, loss = 0.00503990\n",
      "Validation score: 0.774247\n",
      "Iteration 2587, loss = 0.00503864\n",
      "Validation score: 0.774292\n",
      "Iteration 2588, loss = 0.00503738\n",
      "Validation score: 0.774337\n",
      "Iteration 2589, loss = 0.00503612\n",
      "Validation score: 0.774384\n",
      "Iteration 2590, loss = 0.00503486\n",
      "Validation score: 0.774429\n",
      "Iteration 2591, loss = 0.00503361\n",
      "Validation score: 0.774473\n",
      "Iteration 2592, loss = 0.00503235\n",
      "Validation score: 0.774517\n",
      "Iteration 2593, loss = 0.00503110\n",
      "Validation score: 0.774559\n",
      "Iteration 2594, loss = 0.00502986\n",
      "Validation score: 0.774600\n",
      "Iteration 2595, loss = 0.00502861\n",
      "Validation score: 0.774641\n",
      "Iteration 2596, loss = 0.00502736\n",
      "Validation score: 0.774681\n",
      "Iteration 2597, loss = 0.00502611\n",
      "Validation score: 0.774722\n",
      "Iteration 2598, loss = 0.00502487\n",
      "Validation score: 0.774765\n",
      "Iteration 2599, loss = 0.00502363\n",
      "Validation score: 0.774807\n",
      "Iteration 2600, loss = 0.00502239\n",
      "Validation score: 0.774849\n",
      "Iteration 2601, loss = 0.00502115\n",
      "Validation score: 0.774889\n",
      "Iteration 2602, loss = 0.00501991\n",
      "Validation score: 0.774930\n",
      "Iteration 2603, loss = 0.00501867\n",
      "Validation score: 0.774972\n",
      "Iteration 2604, loss = 0.00501744\n",
      "Validation score: 0.775014\n",
      "Iteration 2605, loss = 0.00501621\n",
      "Validation score: 0.775056\n",
      "Iteration 2606, loss = 0.00501498\n",
      "Validation score: 0.775095\n",
      "Iteration 2607, loss = 0.00501374\n",
      "Validation score: 0.775133\n",
      "Iteration 2608, loss = 0.00501251\n",
      "Validation score: 0.775171\n",
      "Iteration 2609, loss = 0.00501128\n",
      "Validation score: 0.775209\n",
      "Iteration 2610, loss = 0.00501006\n",
      "Validation score: 0.775247\n",
      "Iteration 2611, loss = 0.00500883\n",
      "Validation score: 0.775286\n",
      "Iteration 2612, loss = 0.00500761\n",
      "Validation score: 0.775326\n",
      "Iteration 2613, loss = 0.00500638\n",
      "Validation score: 0.775368\n",
      "Iteration 2614, loss = 0.00500516\n",
      "Validation score: 0.775410\n",
      "Iteration 2615, loss = 0.00500394\n",
      "Validation score: 0.775450\n",
      "Iteration 2616, loss = 0.00500273\n",
      "Validation score: 0.775488\n",
      "Iteration 2617, loss = 0.00500151\n",
      "Validation score: 0.775525\n",
      "Iteration 2618, loss = 0.00500029\n",
      "Validation score: 0.775562\n",
      "Iteration 2619, loss = 0.00499907\n",
      "Validation score: 0.775601\n",
      "Iteration 2620, loss = 0.00499786\n",
      "Validation score: 0.775640\n",
      "Iteration 2621, loss = 0.00499664\n",
      "Validation score: 0.775679\n",
      "Iteration 2622, loss = 0.00499543\n",
      "Validation score: 0.775719\n",
      "Iteration 2623, loss = 0.00499423\n",
      "Validation score: 0.775759\n",
      "Iteration 2624, loss = 0.00499305\n",
      "Validation score: 0.775798\n",
      "Iteration 2625, loss = 0.00499185\n",
      "Validation score: 0.775835\n",
      "Iteration 2626, loss = 0.00499066\n",
      "Validation score: 0.775871\n",
      "Iteration 2627, loss = 0.00498947\n",
      "Validation score: 0.775906\n",
      "Iteration 2628, loss = 0.00498828\n",
      "Validation score: 0.775939\n",
      "Iteration 2629, loss = 0.00498708\n",
      "Validation score: 0.775971\n",
      "Iteration 2630, loss = 0.00498588\n",
      "Validation score: 0.776002\n",
      "Iteration 2631, loss = 0.00498469\n",
      "Validation score: 0.776035\n",
      "Iteration 2632, loss = 0.00498349\n",
      "Validation score: 0.776068\n",
      "Iteration 2633, loss = 0.00498231\n",
      "Validation score: 0.776104\n",
      "Iteration 2634, loss = 0.00498113\n",
      "Validation score: 0.776140\n",
      "Iteration 2635, loss = 0.00497994\n",
      "Validation score: 0.776175\n",
      "Iteration 2636, loss = 0.00497876\n",
      "Validation score: 0.776210\n",
      "Iteration 2637, loss = 0.00497758\n",
      "Validation score: 0.776244\n",
      "Iteration 2638, loss = 0.00497640\n",
      "Validation score: 0.776278\n",
      "Iteration 2639, loss = 0.00497522\n",
      "Validation score: 0.776310\n",
      "Iteration 2640, loss = 0.00497405\n",
      "Validation score: 0.776343\n",
      "Iteration 2641, loss = 0.00497287\n",
      "Validation score: 0.776377\n",
      "Iteration 2642, loss = 0.00497170\n",
      "Validation score: 0.776410\n",
      "Iteration 2643, loss = 0.00497053\n",
      "Validation score: 0.776442\n",
      "Iteration 2644, loss = 0.00496936\n",
      "Validation score: 0.776473\n",
      "Iteration 2645, loss = 0.00496819\n",
      "Validation score: 0.776502\n",
      "Iteration 2646, loss = 0.00496702\n",
      "Validation score: 0.776530\n",
      "Iteration 2647, loss = 0.00496585\n",
      "Validation score: 0.776560\n",
      "Iteration 2648, loss = 0.00496469\n",
      "Validation score: 0.776590\n",
      "Iteration 2649, loss = 0.00496352\n",
      "Validation score: 0.776621\n",
      "Iteration 2650, loss = 0.00496236\n",
      "Validation score: 0.776653\n",
      "Iteration 2651, loss = 0.00496119\n",
      "Validation score: 0.776684\n",
      "Iteration 2652, loss = 0.00496003\n",
      "Validation score: 0.776713\n",
      "Iteration 2653, loss = 0.00495888\n",
      "Validation score: 0.776740\n",
      "Iteration 2654, loss = 0.00495772\n",
      "Validation score: 0.776767\n",
      "Iteration 2655, loss = 0.00495657\n",
      "Validation score: 0.776795\n",
      "Iteration 2656, loss = 0.00495543\n",
      "Validation score: 0.776823\n",
      "Iteration 2657, loss = 0.00495429\n",
      "Validation score: 0.776851\n",
      "Iteration 2658, loss = 0.00495315\n",
      "Validation score: 0.776879\n",
      "Iteration 2659, loss = 0.00495202\n",
      "Validation score: 0.776908\n",
      "Iteration 2660, loss = 0.00495088\n",
      "Validation score: 0.776938\n",
      "Iteration 2661, loss = 0.00494974\n",
      "Validation score: 0.776966\n",
      "Iteration 2662, loss = 0.00494861\n",
      "Validation score: 0.776995\n",
      "Iteration 2663, loss = 0.00494748\n",
      "Validation score: 0.777022\n",
      "Iteration 2664, loss = 0.00494635\n",
      "Validation score: 0.777050\n",
      "Iteration 2665, loss = 0.00494522\n",
      "Validation score: 0.777076\n",
      "Iteration 2666, loss = 0.00494409\n",
      "Validation score: 0.777104\n",
      "Iteration 2667, loss = 0.00494296\n",
      "Validation score: 0.777132\n",
      "Iteration 2668, loss = 0.00494184\n",
      "Validation score: 0.777160\n",
      "Iteration 2669, loss = 0.00494071\n",
      "Validation score: 0.777186\n",
      "Iteration 2670, loss = 0.00493959\n",
      "Validation score: 0.777212\n",
      "Iteration 2671, loss = 0.00493847\n",
      "Validation score: 0.777238\n",
      "Iteration 2672, loss = 0.00493735\n",
      "Validation score: 0.777264\n",
      "Iteration 2673, loss = 0.00493623\n",
      "Validation score: 0.777291\n",
      "Iteration 2674, loss = 0.00493511\n",
      "Validation score: 0.777318\n",
      "Iteration 2675, loss = 0.00493399\n",
      "Validation score: 0.777344\n",
      "Iteration 2676, loss = 0.00493288\n",
      "Validation score: 0.777371\n",
      "Iteration 2677, loss = 0.00493177\n",
      "Validation score: 0.777400\n",
      "Iteration 2678, loss = 0.00493066\n",
      "Validation score: 0.777427\n",
      "Iteration 2679, loss = 0.00492955\n",
      "Validation score: 0.777453\n",
      "Iteration 2680, loss = 0.00492844\n",
      "Validation score: 0.777479\n",
      "Iteration 2681, loss = 0.00492734\n",
      "Validation score: 0.777505\n",
      "Iteration 2682, loss = 0.00492623\n",
      "Validation score: 0.777532\n",
      "Iteration 2683, loss = 0.00492513\n",
      "Validation score: 0.777560\n",
      "Iteration 2684, loss = 0.00492403\n",
      "Validation score: 0.777588\n",
      "Iteration 2685, loss = 0.00492293\n",
      "Validation score: 0.777615\n",
      "Iteration 2686, loss = 0.00492183\n",
      "Validation score: 0.777642\n",
      "Iteration 2687, loss = 0.00492073\n",
      "Validation score: 0.777669\n",
      "Iteration 2688, loss = 0.00491964\n",
      "Validation score: 0.777695\n",
      "Iteration 2689, loss = 0.00491854\n",
      "Validation score: 0.777723\n",
      "Iteration 2690, loss = 0.00491744\n",
      "Validation score: 0.777751\n",
      "Iteration 2691, loss = 0.00491635\n",
      "Validation score: 0.777779\n",
      "Iteration 2692, loss = 0.00491525\n",
      "Validation score: 0.777806\n",
      "Iteration 2693, loss = 0.00491415\n",
      "Validation score: 0.777833\n",
      "Iteration 2694, loss = 0.00491306\n",
      "Validation score: 0.777860\n",
      "Iteration 2695, loss = 0.00491197\n",
      "Validation score: 0.777888\n",
      "Iteration 2696, loss = 0.00491088\n",
      "Validation score: 0.777913\n",
      "Iteration 2697, loss = 0.00490979\n",
      "Validation score: 0.777939\n",
      "Iteration 2698, loss = 0.00490870\n",
      "Validation score: 0.777964\n",
      "Iteration 2699, loss = 0.00490761\n",
      "Validation score: 0.777991\n",
      "Iteration 2700, loss = 0.00490653\n",
      "Validation score: 0.778016\n",
      "Iteration 2701, loss = 0.00490545\n",
      "Validation score: 0.778042\n",
      "Iteration 2702, loss = 0.00490436\n",
      "Validation score: 0.778066\n",
      "Iteration 2703, loss = 0.00490327\n",
      "Validation score: 0.778092\n",
      "Iteration 2704, loss = 0.00490219\n",
      "Validation score: 0.778118\n",
      "Iteration 2705, loss = 0.00490111\n",
      "Validation score: 0.778143\n",
      "Iteration 2706, loss = 0.00490003\n",
      "Validation score: 0.778168\n",
      "Iteration 2707, loss = 0.00489894\n",
      "Validation score: 0.778192\n",
      "Iteration 2708, loss = 0.00489786\n",
      "Validation score: 0.778215\n",
      "Iteration 2709, loss = 0.00489679\n",
      "Validation score: 0.778240\n",
      "Iteration 2710, loss = 0.00489571\n",
      "Validation score: 0.778266\n",
      "Iteration 2711, loss = 0.00489463\n",
      "Validation score: 0.778291\n",
      "Iteration 2712, loss = 0.00489355\n",
      "Validation score: 0.778318\n",
      "Iteration 2713, loss = 0.00489248\n",
      "Validation score: 0.778344\n",
      "Iteration 2714, loss = 0.00489141\n",
      "Validation score: 0.778370\n",
      "Iteration 2715, loss = 0.00489034\n",
      "Validation score: 0.778395\n",
      "Iteration 2716, loss = 0.00488927\n",
      "Validation score: 0.778419\n",
      "Iteration 2717, loss = 0.00488821\n",
      "Validation score: 0.778444\n",
      "Iteration 2718, loss = 0.00488714\n",
      "Validation score: 0.778468\n",
      "Iteration 2719, loss = 0.00488607\n",
      "Validation score: 0.778492\n",
      "Iteration 2720, loss = 0.00488501\n",
      "Validation score: 0.778516\n",
      "Iteration 2721, loss = 0.00488395\n",
      "Validation score: 0.778541\n",
      "Iteration 2722, loss = 0.00488289\n",
      "Validation score: 0.778567\n",
      "Iteration 2723, loss = 0.00488183\n",
      "Validation score: 0.778591\n",
      "Iteration 2724, loss = 0.00488076\n",
      "Validation score: 0.778613\n",
      "Iteration 2725, loss = 0.00487971\n",
      "Validation score: 0.778635\n",
      "Iteration 2726, loss = 0.00487865\n",
      "Validation score: 0.778655\n",
      "Iteration 2727, loss = 0.00487759\n",
      "Validation score: 0.778676\n",
      "Iteration 2728, loss = 0.00487653\n",
      "Validation score: 0.778700\n",
      "Iteration 2729, loss = 0.00487548\n",
      "Validation score: 0.778724\n",
      "Iteration 2730, loss = 0.00487443\n",
      "Validation score: 0.778750\n",
      "Iteration 2731, loss = 0.00487338\n",
      "Validation score: 0.778776\n",
      "Iteration 2732, loss = 0.00487233\n",
      "Validation score: 0.778800\n",
      "Iteration 2733, loss = 0.00487127\n",
      "Validation score: 0.778824\n",
      "Iteration 2734, loss = 0.00487022\n",
      "Validation score: 0.778847\n",
      "Iteration 2735, loss = 0.00486917\n",
      "Validation score: 0.778868\n",
      "Iteration 2736, loss = 0.00486812\n",
      "Validation score: 0.778889\n",
      "Iteration 2737, loss = 0.00486707\n",
      "Validation score: 0.778912\n",
      "Iteration 2738, loss = 0.00486602\n",
      "Validation score: 0.778936\n",
      "Iteration 2739, loss = 0.00486496\n",
      "Validation score: 0.778960\n",
      "Iteration 2740, loss = 0.00486391\n",
      "Validation score: 0.778985\n",
      "Iteration 2741, loss = 0.00486285\n",
      "Validation score: 0.779010\n",
      "Iteration 2742, loss = 0.00486180\n",
      "Validation score: 0.779035\n",
      "Iteration 2743, loss = 0.00486074\n",
      "Validation score: 0.779059\n",
      "Iteration 2744, loss = 0.00485969\n",
      "Validation score: 0.779082\n",
      "Iteration 2745, loss = 0.00485863\n",
      "Validation score: 0.779103\n",
      "Iteration 2746, loss = 0.00485758\n",
      "Validation score: 0.779125\n",
      "Iteration 2747, loss = 0.00485653\n",
      "Validation score: 0.779147\n",
      "Iteration 2748, loss = 0.00485547\n",
      "Validation score: 0.779171\n",
      "Iteration 2749, loss = 0.00485442\n",
      "Validation score: 0.779196\n",
      "Iteration 2750, loss = 0.00485337\n",
      "Validation score: 0.779221\n",
      "Iteration 2751, loss = 0.00485232\n",
      "Validation score: 0.779242\n",
      "Iteration 2752, loss = 0.00485127\n",
      "Validation score: 0.779264\n",
      "Iteration 2753, loss = 0.00485022\n",
      "Validation score: 0.779286\n",
      "Iteration 2754, loss = 0.00484917\n",
      "Validation score: 0.779308\n",
      "Iteration 2755, loss = 0.00484812\n",
      "Validation score: 0.779329\n",
      "Iteration 2756, loss = 0.00484707\n",
      "Validation score: 0.779349\n",
      "Iteration 2757, loss = 0.00484603\n",
      "Validation score: 0.779370\n",
      "Iteration 2758, loss = 0.00484498\n",
      "Validation score: 0.779392\n",
      "Iteration 2759, loss = 0.00484393\n",
      "Validation score: 0.779414\n",
      "Iteration 2760, loss = 0.00484288\n",
      "Validation score: 0.779435\n",
      "Iteration 2761, loss = 0.00484184\n",
      "Validation score: 0.779455\n",
      "Iteration 2762, loss = 0.00484080\n",
      "Validation score: 0.779476\n",
      "Iteration 2763, loss = 0.00483975\n",
      "Validation score: 0.779496\n",
      "Iteration 2764, loss = 0.00483871\n",
      "Validation score: 0.779516\n",
      "Iteration 2765, loss = 0.00483768\n",
      "Validation score: 0.779536\n",
      "Iteration 2766, loss = 0.00483665\n",
      "Validation score: 0.779554\n",
      "Iteration 2767, loss = 0.00483562\n",
      "Validation score: 0.779572\n",
      "Iteration 2768, loss = 0.00483459\n",
      "Validation score: 0.779591\n",
      "Iteration 2769, loss = 0.00483355\n",
      "Validation score: 0.779612\n",
      "Iteration 2770, loss = 0.00483252\n",
      "Validation score: 0.779633\n",
      "Iteration 2771, loss = 0.00483149\n",
      "Validation score: 0.779656\n",
      "Iteration 2772, loss = 0.00483046\n",
      "Validation score: 0.779678\n",
      "Iteration 2773, loss = 0.00482943\n",
      "Validation score: 0.779700\n",
      "Iteration 2774, loss = 0.00482840\n",
      "Validation score: 0.779721\n",
      "Iteration 2775, loss = 0.00482737\n",
      "Validation score: 0.779744\n",
      "Iteration 2776, loss = 0.00482634\n",
      "Validation score: 0.779767\n",
      "Iteration 2777, loss = 0.00482531\n",
      "Validation score: 0.779788\n",
      "Iteration 2778, loss = 0.00482429\n",
      "Validation score: 0.779809\n",
      "Iteration 2779, loss = 0.00482327\n",
      "Validation score: 0.779830\n",
      "Iteration 2780, loss = 0.00482225\n",
      "Validation score: 0.779853\n",
      "Iteration 2781, loss = 0.00482123\n",
      "Validation score: 0.779875\n",
      "Iteration 2782, loss = 0.00482021\n",
      "Validation score: 0.779897\n",
      "Iteration 2783, loss = 0.00481919\n",
      "Validation score: 0.779919\n",
      "Iteration 2784, loss = 0.00481818\n",
      "Validation score: 0.779939\n",
      "Iteration 2785, loss = 0.00481716\n",
      "Validation score: 0.779960\n",
      "Iteration 2786, loss = 0.00481614\n",
      "Validation score: 0.779982\n",
      "Iteration 2787, loss = 0.00481513\n",
      "Validation score: 0.780005\n",
      "Iteration 2788, loss = 0.00481411\n",
      "Validation score: 0.780029\n",
      "Iteration 2789, loss = 0.00481310\n",
      "Validation score: 0.780054\n",
      "Iteration 2790, loss = 0.00481209\n",
      "Validation score: 0.780079\n",
      "Iteration 2791, loss = 0.00481108\n",
      "Validation score: 0.780103\n",
      "Iteration 2792, loss = 0.00481007\n",
      "Validation score: 0.780126\n",
      "Iteration 2793, loss = 0.00480906\n",
      "Validation score: 0.780149\n",
      "Iteration 2794, loss = 0.00480806\n",
      "Validation score: 0.780173\n",
      "Iteration 2795, loss = 0.00480706\n",
      "Validation score: 0.780198\n",
      "Iteration 2796, loss = 0.00480606\n",
      "Validation score: 0.780224\n",
      "Iteration 2797, loss = 0.00480506\n",
      "Validation score: 0.780251\n",
      "Iteration 2798, loss = 0.00480406\n",
      "Validation score: 0.780277\n",
      "Iteration 2799, loss = 0.00480306\n",
      "Validation score: 0.780304\n",
      "Iteration 2800, loss = 0.00480206\n",
      "Validation score: 0.780328\n",
      "Iteration 2801, loss = 0.00480107\n",
      "Validation score: 0.780352\n",
      "Iteration 2802, loss = 0.00480007\n",
      "Validation score: 0.780375\n",
      "Iteration 2803, loss = 0.00479907\n",
      "Validation score: 0.780398\n",
      "Iteration 2804, loss = 0.00479808\n",
      "Validation score: 0.780422\n",
      "Iteration 2805, loss = 0.00479708\n",
      "Validation score: 0.780447\n",
      "Iteration 2806, loss = 0.00479609\n",
      "Validation score: 0.780471\n",
      "Iteration 2807, loss = 0.00479509\n",
      "Validation score: 0.780495\n",
      "Iteration 2808, loss = 0.00479410\n",
      "Validation score: 0.780519\n",
      "Iteration 2809, loss = 0.00479311\n",
      "Validation score: 0.780543\n",
      "Iteration 2810, loss = 0.00479211\n",
      "Validation score: 0.780566\n",
      "Iteration 2811, loss = 0.00479112\n",
      "Validation score: 0.780588\n",
      "Iteration 2812, loss = 0.00479013\n",
      "Validation score: 0.780610\n",
      "Iteration 2813, loss = 0.00478914\n",
      "Validation score: 0.780633\n",
      "Iteration 2814, loss = 0.00478816\n",
      "Validation score: 0.780656\n",
      "Iteration 2815, loss = 0.00478717\n",
      "Validation score: 0.780679\n",
      "Iteration 2816, loss = 0.00478618\n",
      "Validation score: 0.780702\n",
      "Iteration 2817, loss = 0.00478518\n",
      "Validation score: 0.780726\n",
      "Iteration 2818, loss = 0.00478419\n",
      "Validation score: 0.780747\n",
      "Iteration 2819, loss = 0.00478321\n",
      "Validation score: 0.780767\n",
      "Iteration 2820, loss = 0.00478222\n",
      "Validation score: 0.780787\n",
      "Iteration 2821, loss = 0.00478123\n",
      "Validation score: 0.780806\n",
      "Iteration 2822, loss = 0.00478024\n",
      "Validation score: 0.780827\n",
      "Iteration 2823, loss = 0.00477925\n",
      "Validation score: 0.780848\n",
      "Iteration 2824, loss = 0.00477825\n",
      "Validation score: 0.780870\n",
      "Iteration 2825, loss = 0.00477726\n",
      "Validation score: 0.780893\n",
      "Iteration 2826, loss = 0.00477626\n",
      "Validation score: 0.780917\n",
      "Iteration 2827, loss = 0.00477527\n",
      "Validation score: 0.780941\n",
      "Iteration 2828, loss = 0.00477428\n",
      "Validation score: 0.780963\n",
      "Iteration 2829, loss = 0.00477329\n",
      "Validation score: 0.780984\n",
      "Iteration 2830, loss = 0.00477230\n",
      "Validation score: 0.781005\n",
      "Iteration 2831, loss = 0.00477131\n",
      "Validation score: 0.781028\n",
      "Iteration 2832, loss = 0.00477031\n",
      "Validation score: 0.781050\n",
      "Iteration 2833, loss = 0.00476932\n",
      "Validation score: 0.781071\n",
      "Iteration 2834, loss = 0.00476833\n",
      "Validation score: 0.781092\n",
      "Iteration 2835, loss = 0.00476733\n",
      "Validation score: 0.781114\n",
      "Iteration 2836, loss = 0.00476634\n",
      "Validation score: 0.781136\n",
      "Iteration 2837, loss = 0.00476535\n",
      "Validation score: 0.781159\n",
      "Iteration 2838, loss = 0.00476436\n",
      "Validation score: 0.781181\n",
      "Iteration 2839, loss = 0.00476337\n",
      "Validation score: 0.781202\n",
      "Iteration 2840, loss = 0.00476238\n",
      "Validation score: 0.781222\n",
      "Iteration 2841, loss = 0.00476139\n",
      "Validation score: 0.781242\n",
      "Iteration 2842, loss = 0.00476040\n",
      "Validation score: 0.781264\n",
      "Iteration 2843, loss = 0.00475941\n",
      "Validation score: 0.781286\n",
      "Iteration 2844, loss = 0.00475843\n",
      "Validation score: 0.781308\n",
      "Iteration 2845, loss = 0.00475744\n",
      "Validation score: 0.781329\n",
      "Iteration 2846, loss = 0.00475645\n",
      "Validation score: 0.781351\n",
      "Iteration 2847, loss = 0.00475547\n",
      "Validation score: 0.781374\n",
      "Iteration 2848, loss = 0.00475448\n",
      "Validation score: 0.781397\n",
      "Iteration 2849, loss = 0.00475349\n",
      "Validation score: 0.781420\n",
      "Iteration 2850, loss = 0.00475252\n",
      "Validation score: 0.781444\n",
      "Iteration 2851, loss = 0.00475155\n",
      "Validation score: 0.781466\n",
      "Iteration 2852, loss = 0.00475057\n",
      "Validation score: 0.781486\n",
      "Iteration 2853, loss = 0.00474960\n",
      "Validation score: 0.781506\n",
      "Iteration 2854, loss = 0.00474862\n",
      "Validation score: 0.781525\n",
      "Iteration 2855, loss = 0.00474764\n",
      "Validation score: 0.781541\n",
      "Iteration 2856, loss = 0.00474666\n",
      "Validation score: 0.781556\n",
      "Iteration 2857, loss = 0.00474567\n",
      "Validation score: 0.781570\n",
      "Iteration 2858, loss = 0.00474469\n",
      "Validation score: 0.781585\n",
      "Iteration 2859, loss = 0.00474370\n",
      "Validation score: 0.781600\n",
      "Iteration 2860, loss = 0.00474271\n",
      "Validation score: 0.781614\n",
      "Iteration 2861, loss = 0.00474172\n",
      "Validation score: 0.781628\n",
      "Iteration 2862, loss = 0.00474074\n",
      "Validation score: 0.781643\n",
      "Iteration 2863, loss = 0.00473976\n",
      "Validation score: 0.781659\n",
      "Iteration 2864, loss = 0.00473878\n",
      "Validation score: 0.781675\n",
      "Iteration 2865, loss = 0.00473779\n",
      "Validation score: 0.781691\n",
      "Iteration 2866, loss = 0.00473681\n",
      "Validation score: 0.781707\n",
      "Iteration 2867, loss = 0.00473583\n",
      "Validation score: 0.781725\n",
      "Iteration 2868, loss = 0.00473484\n",
      "Validation score: 0.781743\n",
      "Iteration 2869, loss = 0.00473386\n",
      "Validation score: 0.781762\n",
      "Iteration 2870, loss = 0.00473287\n",
      "Validation score: 0.781782\n",
      "Iteration 2871, loss = 0.00473189\n",
      "Validation score: 0.781801\n",
      "Iteration 2872, loss = 0.00473092\n",
      "Validation score: 0.781820\n",
      "Iteration 2873, loss = 0.00472995\n",
      "Validation score: 0.781841\n",
      "Iteration 2874, loss = 0.00472898\n",
      "Validation score: 0.781859\n",
      "Iteration 2875, loss = 0.00472800\n",
      "Validation score: 0.781873\n",
      "Iteration 2876, loss = 0.00472702\n",
      "Validation score: 0.781888\n",
      "Iteration 2877, loss = 0.00472604\n",
      "Validation score: 0.781906\n",
      "Iteration 2878, loss = 0.00472507\n",
      "Validation score: 0.781926\n",
      "Iteration 2879, loss = 0.00472410\n",
      "Validation score: 0.781945\n",
      "Iteration 2880, loss = 0.00472312\n",
      "Validation score: 0.781966\n",
      "Iteration 2881, loss = 0.00472214\n",
      "Validation score: 0.781987\n",
      "Iteration 2882, loss = 0.00472117\n",
      "Validation score: 0.782007\n",
      "Iteration 2883, loss = 0.00472020\n",
      "Validation score: 0.782026\n",
      "Iteration 2884, loss = 0.00471922\n",
      "Validation score: 0.782045\n",
      "Iteration 2885, loss = 0.00471825\n",
      "Validation score: 0.782064\n",
      "Iteration 2886, loss = 0.00471728\n",
      "Validation score: 0.782083\n",
      "Iteration 2887, loss = 0.00471630\n",
      "Validation score: 0.782100\n",
      "Iteration 2888, loss = 0.00471533\n",
      "Validation score: 0.782117\n",
      "Iteration 2889, loss = 0.00471437\n",
      "Validation score: 0.782134\n",
      "Iteration 2890, loss = 0.00471340\n",
      "Validation score: 0.782152\n",
      "Iteration 2891, loss = 0.00471243\n",
      "Validation score: 0.782172\n",
      "Iteration 2892, loss = 0.00471146\n",
      "Validation score: 0.782193\n",
      "Iteration 2893, loss = 0.00471049\n",
      "Validation score: 0.782213\n",
      "Iteration 2894, loss = 0.00470952\n",
      "Validation score: 0.782232\n",
      "Iteration 2895, loss = 0.00470854\n",
      "Validation score: 0.782251\n",
      "Iteration 2896, loss = 0.00470758\n",
      "Validation score: 0.782270\n",
      "Iteration 2897, loss = 0.00470661\n",
      "Validation score: 0.782288\n",
      "Iteration 2898, loss = 0.00470563\n",
      "Validation score: 0.782305\n",
      "Iteration 2899, loss = 0.00470466\n",
      "Validation score: 0.782323\n",
      "Iteration 2900, loss = 0.00470370\n",
      "Validation score: 0.782339\n",
      "Iteration 2901, loss = 0.00470273\n",
      "Validation score: 0.782357\n",
      "Iteration 2902, loss = 0.00470176\n",
      "Validation score: 0.782376\n",
      "Iteration 2903, loss = 0.00470078\n",
      "Validation score: 0.782395\n",
      "Iteration 2904, loss = 0.00469981\n",
      "Validation score: 0.782412\n",
      "Iteration 2905, loss = 0.00469885\n",
      "Validation score: 0.782431\n",
      "Iteration 2906, loss = 0.00469788\n",
      "Validation score: 0.782452\n",
      "Iteration 2907, loss = 0.00469691\n",
      "Validation score: 0.782470\n",
      "Iteration 2908, loss = 0.00469594\n",
      "Validation score: 0.782487\n",
      "Iteration 2909, loss = 0.00469497\n",
      "Validation score: 0.782504\n",
      "Iteration 2910, loss = 0.00469401\n",
      "Validation score: 0.782521\n",
      "Iteration 2911, loss = 0.00469304\n",
      "Validation score: 0.782537\n",
      "Iteration 2912, loss = 0.00469207\n",
      "Validation score: 0.782552\n",
      "Iteration 2913, loss = 0.00469110\n",
      "Validation score: 0.782569\n",
      "Iteration 2914, loss = 0.00469013\n",
      "Validation score: 0.782585\n",
      "Iteration 2915, loss = 0.00468917\n",
      "Validation score: 0.782603\n",
      "Iteration 2916, loss = 0.00468820\n",
      "Validation score: 0.782623\n",
      "Iteration 2917, loss = 0.00468723\n",
      "Validation score: 0.782646\n",
      "Iteration 2918, loss = 0.00468627\n",
      "Validation score: 0.782664\n",
      "Iteration 2919, loss = 0.00468530\n",
      "Validation score: 0.782678\n",
      "Iteration 2920, loss = 0.00468433\n",
      "Validation score: 0.782692\n",
      "Iteration 2921, loss = 0.00468338\n",
      "Validation score: 0.782707\n",
      "Iteration 2922, loss = 0.00468242\n",
      "Validation score: 0.782723\n",
      "Iteration 2923, loss = 0.00468146\n",
      "Validation score: 0.782739\n",
      "Iteration 2924, loss = 0.00468051\n",
      "Validation score: 0.782756\n",
      "Iteration 2925, loss = 0.00467956\n",
      "Validation score: 0.782775\n",
      "Iteration 2926, loss = 0.00467861\n",
      "Validation score: 0.782793\n",
      "Iteration 2927, loss = 0.00467766\n",
      "Validation score: 0.782807\n",
      "Iteration 2928, loss = 0.00467672\n",
      "Validation score: 0.782820\n",
      "Iteration 2929, loss = 0.00467577\n",
      "Validation score: 0.782835\n",
      "Iteration 2930, loss = 0.00467483\n",
      "Validation score: 0.782853\n",
      "Iteration 2931, loss = 0.00467389\n",
      "Validation score: 0.782871\n",
      "Iteration 2932, loss = 0.00467295\n",
      "Validation score: 0.782887\n",
      "Iteration 2933, loss = 0.00467201\n",
      "Validation score: 0.782904\n",
      "Iteration 2934, loss = 0.00467107\n",
      "Validation score: 0.782919\n",
      "Iteration 2935, loss = 0.00467013\n",
      "Validation score: 0.782935\n",
      "Iteration 2936, loss = 0.00466919\n",
      "Validation score: 0.782950\n",
      "Iteration 2937, loss = 0.00466825\n",
      "Validation score: 0.782964\n",
      "Iteration 2938, loss = 0.00466732\n",
      "Validation score: 0.782979\n",
      "Iteration 2939, loss = 0.00466638\n",
      "Validation score: 0.782995\n",
      "Iteration 2940, loss = 0.00466544\n",
      "Validation score: 0.783013\n",
      "Iteration 2941, loss = 0.00466450\n",
      "Validation score: 0.783030\n",
      "Iteration 2942, loss = 0.00466357\n",
      "Validation score: 0.783045\n",
      "Iteration 2943, loss = 0.00466263\n",
      "Validation score: 0.783060\n",
      "Iteration 2944, loss = 0.00466170\n",
      "Validation score: 0.783075\n",
      "Iteration 2945, loss = 0.00466076\n",
      "Validation score: 0.783088\n",
      "Iteration 2946, loss = 0.00465983\n",
      "Validation score: 0.783102\n",
      "Iteration 2947, loss = 0.00465889\n",
      "Validation score: 0.783117\n",
      "Iteration 2948, loss = 0.00465796\n",
      "Validation score: 0.783133\n",
      "Iteration 2949, loss = 0.00465703\n",
      "Validation score: 0.783150\n",
      "Iteration 2950, loss = 0.00465609\n",
      "Validation score: 0.783166\n",
      "Iteration 2951, loss = 0.00465516\n",
      "Validation score: 0.783180\n",
      "Iteration 2952, loss = 0.00465422\n",
      "Validation score: 0.783196\n",
      "Iteration 2953, loss = 0.00465329\n",
      "Validation score: 0.783212\n",
      "Iteration 2954, loss = 0.00465235\n",
      "Validation score: 0.783229\n",
      "Iteration 2955, loss = 0.00465143\n",
      "Validation score: 0.783245\n",
      "Iteration 2956, loss = 0.00465049\n",
      "Validation score: 0.783259\n",
      "Iteration 2957, loss = 0.00464956\n",
      "Validation score: 0.783273\n",
      "Iteration 2958, loss = 0.00464863\n",
      "Validation score: 0.783288\n",
      "Iteration 2959, loss = 0.00464770\n",
      "Validation score: 0.783304\n",
      "Iteration 2960, loss = 0.00464677\n",
      "Validation score: 0.783318\n",
      "Iteration 2961, loss = 0.00464585\n",
      "Validation score: 0.783333\n",
      "Iteration 2962, loss = 0.00464492\n",
      "Validation score: 0.783349\n",
      "Iteration 2963, loss = 0.00464399\n",
      "Validation score: 0.783364\n",
      "Iteration 2964, loss = 0.00464306\n",
      "Validation score: 0.783380\n",
      "Iteration 2965, loss = 0.00464213\n",
      "Validation score: 0.783398\n",
      "Iteration 2966, loss = 0.00464120\n",
      "Validation score: 0.783415\n",
      "Iteration 2967, loss = 0.00464027\n",
      "Validation score: 0.783432\n",
      "Iteration 2968, loss = 0.00463934\n",
      "Validation score: 0.783451\n",
      "Iteration 2969, loss = 0.00463842\n",
      "Validation score: 0.783466\n",
      "Iteration 2970, loss = 0.00463749\n",
      "Validation score: 0.783480\n",
      "Iteration 2971, loss = 0.00463656\n",
      "Validation score: 0.783496\n",
      "Iteration 2972, loss = 0.00463564\n",
      "Validation score: 0.783514\n",
      "Iteration 2973, loss = 0.00463471\n",
      "Validation score: 0.783534\n",
      "Iteration 2974, loss = 0.00463378\n",
      "Validation score: 0.783555\n",
      "Iteration 2975, loss = 0.00463286\n",
      "Validation score: 0.783576\n",
      "Iteration 2976, loss = 0.00463193\n",
      "Validation score: 0.783596\n",
      "Iteration 2977, loss = 0.00463101\n",
      "Validation score: 0.783615\n",
      "Iteration 2978, loss = 0.00463008\n",
      "Validation score: 0.783633\n",
      "Iteration 2979, loss = 0.00462915\n",
      "Validation score: 0.783653\n",
      "Iteration 2980, loss = 0.00462823\n",
      "Validation score: 0.783675\n",
      "Iteration 2981, loss = 0.00462731\n",
      "Validation score: 0.783697\n",
      "Iteration 2982, loss = 0.00462638\n",
      "Validation score: 0.783718\n",
      "Iteration 2983, loss = 0.00462546\n",
      "Validation score: 0.783737\n",
      "Iteration 2984, loss = 0.00462454\n",
      "Validation score: 0.783758\n",
      "Iteration 2985, loss = 0.00462361\n",
      "Validation score: 0.783779\n",
      "Iteration 2986, loss = 0.00462269\n",
      "Validation score: 0.783802\n",
      "Iteration 2987, loss = 0.00462176\n",
      "Validation score: 0.783826\n",
      "Iteration 2988, loss = 0.00462084\n",
      "Validation score: 0.783849\n",
      "Iteration 2989, loss = 0.00461992\n",
      "Validation score: 0.783870\n",
      "Iteration 2990, loss = 0.00461900\n",
      "Validation score: 0.783892\n",
      "Iteration 2991, loss = 0.00461807\n",
      "Validation score: 0.783914\n",
      "Iteration 2992, loss = 0.00461715\n",
      "Validation score: 0.783936\n",
      "Iteration 2993, loss = 0.00461623\n",
      "Validation score: 0.783955\n",
      "Iteration 2994, loss = 0.00461531\n",
      "Validation score: 0.783975\n",
      "Iteration 2995, loss = 0.00461440\n",
      "Validation score: 0.783994\n",
      "Iteration 2996, loss = 0.00461348\n",
      "Validation score: 0.784015\n",
      "Iteration 2997, loss = 0.00461256\n",
      "Validation score: 0.784036\n",
      "Iteration 2998, loss = 0.00461164\n",
      "Validation score: 0.784057\n",
      "Iteration 2999, loss = 0.00461072\n",
      "Validation score: 0.784077\n",
      "Iteration 3000, loss = 0.00460980\n",
      "Validation score: 0.784097\n",
      "Iteration 3001, loss = 0.00460889\n",
      "Validation score: 0.784115\n",
      "Iteration 3002, loss = 0.00460799\n",
      "Validation score: 0.784134\n",
      "Iteration 3003, loss = 0.00460707\n",
      "Validation score: 0.784152\n",
      "Iteration 3004, loss = 0.00460616\n",
      "Validation score: 0.784169\n",
      "Iteration 3005, loss = 0.00460523\n",
      "Validation score: 0.784185\n",
      "Iteration 3006, loss = 0.00460432\n",
      "Validation score: 0.784200\n",
      "Iteration 3007, loss = 0.00460341\n",
      "Validation score: 0.784214\n",
      "Iteration 3008, loss = 0.00460250\n",
      "Validation score: 0.784226\n",
      "Iteration 3009, loss = 0.00460158\n",
      "Validation score: 0.784241\n",
      "Iteration 3010, loss = 0.00460067\n",
      "Validation score: 0.784257\n",
      "Iteration 3011, loss = 0.00459976\n",
      "Validation score: 0.784274\n",
      "Iteration 3012, loss = 0.00459885\n",
      "Validation score: 0.784291\n",
      "Iteration 3013, loss = 0.00459794\n",
      "Validation score: 0.784308\n",
      "Iteration 3014, loss = 0.00459702\n",
      "Validation score: 0.784324\n",
      "Iteration 3015, loss = 0.00459611\n",
      "Validation score: 0.784341\n",
      "Iteration 3016, loss = 0.00459519\n",
      "Validation score: 0.784359\n",
      "Iteration 3017, loss = 0.00459428\n",
      "Validation score: 0.784376\n",
      "Iteration 3018, loss = 0.00459337\n",
      "Validation score: 0.784391\n",
      "Iteration 3019, loss = 0.00459245\n",
      "Validation score: 0.784407\n",
      "Iteration 3020, loss = 0.00459153\n",
      "Validation score: 0.784423\n",
      "Iteration 3021, loss = 0.00459062\n",
      "Validation score: 0.784441\n",
      "Iteration 3022, loss = 0.00458970\n",
      "Validation score: 0.784459\n",
      "Iteration 3023, loss = 0.00458878\n",
      "Validation score: 0.784477\n",
      "Iteration 3024, loss = 0.00458787\n",
      "Validation score: 0.784493\n",
      "Iteration 3025, loss = 0.00458695\n",
      "Validation score: 0.784509\n",
      "Iteration 3026, loss = 0.00458604\n",
      "Validation score: 0.784527\n",
      "Iteration 3027, loss = 0.00458513\n",
      "Validation score: 0.784544\n",
      "Iteration 3028, loss = 0.00458422\n",
      "Validation score: 0.784560\n",
      "Iteration 3029, loss = 0.00458330\n",
      "Validation score: 0.784575\n",
      "Iteration 3030, loss = 0.00458237\n",
      "Validation score: 0.784589\n",
      "Iteration 3031, loss = 0.00458144\n",
      "Validation score: 0.784603\n",
      "Iteration 3032, loss = 0.00458052\n",
      "Validation score: 0.784620\n",
      "Iteration 3033, loss = 0.00457961\n",
      "Validation score: 0.784636\n",
      "Iteration 3034, loss = 0.00457870\n",
      "Validation score: 0.784652\n",
      "Iteration 3035, loss = 0.00457777\n",
      "Validation score: 0.784666\n",
      "Iteration 3036, loss = 0.00457685\n",
      "Validation score: 0.784683\n",
      "Iteration 3037, loss = 0.00457593\n",
      "Validation score: 0.784700\n",
      "Iteration 3038, loss = 0.00457501\n",
      "Validation score: 0.784717\n",
      "Iteration 3039, loss = 0.00457410\n",
      "Validation score: 0.784731\n",
      "Iteration 3040, loss = 0.00457318\n",
      "Validation score: 0.784747\n",
      "Iteration 3041, loss = 0.00457226\n",
      "Validation score: 0.784763\n",
      "Iteration 3042, loss = 0.00457134\n",
      "Validation score: 0.784783\n",
      "Iteration 3043, loss = 0.00457042\n",
      "Validation score: 0.784802\n",
      "Iteration 3044, loss = 0.00456951\n",
      "Validation score: 0.784823\n",
      "Iteration 3045, loss = 0.00456860\n",
      "Validation score: 0.784841\n",
      "Iteration 3046, loss = 0.00456768\n",
      "Validation score: 0.784858\n",
      "Iteration 3047, loss = 0.00456676\n",
      "Validation score: 0.784874\n",
      "Iteration 3048, loss = 0.00456584\n",
      "Validation score: 0.784891\n",
      "Iteration 3049, loss = 0.00456493\n",
      "Validation score: 0.784908\n",
      "Iteration 3050, loss = 0.00456401\n",
      "Validation score: 0.784927\n",
      "Iteration 3051, loss = 0.00456310\n",
      "Validation score: 0.784947\n",
      "Iteration 3052, loss = 0.00456219\n",
      "Validation score: 0.784967\n",
      "Iteration 3053, loss = 0.00456128\n",
      "Validation score: 0.784987\n",
      "Iteration 3054, loss = 0.00456036\n",
      "Validation score: 0.785007\n",
      "Iteration 3055, loss = 0.00455946\n",
      "Validation score: 0.785024\n",
      "Iteration 3056, loss = 0.00455855\n",
      "Validation score: 0.785041\n",
      "Iteration 3057, loss = 0.00455763\n",
      "Validation score: 0.785061\n",
      "Iteration 3058, loss = 0.00455671\n",
      "Validation score: 0.785081\n",
      "Iteration 3059, loss = 0.00455581\n",
      "Validation score: 0.785098\n",
      "Iteration 3060, loss = 0.00455489\n",
      "Validation score: 0.785117\n",
      "Iteration 3061, loss = 0.00455398\n",
      "Validation score: 0.785136\n",
      "Iteration 3062, loss = 0.00455308\n",
      "Validation score: 0.785155\n",
      "Iteration 3063, loss = 0.00455216\n",
      "Validation score: 0.785174\n",
      "Iteration 3064, loss = 0.00455125\n",
      "Validation score: 0.785194\n",
      "Iteration 3065, loss = 0.00455035\n",
      "Validation score: 0.785215\n",
      "Iteration 3066, loss = 0.00454944\n",
      "Validation score: 0.785236\n",
      "Iteration 3067, loss = 0.00454854\n",
      "Validation score: 0.785254\n",
      "Iteration 3068, loss = 0.00454763\n",
      "Validation score: 0.785273\n",
      "Iteration 3069, loss = 0.00454673\n",
      "Validation score: 0.785289\n",
      "Iteration 3070, loss = 0.00454582\n",
      "Validation score: 0.785303\n",
      "Iteration 3071, loss = 0.00454492\n",
      "Validation score: 0.785317\n",
      "Iteration 3072, loss = 0.00454402\n",
      "Validation score: 0.785334\n",
      "Iteration 3073, loss = 0.00454312\n",
      "Validation score: 0.785349\n",
      "Iteration 3074, loss = 0.00454221\n",
      "Validation score: 0.785366\n",
      "Iteration 3075, loss = 0.00454132\n",
      "Validation score: 0.785383\n",
      "Iteration 3076, loss = 0.00454042\n",
      "Validation score: 0.785399\n",
      "Iteration 3077, loss = 0.00453952\n",
      "Validation score: 0.785413\n",
      "Iteration 3078, loss = 0.00453862\n",
      "Validation score: 0.785427\n",
      "Iteration 3079, loss = 0.00453772\n",
      "Validation score: 0.785443\n",
      "Iteration 3080, loss = 0.00453681\n",
      "Validation score: 0.785458\n",
      "Iteration 3081, loss = 0.00453592\n",
      "Validation score: 0.785473\n",
      "Iteration 3082, loss = 0.00453503\n",
      "Validation score: 0.785487\n",
      "Iteration 3083, loss = 0.00453413\n",
      "Validation score: 0.785501\n",
      "Iteration 3084, loss = 0.00453323\n",
      "Validation score: 0.785516\n",
      "Iteration 3085, loss = 0.00453234\n",
      "Validation score: 0.785531\n",
      "Iteration 3086, loss = 0.00453144\n",
      "Validation score: 0.785547\n",
      "Iteration 3087, loss = 0.00453055\n",
      "Validation score: 0.785562\n",
      "Iteration 3088, loss = 0.00452965\n",
      "Validation score: 0.785577\n",
      "Iteration 3089, loss = 0.00452876\n",
      "Validation score: 0.785589\n",
      "Iteration 3090, loss = 0.00452787\n",
      "Validation score: 0.785602\n",
      "Iteration 3091, loss = 0.00452698\n",
      "Validation score: 0.785615\n",
      "Iteration 3092, loss = 0.00452609\n",
      "Validation score: 0.785630\n",
      "Iteration 3093, loss = 0.00452520\n",
      "Validation score: 0.785644\n",
      "Iteration 3094, loss = 0.00452431\n",
      "Validation score: 0.785659\n",
      "Iteration 3095, loss = 0.00452342\n",
      "Validation score: 0.785675\n",
      "Iteration 3096, loss = 0.00452253\n",
      "Validation score: 0.785691\n",
      "Iteration 3097, loss = 0.00452164\n",
      "Validation score: 0.785708\n",
      "Iteration 3098, loss = 0.00452074\n",
      "Validation score: 0.785724\n",
      "Iteration 3099, loss = 0.00451986\n",
      "Validation score: 0.785743\n",
      "Iteration 3100, loss = 0.00451898\n",
      "Validation score: 0.785760\n",
      "Iteration 3101, loss = 0.00451810\n",
      "Validation score: 0.785776\n",
      "Iteration 3102, loss = 0.00451721\n",
      "Validation score: 0.785791\n",
      "Iteration 3103, loss = 0.00451633\n",
      "Validation score: 0.785805\n",
      "Iteration 3104, loss = 0.00451545\n",
      "Validation score: 0.785819\n",
      "Iteration 3105, loss = 0.00451457\n",
      "Validation score: 0.785836\n",
      "Iteration 3106, loss = 0.00451369\n",
      "Validation score: 0.785853\n",
      "Iteration 3107, loss = 0.00451281\n",
      "Validation score: 0.785873\n",
      "Iteration 3108, loss = 0.00451193\n",
      "Validation score: 0.785893\n",
      "Iteration 3109, loss = 0.00451105\n",
      "Validation score: 0.785912\n",
      "Iteration 3110, loss = 0.00451018\n",
      "Validation score: 0.785928\n",
      "Iteration 3111, loss = 0.00450930\n",
      "Validation score: 0.785945\n",
      "Iteration 3112, loss = 0.00450843\n",
      "Validation score: 0.785965\n",
      "Iteration 3113, loss = 0.00450756\n",
      "Validation score: 0.785982\n",
      "Iteration 3114, loss = 0.00450669\n",
      "Validation score: 0.786002\n",
      "Iteration 3115, loss = 0.00450582\n",
      "Validation score: 0.786021\n",
      "Iteration 3116, loss = 0.00450495\n",
      "Validation score: 0.786040\n",
      "Iteration 3117, loss = 0.00450408\n",
      "Validation score: 0.786058\n",
      "Iteration 3118, loss = 0.00450322\n",
      "Validation score: 0.786072\n",
      "Iteration 3119, loss = 0.00450235\n",
      "Validation score: 0.786086\n",
      "Iteration 3120, loss = 0.00450148\n",
      "Validation score: 0.786096\n",
      "Iteration 3121, loss = 0.00450062\n",
      "Validation score: 0.786106\n",
      "Iteration 3122, loss = 0.00449975\n",
      "Validation score: 0.786116\n",
      "Iteration 3123, loss = 0.00449889\n",
      "Validation score: 0.786130\n",
      "Iteration 3124, loss = 0.00449802\n",
      "Validation score: 0.786142\n",
      "Iteration 3125, loss = 0.00449715\n",
      "Validation score: 0.786155\n",
      "Iteration 3126, loss = 0.00449628\n",
      "Validation score: 0.786169\n",
      "Iteration 3127, loss = 0.00449542\n",
      "Validation score: 0.786184\n",
      "Iteration 3128, loss = 0.00449454\n",
      "Validation score: 0.786197\n",
      "Iteration 3129, loss = 0.00449367\n",
      "Validation score: 0.786212\n",
      "Iteration 3130, loss = 0.00449280\n",
      "Validation score: 0.786227\n",
      "Iteration 3131, loss = 0.00449193\n",
      "Validation score: 0.786241\n",
      "Iteration 3132, loss = 0.00449106\n",
      "Validation score: 0.786256\n",
      "Iteration 3133, loss = 0.00449020\n",
      "Validation score: 0.786269\n",
      "Iteration 3134, loss = 0.00448934\n",
      "Validation score: 0.786280\n",
      "Iteration 3135, loss = 0.00448848\n",
      "Validation score: 0.786290\n",
      "Iteration 3136, loss = 0.00448762\n",
      "Validation score: 0.786299\n",
      "Iteration 3137, loss = 0.00448676\n",
      "Validation score: 0.786308\n",
      "Iteration 3138, loss = 0.00448590\n",
      "Validation score: 0.786318\n",
      "Iteration 3139, loss = 0.00448504\n",
      "Validation score: 0.786328\n",
      "Iteration 3140, loss = 0.00448419\n",
      "Validation score: 0.786340\n",
      "Iteration 3141, loss = 0.00448334\n",
      "Validation score: 0.786350\n",
      "Iteration 3142, loss = 0.00448249\n",
      "Validation score: 0.786357\n",
      "Iteration 3143, loss = 0.00448163\n",
      "Validation score: 0.786360\n",
      "Iteration 3144, loss = 0.00448077\n",
      "Validation score: 0.786363\n",
      "Iteration 3145, loss = 0.00447991\n",
      "Validation score: 0.786366\n",
      "Iteration 3146, loss = 0.00447905\n",
      "Validation score: 0.786372\n",
      "Iteration 3147, loss = 0.00447820\n",
      "Validation score: 0.786377\n",
      "Iteration 3148, loss = 0.00447734\n",
      "Validation score: 0.786383\n",
      "Iteration 3149, loss = 0.00447648\n",
      "Validation score: 0.786391\n",
      "Iteration 3150, loss = 0.00447564\n",
      "Validation score: 0.786400\n",
      "Iteration 3151, loss = 0.00447478\n",
      "Validation score: 0.786410\n",
      "Iteration 3152, loss = 0.00447393\n",
      "Validation score: 0.786418\n",
      "Iteration 3153, loss = 0.00447308\n",
      "Validation score: 0.786427\n",
      "Iteration 3154, loss = 0.00447223\n",
      "Validation score: 0.786439\n",
      "Iteration 3155, loss = 0.00447137\n",
      "Validation score: 0.786451\n",
      "Iteration 3156, loss = 0.00447053\n",
      "Validation score: 0.786463\n",
      "Iteration 3157, loss = 0.00446968\n",
      "Validation score: 0.786471\n",
      "Iteration 3158, loss = 0.00446883\n",
      "Validation score: 0.786479\n",
      "Iteration 3159, loss = 0.00446798\n",
      "Validation score: 0.786484\n",
      "Iteration 3160, loss = 0.00446716\n",
      "Validation score: 0.786489\n",
      "Iteration 3161, loss = 0.00446630\n",
      "Validation score: 0.786496\n",
      "Iteration 3162, loss = 0.00446544\n",
      "Validation score: 0.786503\n",
      "Iteration 3163, loss = 0.00446461\n",
      "Validation score: 0.786512\n",
      "Iteration 3164, loss = 0.00446378\n",
      "Validation score: 0.786521\n",
      "Iteration 3165, loss = 0.00446294\n",
      "Validation score: 0.786527\n",
      "Iteration 3166, loss = 0.00446211\n",
      "Validation score: 0.786536\n",
      "Iteration 3167, loss = 0.00446128\n",
      "Validation score: 0.786544\n",
      "Iteration 3168, loss = 0.00446045\n",
      "Validation score: 0.786553\n",
      "Iteration 3169, loss = 0.00445961\n",
      "Validation score: 0.786562\n",
      "Iteration 3170, loss = 0.00445880\n",
      "Validation score: 0.786571\n",
      "Iteration 3171, loss = 0.00445798\n",
      "Validation score: 0.786582\n",
      "Iteration 3172, loss = 0.00445714\n",
      "Validation score: 0.786593\n",
      "Iteration 3173, loss = 0.00445632\n",
      "Validation score: 0.786600\n",
      "Iteration 3174, loss = 0.00445550\n",
      "Validation score: 0.786607\n",
      "Iteration 3175, loss = 0.00445469\n",
      "Validation score: 0.786617\n",
      "Iteration 3176, loss = 0.00445386\n",
      "Validation score: 0.786629\n",
      "Iteration 3177, loss = 0.00445303\n",
      "Validation score: 0.786644\n",
      "Iteration 3178, loss = 0.00445221\n",
      "Validation score: 0.786659\n",
      "Iteration 3179, loss = 0.00445141\n",
      "Validation score: 0.786673\n",
      "Iteration 3180, loss = 0.00445059\n",
      "Validation score: 0.786687\n",
      "Iteration 3181, loss = 0.00444975\n",
      "Validation score: 0.786699\n",
      "Iteration 3182, loss = 0.00444893\n",
      "Validation score: 0.786710\n",
      "Iteration 3183, loss = 0.00444811\n",
      "Validation score: 0.786719\n",
      "Iteration 3184, loss = 0.00444730\n",
      "Validation score: 0.786730\n",
      "Iteration 3185, loss = 0.00444649\n",
      "Validation score: 0.786738\n",
      "Iteration 3186, loss = 0.00444567\n",
      "Validation score: 0.786747\n",
      "Iteration 3187, loss = 0.00444485\n",
      "Validation score: 0.786760\n",
      "Iteration 3188, loss = 0.00444405\n",
      "Validation score: 0.786773\n",
      "Iteration 3189, loss = 0.00444323\n",
      "Validation score: 0.786789\n",
      "Iteration 3190, loss = 0.00444241\n",
      "Validation score: 0.786805\n",
      "Iteration 3191, loss = 0.00444160\n",
      "Validation score: 0.786820\n",
      "Iteration 3192, loss = 0.00444079\n",
      "Validation score: 0.786833\n",
      "Iteration 3193, loss = 0.00443997\n",
      "Validation score: 0.786847\n",
      "Iteration 3194, loss = 0.00443915\n",
      "Validation score: 0.786860\n",
      "Iteration 3195, loss = 0.00443834\n",
      "Validation score: 0.786873\n",
      "Iteration 3196, loss = 0.00443753\n",
      "Validation score: 0.786888\n",
      "Iteration 3197, loss = 0.00443671\n",
      "Validation score: 0.786901\n",
      "Iteration 3198, loss = 0.00443590\n",
      "Validation score: 0.786914\n",
      "Iteration 3199, loss = 0.00443509\n",
      "Validation score: 0.786927\n",
      "Iteration 3200, loss = 0.00443428\n",
      "Validation score: 0.786943\n",
      "Iteration 3201, loss = 0.00443347\n",
      "Validation score: 0.786959\n",
      "Iteration 3202, loss = 0.00443266\n",
      "Validation score: 0.786974\n",
      "Iteration 3203, loss = 0.00443185\n",
      "Validation score: 0.786988\n",
      "Iteration 3204, loss = 0.00443104\n",
      "Validation score: 0.786999\n",
      "Iteration 3205, loss = 0.00443023\n",
      "Validation score: 0.787011\n",
      "Iteration 3206, loss = 0.00442942\n",
      "Validation score: 0.787024\n",
      "Iteration 3207, loss = 0.00442861\n",
      "Validation score: 0.787037\n",
      "Iteration 3208, loss = 0.00442781\n",
      "Validation score: 0.787052\n",
      "Iteration 3209, loss = 0.00442700\n",
      "Validation score: 0.787065\n",
      "Iteration 3210, loss = 0.00442619\n",
      "Validation score: 0.787077\n",
      "Iteration 3211, loss = 0.00442538\n",
      "Validation score: 0.787088\n",
      "Iteration 3212, loss = 0.00442458\n",
      "Validation score: 0.787099\n",
      "Iteration 3213, loss = 0.00442378\n",
      "Validation score: 0.787113\n",
      "Iteration 3214, loss = 0.00442297\n",
      "Validation score: 0.787128\n",
      "Iteration 3215, loss = 0.00442216\n",
      "Validation score: 0.787141\n",
      "Iteration 3216, loss = 0.00442137\n",
      "Validation score: 0.787157\n",
      "Iteration 3217, loss = 0.00442056\n",
      "Validation score: 0.787171\n",
      "Iteration 3218, loss = 0.00441975\n",
      "Validation score: 0.787186\n",
      "Iteration 3219, loss = 0.00441895\n",
      "Validation score: 0.787201\n",
      "Iteration 3220, loss = 0.00441815\n",
      "Validation score: 0.787210\n",
      "Iteration 3221, loss = 0.00441735\n",
      "Validation score: 0.787219\n",
      "Iteration 3222, loss = 0.00441655\n",
      "Validation score: 0.787228\n",
      "Iteration 3223, loss = 0.00441575\n",
      "Validation score: 0.787238\n",
      "Iteration 3224, loss = 0.00441495\n",
      "Validation score: 0.787255\n",
      "Iteration 3225, loss = 0.00441414\n",
      "Validation score: 0.787271\n",
      "Iteration 3226, loss = 0.00441334\n",
      "Validation score: 0.787282\n",
      "Iteration 3227, loss = 0.00441254\n",
      "Validation score: 0.787292\n",
      "Iteration 3228, loss = 0.00441173\n",
      "Validation score: 0.787301\n",
      "Iteration 3229, loss = 0.00441093\n",
      "Validation score: 0.787312\n",
      "Iteration 3230, loss = 0.00441013\n",
      "Validation score: 0.787326\n",
      "Iteration 3231, loss = 0.00440933\n",
      "Validation score: 0.787343\n",
      "Iteration 3232, loss = 0.00440853\n",
      "Validation score: 0.787361\n",
      "Iteration 3233, loss = 0.00440773\n",
      "Validation score: 0.787375\n",
      "Iteration 3234, loss = 0.00440692\n",
      "Validation score: 0.787386\n",
      "Iteration 3235, loss = 0.00440612\n",
      "Validation score: 0.787397\n",
      "Iteration 3236, loss = 0.00440531\n",
      "Validation score: 0.787408\n",
      "Iteration 3237, loss = 0.00440453\n",
      "Validation score: 0.787419\n",
      "Iteration 3238, loss = 0.00440373\n",
      "Validation score: 0.787429\n",
      "Iteration 3239, loss = 0.00440291\n",
      "Validation score: 0.787442\n",
      "Iteration 3240, loss = 0.00440211\n",
      "Validation score: 0.787455\n",
      "Iteration 3241, loss = 0.00440132\n",
      "Validation score: 0.787468\n",
      "Iteration 3242, loss = 0.00440052\n",
      "Validation score: 0.787477\n",
      "Iteration 3243, loss = 0.00439973\n",
      "Validation score: 0.787485\n",
      "Iteration 3244, loss = 0.00439893\n",
      "Validation score: 0.787496\n",
      "Iteration 3245, loss = 0.00439813\n",
      "Validation score: 0.787506\n",
      "Iteration 3246, loss = 0.00439733\n",
      "Validation score: 0.787516\n",
      "Iteration 3247, loss = 0.00439655\n",
      "Validation score: 0.787527\n",
      "Iteration 3248, loss = 0.00439575\n",
      "Validation score: 0.787538\n",
      "Iteration 3249, loss = 0.00439495\n",
      "Validation score: 0.787550\n",
      "Iteration 3250, loss = 0.00439416\n",
      "Validation score: 0.787565\n",
      "Iteration 3251, loss = 0.00439336\n",
      "Validation score: 0.787579\n",
      "Iteration 3252, loss = 0.00439257\n",
      "Validation score: 0.787593\n",
      "Iteration 3253, loss = 0.00439178\n",
      "Validation score: 0.787602\n",
      "Iteration 3254, loss = 0.00439098\n",
      "Validation score: 0.787610\n",
      "Iteration 3255, loss = 0.00439019\n",
      "Validation score: 0.787621\n",
      "Iteration 3256, loss = 0.00438939\n",
      "Validation score: 0.787632\n",
      "Iteration 3257, loss = 0.00438861\n",
      "Validation score: 0.787642\n",
      "Iteration 3258, loss = 0.00438781\n",
      "Validation score: 0.787654\n",
      "Iteration 3259, loss = 0.00438702\n",
      "Validation score: 0.787662\n",
      "Iteration 3260, loss = 0.00438623\n",
      "Validation score: 0.787672\n",
      "Iteration 3261, loss = 0.00438544\n",
      "Validation score: 0.787684\n",
      "Iteration 3262, loss = 0.00438465\n",
      "Validation score: 0.787694\n",
      "Iteration 3263, loss = 0.00438385\n",
      "Validation score: 0.787705\n",
      "Iteration 3264, loss = 0.00438305\n",
      "Validation score: 0.787715\n",
      "Iteration 3265, loss = 0.00438225\n",
      "Validation score: 0.787728\n",
      "Iteration 3266, loss = 0.00438145\n",
      "Validation score: 0.787743\n",
      "Iteration 3267, loss = 0.00438065\n",
      "Validation score: 0.787755\n",
      "Iteration 3268, loss = 0.00437986\n",
      "Validation score: 0.787766\n",
      "Iteration 3269, loss = 0.00437906\n",
      "Validation score: 0.787775\n",
      "Iteration 3270, loss = 0.00437825\n",
      "Validation score: 0.787785\n",
      "Iteration 3271, loss = 0.00437746\n",
      "Validation score: 0.787800\n",
      "Iteration 3272, loss = 0.00437666\n",
      "Validation score: 0.787815\n",
      "Iteration 3273, loss = 0.00437586\n",
      "Validation score: 0.787832\n",
      "Iteration 3274, loss = 0.00437506\n",
      "Validation score: 0.787844\n",
      "Iteration 3275, loss = 0.00437425\n",
      "Validation score: 0.787851\n",
      "Iteration 3276, loss = 0.00437345\n",
      "Validation score: 0.787860\n",
      "Iteration 3277, loss = 0.00437265\n",
      "Validation score: 0.787872\n",
      "Iteration 3278, loss = 0.00437185\n",
      "Validation score: 0.787886\n",
      "Iteration 3279, loss = 0.00437105\n",
      "Validation score: 0.787902\n",
      "Iteration 3280, loss = 0.00437026\n",
      "Validation score: 0.787915\n",
      "Iteration 3281, loss = 0.00436947\n",
      "Validation score: 0.787927\n",
      "Iteration 3282, loss = 0.00436867\n",
      "Validation score: 0.787936\n",
      "Iteration 3283, loss = 0.00436787\n",
      "Validation score: 0.787947\n",
      "Iteration 3284, loss = 0.00436707\n",
      "Validation score: 0.787959\n",
      "Iteration 3285, loss = 0.00436628\n",
      "Validation score: 0.787972\n",
      "Iteration 3286, loss = 0.00436548\n",
      "Validation score: 0.787986\n",
      "Iteration 3287, loss = 0.00436468\n",
      "Validation score: 0.787998\n",
      "Iteration 3288, loss = 0.00436388\n",
      "Validation score: 0.788008\n",
      "Iteration 3289, loss = 0.00436309\n",
      "Validation score: 0.788017\n",
      "Iteration 3290, loss = 0.00436231\n",
      "Validation score: 0.788028\n",
      "Iteration 3291, loss = 0.00436151\n",
      "Validation score: 0.788043\n",
      "Iteration 3292, loss = 0.00436070\n",
      "Validation score: 0.788059\n",
      "Iteration 3293, loss = 0.00435991\n",
      "Validation score: 0.788074\n",
      "Iteration 3294, loss = 0.00435912\n",
      "Validation score: 0.788088\n",
      "Iteration 3295, loss = 0.00435833\n",
      "Validation score: 0.788099\n",
      "Iteration 3296, loss = 0.00435753\n",
      "Validation score: 0.788109\n",
      "Iteration 3297, loss = 0.00435674\n",
      "Validation score: 0.788121\n",
      "Iteration 3298, loss = 0.00435594\n",
      "Validation score: 0.788137\n",
      "Iteration 3299, loss = 0.00435514\n",
      "Validation score: 0.788154\n",
      "Iteration 3300, loss = 0.00435436\n",
      "Validation score: 0.788168\n",
      "Iteration 3301, loss = 0.00435356\n",
      "Validation score: 0.788178\n",
      "Iteration 3302, loss = 0.00435276\n",
      "Validation score: 0.788189\n",
      "Iteration 3303, loss = 0.00435197\n",
      "Validation score: 0.788200\n",
      "Iteration 3304, loss = 0.00435118\n",
      "Validation score: 0.788212\n",
      "Iteration 3305, loss = 0.00435039\n",
      "Validation score: 0.788224\n",
      "Iteration 3306, loss = 0.00434959\n",
      "Validation score: 0.788240\n",
      "Iteration 3307, loss = 0.00434880\n",
      "Validation score: 0.788257\n",
      "Iteration 3308, loss = 0.00434800\n",
      "Validation score: 0.788270\n",
      "Iteration 3309, loss = 0.00434721\n",
      "Validation score: 0.788277\n",
      "Iteration 3310, loss = 0.00434642\n",
      "Validation score: 0.788284\n",
      "Iteration 3311, loss = 0.00434563\n",
      "Validation score: 0.788294\n",
      "Iteration 3312, loss = 0.00434485\n",
      "Validation score: 0.788307\n",
      "Iteration 3313, loss = 0.00434406\n",
      "Validation score: 0.788321\n",
      "Iteration 3314, loss = 0.00434326\n",
      "Validation score: 0.788337\n",
      "Iteration 3315, loss = 0.00434247\n",
      "Validation score: 0.788352\n",
      "Iteration 3316, loss = 0.00434169\n",
      "Validation score: 0.788366\n",
      "Iteration 3317, loss = 0.00434090\n",
      "Validation score: 0.788378\n",
      "Iteration 3318, loss = 0.00434011\n",
      "Validation score: 0.788388\n",
      "Iteration 3319, loss = 0.00433932\n",
      "Validation score: 0.788398\n",
      "Iteration 3320, loss = 0.00433853\n",
      "Validation score: 0.788408\n",
      "Iteration 3321, loss = 0.00433774\n",
      "Validation score: 0.788417\n",
      "Iteration 3322, loss = 0.00433695\n",
      "Validation score: 0.788427\n",
      "Iteration 3323, loss = 0.00433617\n",
      "Validation score: 0.788437\n",
      "Iteration 3324, loss = 0.00433538\n",
      "Validation score: 0.788446\n",
      "Iteration 3325, loss = 0.00433460\n",
      "Validation score: 0.788457\n",
      "Iteration 3326, loss = 0.00433381\n",
      "Validation score: 0.788469\n",
      "Iteration 3327, loss = 0.00433303\n",
      "Validation score: 0.788483\n",
      "Iteration 3328, loss = 0.00433224\n",
      "Validation score: 0.788497\n",
      "Iteration 3329, loss = 0.00433147\n",
      "Validation score: 0.788507\n",
      "Iteration 3330, loss = 0.00433068\n",
      "Validation score: 0.788515\n",
      "Iteration 3331, loss = 0.00432990\n",
      "Validation score: 0.788523\n",
      "Iteration 3332, loss = 0.00432911\n",
      "Validation score: 0.788532\n",
      "Iteration 3333, loss = 0.00432833\n",
      "Validation score: 0.788542\n",
      "Iteration 3334, loss = 0.00432755\n",
      "Validation score: 0.788552\n",
      "Iteration 3335, loss = 0.00432676\n",
      "Validation score: 0.788562\n",
      "Iteration 3336, loss = 0.00432598\n",
      "Validation score: 0.788571\n",
      "Iteration 3337, loss = 0.00432520\n",
      "Validation score: 0.788580\n",
      "Iteration 3338, loss = 0.00432442\n",
      "Validation score: 0.788592\n",
      "Iteration 3339, loss = 0.00432364\n",
      "Validation score: 0.788601\n",
      "Iteration 3340, loss = 0.00432286\n",
      "Validation score: 0.788611\n",
      "Iteration 3341, loss = 0.00432209\n",
      "Validation score: 0.788619\n",
      "Iteration 3342, loss = 0.00432131\n",
      "Validation score: 0.788631\n",
      "Iteration 3343, loss = 0.00432053\n",
      "Validation score: 0.788644\n",
      "Iteration 3344, loss = 0.00431975\n",
      "Validation score: 0.788653\n",
      "Iteration 3345, loss = 0.00431898\n",
      "Validation score: 0.788661\n",
      "Iteration 3346, loss = 0.00431820\n",
      "Validation score: 0.788669\n",
      "Iteration 3347, loss = 0.00431742\n",
      "Validation score: 0.788678\n",
      "Iteration 3348, loss = 0.00431665\n",
      "Validation score: 0.788687\n",
      "Iteration 3349, loss = 0.00431587\n",
      "Validation score: 0.788696\n",
      "Iteration 3350, loss = 0.00431509\n",
      "Validation score: 0.788705\n",
      "Iteration 3351, loss = 0.00431431\n",
      "Validation score: 0.788712\n",
      "Iteration 3352, loss = 0.00431353\n",
      "Validation score: 0.788719\n",
      "Iteration 3353, loss = 0.00431276\n",
      "Validation score: 0.788727\n",
      "Iteration 3354, loss = 0.00431198\n",
      "Validation score: 0.788736\n",
      "Iteration 3355, loss = 0.00431120\n",
      "Validation score: 0.788743\n",
      "Iteration 3356, loss = 0.00431042\n",
      "Validation score: 0.788751\n",
      "Iteration 3357, loss = 0.00430964\n",
      "Validation score: 0.788760\n",
      "Iteration 3358, loss = 0.00430886\n",
      "Validation score: 0.788768\n",
      "Iteration 3359, loss = 0.00430809\n",
      "Validation score: 0.788775\n",
      "Iteration 3360, loss = 0.00430731\n",
      "Validation score: 0.788782\n",
      "Iteration 3361, loss = 0.00430653\n",
      "Validation score: 0.788790\n",
      "Iteration 3362, loss = 0.00430576\n",
      "Validation score: 0.788798\n",
      "Iteration 3363, loss = 0.00430498\n",
      "Validation score: 0.788802\n",
      "Iteration 3364, loss = 0.00430421\n",
      "Validation score: 0.788807\n",
      "Iteration 3365, loss = 0.00430343\n",
      "Validation score: 0.788813\n",
      "Iteration 3366, loss = 0.00430265\n",
      "Validation score: 0.788821\n",
      "Iteration 3367, loss = 0.00430187\n",
      "Validation score: 0.788827\n",
      "Iteration 3368, loss = 0.00430110\n",
      "Validation score: 0.788834\n",
      "Iteration 3369, loss = 0.00430032\n",
      "Validation score: 0.788841\n",
      "Validation score did not improve more than tol=0.000010 for 25 consecutive epochs. Stopping.\n",
      "R² Score: 0.7898930721565655\n",
      "RMSE: 0.08781378319381868\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(256, 128, 64),  \n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.001,             \n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.00001,\n",
    "    max_iter=10000,\n",
    "    random_state=87,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=25,\n",
    "    tol=1e-5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8800326530531825\n",
      "RMSE: 0.06635505734640551\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "\n",
    "importances = model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8499843089645263\n",
      "RMSE: 0.07420118566815581\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "xgb.plot_importance(model)\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8428288808539195\n",
      "RMSE: 0.07595019169277599\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(\n",
    "    n_neighbors=5,      \n",
    "    weights='distance', \n",
    "    algorithm='auto'    \n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
